{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-20T14:48:21.610213Z",
     "iopub.status.busy": "2024-04-20T14:48:21.609885Z",
     "iopub.status.idle": "2024-04-20T14:48:21.981536Z",
     "shell.execute_reply": "2024-04-20T14:48:21.980557Z",
     "shell.execute_reply.started": "2024-04-20T14:48:21.610186Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/fault-data-for-sensors/data/MissingInfoData.npy\n",
      "/kaggle/input/fault-data-for-sensors/data/NormalData.npy\n",
      "/kaggle/input/fault-data-for-sensors/data/TrendData.npy\n",
      "/kaggle/input/fault-data-for-sensors/data/MissingData.npy\n",
      "/kaggle/input/fault-data-for-sensors/data/RandomData.npy\n",
      "/kaggle/input/fault-data-for-sensors/data/JumpData.npy\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load  \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T14:48:21.983544Z",
     "iopub.status.busy": "2024-04-20T14:48:21.983180Z",
     "iopub.status.idle": "2024-04-20T14:48:30.856628Z",
     "shell.execute_reply": "2024-04-20T14:48:30.855568Z",
     "shell.execute_reply.started": "2024-04-20T14:48:21.983521Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# data in format 5000 x 200 x 10\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.initializers import glorot_uniform, glorot_normal\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_indices = random.sample(range(10001), 60)\n",
    "\n",
    "print(random_indices)\n",
    "\n",
    "numbers = list(range(60))\n",
    "\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T15:32:06.399613Z",
     "iopub.status.busy": "2024-04-20T15:32:06.399216Z",
     "iopub.status.idle": "2024-04-20T15:32:06.404234Z",
     "shell.execute_reply": "2024-04-20T15:32:06.403238Z",
     "shell.execute_reply.started": "2024-04-20T15:32:06.399585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T15:32:06.622887Z",
     "iopub.status.busy": "2024-04-20T15:32:06.621975Z",
     "iopub.status.idle": "2024-04-20T15:32:06.629325Z",
     "shell.execute_reply": "2024-04-20T15:32:06.628312Z",
     "shell.execute_reply.started": "2024-04-20T15:32:06.622847Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 50)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_indices = range(0,batch_size)\n",
    "random_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T15:32:07.308399Z",
     "iopub.status.busy": "2024-04-20T15:32:07.308042Z",
     "iopub.status.idle": "2024-04-20T15:32:07.561310Z",
     "shell.execute_reply": "2024-04-20T15:32:07.560388Z",
     "shell.execute_reply.started": "2024-04-20T15:32:07.308372Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Checking the Data\n",
    "\n",
    "JumpData = np.load(\"/kaggle/input/fault-data-for-sensors/data/JumpData.npy\")[random_indices]\n",
    "MissingData = np.load(\"/kaggle/input/fault-data-for-sensors/data/MissingData.npy\")[random_indices]\n",
    "NormalData = np.load(\"/kaggle/input/fault-data-for-sensors/data/NormalData.npy\")[random_indices]\n",
    "RandomData = np.load(\"/kaggle/input/fault-data-for-sensors/data/RandomData.npy\")[random_indices]\n",
    "TrendData = np.load(\"/kaggle/input/fault-data-for-sensors/data/TrendData.npy\")[random_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T15:32:07.664762Z",
     "iopub.status.busy": "2024-04-20T15:32:07.664238Z",
     "iopub.status.idle": "2024-04-20T15:32:07.670622Z",
     "shell.execute_reply": "2024-04-20T15:32:07.669804Z",
     "shell.execute_reply.started": "2024-04-20T15:32:07.664727Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 200, 10), (50, 200, 10), (50, 200, 10), (50, 200, 10), (50, 200, 10))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JumpData.shape, MissingData.shape, NormalData.shape, RandomData.shape, TrendData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T15:32:07.817874Z",
     "iopub.status.busy": "2024-04-20T15:32:07.817500Z",
     "iopub.status.idle": "2024-04-20T15:32:07.824670Z",
     "shell.execute_reply": "2024-04-20T15:32:07.823748Z",
     "shell.execute_reply.started": "2024-04-20T15:32:07.817841Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "JumpLabels = np.tile([1,0,0,0,0], (10000, 1))[:batch_size] \n",
    "MissingLabels = np.tile([0,1,0,0,0], (10000, 1))[:batch_size]\n",
    "NormalLabels = np.tile([0,0,1,0,0], (10000, 1))[:batch_size]\n",
    "RandomLabels = np.tile([0,0,0,1,0], (10000, 1))[:batch_size]\n",
    "TrendLabels = np.tile([0,0,0,0,1], (10000, 1))[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T15:32:07.968493Z",
     "iopub.status.busy": "2024-04-20T15:32:07.967634Z",
     "iopub.status.idle": "2024-04-20T15:32:07.983727Z",
     "shell.execute_reply": "2024-04-20T15:32:07.982853Z",
     "shell.execute_reply.started": "2024-04-20T15:32:07.968463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#splitting individual datas into train test val\n",
    "\n",
    "JumpX_train, JumpX_test, Jumpy_train, Jumpy_test = train_test_split(JumpData, JumpLabels, test_size=0.2, random_state=42)\n",
    "JumpX_train, JumpX_val, Jumpy_train, Jumpy_val = train_test_split(JumpX_train, Jumpy_train, test_size=0.1, random_state=42)\n",
    "\n",
    "MissingX_train, MissingX_test, Missingy_train, Missingy_test = train_test_split(MissingData, MissingLabels, test_size=0.2, random_state=42)\n",
    "MissingX_train, MissingX_val, Missingy_train, Missingy_val = train_test_split(MissingX_train, Missingy_train, test_size=0.1, random_state=42)\n",
    "\n",
    "NormalX_train, NormalX_test, Normaly_train, Normaly_test = train_test_split(NormalData, NormalLabels, test_size=0.2, random_state=42)\n",
    "NormalX_train, NormalX_val, Normaly_train, Normaly_val = train_test_split(NormalX_train, Normaly_train, test_size=0.1, random_state=42)\n",
    "\n",
    "RandomX_train, RandomX_test, Randomy_train, Randomy_test = train_test_split(RandomData, RandomLabels, test_size=0.2, random_state=42)\n",
    "RandomX_train, RandomX_val, Randomy_train, Randomy_val = train_test_split(RandomX_train, Randomy_train, test_size=0.1, random_state=42)\n",
    "\n",
    "TrendX_train, TrendX_test, Trendy_train, Trendy_test = train_test_split(TrendData, TrendLabels, test_size=0.2, random_state=42)\n",
    "TrendX_train, TrendX_val, Trendy_train, Trendy_val = train_test_split(TrendX_train, Trendy_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T15:32:08.126347Z",
     "iopub.status.busy": "2024-04-20T15:32:08.125827Z",
     "iopub.status.idle": "2024-04-20T15:32:08.133933Z",
     "shell.execute_reply": "2024-04-20T15:32:08.132979Z",
     "shell.execute_reply.started": "2024-04-20T15:32:08.126322Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train = np.append(JumpX_train, MissingX_train, axis=0)\n",
    "X_train = np.append(X_train, NormalX_train, axis=0)\n",
    "X_train = np.append(X_train, RandomX_train, axis=0)\n",
    "X_train = np.append(X_train, TrendX_train, axis=0) \n",
    "\n",
    "y_train = np.append(Jumpy_train, Missingy_train, axis=0)\n",
    "y_train = np.append(y_train, Normaly_train, axis=0)\n",
    "y_train = np.append(y_train, Randomy_train, axis=0)\n",
    "y_train = np.append(y_train, Trendy_train, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T15:32:08.302137Z",
     "iopub.status.busy": "2024-04-20T15:32:08.301540Z",
     "iopub.status.idle": "2024-04-20T15:32:08.308607Z",
     "shell.execute_reply": "2024-04-20T15:32:08.307706Z",
     "shell.execute_reply.started": "2024-04-20T15:32:08.302111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_test = np.append(JumpX_test, MissingX_test, axis=0)\n",
    "X_test = np.append(X_test, NormalX_test, axis=0)\n",
    "X_test = np.append(X_test, RandomX_test, axis=0)\n",
    "X_test = np.append(X_test, TrendX_test, axis=0) \n",
    "\n",
    "y_test = np.append(Jumpy_test, Missingy_test, axis=0)\n",
    "y_test = np.append(y_test, Normaly_test, axis=0)\n",
    "y_test = np.append(y_test, Randomy_test, axis=0)\n",
    "y_test = np.append(y_test, Trendy_test, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T15:32:08.467294Z",
     "iopub.status.busy": "2024-04-20T15:32:08.466569Z",
     "iopub.status.idle": "2024-04-20T15:32:08.473662Z",
     "shell.execute_reply": "2024-04-20T15:32:08.472864Z",
     "shell.execute_reply.started": "2024-04-20T15:32:08.467266Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_val = np.append(JumpX_val, MissingX_val, axis=0)\n",
    "X_val = np.append(X_val, NormalX_val, axis=0)\n",
    "X_val = np.append(X_val, RandomX_val, axis=0)\n",
    "X_val = np.append(X_val, TrendX_val, axis=0) \n",
    "\n",
    "y_val = np.append(Jumpy_val, Missingy_val, axis=0)\n",
    "y_val = np.append(y_val, Normaly_val, axis=0)\n",
    "y_val = np.append(y_val, Randomy_val, axis=0)\n",
    "y_val = np.append(y_val, Trendy_val, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T15:32:08.922712Z",
     "iopub.status.busy": "2024-04-20T15:32:08.922040Z",
     "iopub.status.idle": "2024-04-20T15:32:08.929289Z",
     "shell.execute_reply": "2024-04-20T15:32:08.928372Z",
     "shell.execute_reply.started": "2024-04-20T15:32:08.922672Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((180, 200, 10), (50, 200, 10), (20, 200, 10), (180, 5), (50, 5), (20, 5))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_val.shape, y_train.shape, y_test.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T15:32:09.283538Z",
     "iopub.status.busy": "2024-04-20T15:32:09.282752Z",
     "iopub.status.idle": "2024-04-20T15:32:09.289637Z",
     "shell.execute_reply": "2024-04-20T15:32:09.288729Z",
     "shell.execute_reply.started": "2024-04-20T15:32:09.283506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train = np.round(X_train, 3)\n",
    "X_test = np.round(X_test, 3)\n",
    "X_val = np.round(X_val, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T15:32:09.780452Z",
     "iopub.status.busy": "2024-04-20T15:32:09.779590Z",
     "iopub.status.idle": "2024-04-20T15:32:09.787428Z",
     "shell.execute_reply": "2024-04-20T15:32:09.786516Z",
     "shell.execute_reply.started": "2024-04-20T15:32:09.780418Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Shuffling the Data and labels\n",
    "\n",
    "train_samples = X_train.shape[0]\n",
    "test_samples = X_test.shape[0]\n",
    "val_samples = X_val.shape[0]\n",
    "\n",
    "random_indices = np.random.permutation(train_samples)\n",
    "X_train = X_train[random_indices]\n",
    "y_train = y_train[random_indices]\n",
    "\n",
    "random_indices = np.random.permutation(test_samples)\n",
    "X_test = X_test[random_indices]\n",
    "y_test = y_test[random_indices]\n",
    "\n",
    "random_indices = np.random.permutation(val_samples)\n",
    "X_val = X_val[random_indices]\n",
    "y_val = y_val[random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T15:32:10.829126Z",
     "iopub.status.busy": "2024-04-20T15:32:10.828284Z",
     "iopub.status.idle": "2024-04-20T15:32:10.835417Z",
     "shell.execute_reply": "2024-04-20T15:32:10.834540Z",
     "shell.execute_reply.started": "2024-04-20T15:32:10.829092Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((180, 200, 10), (50, 200, 10), (20, 200, 10), (180, 5), (50, 5), (20, 5))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_val.shape, y_train.shape, y_test.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T15:32:11.157719Z",
     "iopub.status.busy": "2024-04-20T15:32:11.156900Z",
     "iopub.status.idle": "2024-04-20T15:32:11.246811Z",
     "shell.execute_reply": "2024-04-20T15:32:11.245909Z",
     "shell.execute_reply.started": "2024-04-20T15:32:11.157667Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.553 -0.013  0.259  0.046 -4.819  0.154  0.035 -0.179  0.208  0.087]\n",
      "[0.59688889 0.06257143 0.0442     0.03966667 0.041     ]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# derive new columns\n",
    "\n",
    "def derive_columns(data):\n",
    "    \n",
    "    min_vals = np.min(data, axis=1)\n",
    "    max_vals = np.max(data, axis=1)\n",
    "    median_vals = np.median(data, axis=1)\n",
    "    avg_vals = np.mean(data, axis=1)\n",
    "    std_dev_vals = np.std(data, axis=1)\n",
    "    \n",
    "    new_data = np.zeros((data.shape[0], 5))\n",
    "    \n",
    "    \n",
    "    sorted_data = np.sort(data, axis=1)\n",
    "    new_data[:, 0] = (max_vals - min_vals)/9\n",
    "    new_data[:, 1] = (sorted_data[:, -2] - sorted_data[:, 1])/7\n",
    "    new_data[:, 2] = (sorted_data[:, -3] - sorted_data[:, 2])/5\n",
    "    new_data[:, 3] = (sorted_data[:, -4] - sorted_data[:, 3])/3\n",
    "    new_data[:, 4] = sorted_data[:, -5] - sorted_data[:, 4]\n",
    "\n",
    "    \n",
    "    return new_data\n",
    "    \n",
    "    \n",
    "# Test\n",
    "X_train_new = np.zeros((len(X_train), 200, 5))\n",
    "X_test_new = np.zeros((len(X_test), 200, 5))\n",
    "X_val_new = np.zeros((len(X_val), 200, 5))\n",
    "print(X_train[0][0][:])\n",
    "print(derive_columns(X_train[0])[0][:])\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    X_train_new[i] = derive_columns(X_train[i])\n",
    "    \n",
    "for i in range(len(X_test)):\n",
    "    X_test_new[i] = derive_columns(X_test[i])\n",
    "    \n",
    "for i in range(len(X_val)):\n",
    "    X_val_new[i] = derive_columns(X_val[i])\n",
    "\n",
    "print(\"done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T15:32:11.965828Z",
     "iopub.status.busy": "2024-04-20T15:32:11.965099Z",
     "iopub.status.idle": "2024-04-20T15:32:11.971737Z",
     "shell.execute_reply": "2024-04-20T15:32:11.970842Z",
     "shell.execute_reply.started": "2024-04-20T15:32:11.965795Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((180, 200, 5), (50, 200, 5), (20, 200, 5))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new.shape,X_test_new.shape,X_val_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T15:32:12.101555Z",
     "iopub.status.busy": "2024-04-20T15:32:12.100894Z",
     "iopub.status.idle": "2024-04-20T15:32:12.105710Z",
     "shell.execute_reply": "2024-04-20T15:32:12.104638Z",
     "shell.execute_reply.started": "2024-04-20T15:32:12.101528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train= X_train_new\n",
    "X_test= X_test_new\n",
    "X_val= X_val_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial stage : CNN MODEL FOR FAULT DETECTION AND CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:20:58.511500Z",
     "iopub.status.busy": "2024-04-17T12:20:58.511147Z",
     "iopub.status.idle": "2024-04-17T12:20:58.587800Z",
     "shell.execute_reply": "2024-04-17T12:20:58.587018Z",
     "shell.execute_reply.started": "2024-04-17T12:20:58.511455Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "classifier_model = keras.models.Sequential([    \n",
    "    keras.layers.Conv2D(filters=10, kernel_size=(11,1),kernel_initializer=glorot_normal() ,activation='tanh',padding='same' ,input_shape=(200,5,1)),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 1)),\n",
    "\n",
    "    \n",
    "    keras.layers.Conv2D(filters=20, kernel_size=(5,1),kernel_initializer=glorot_normal() ,activation='tanh' ,padding='same'), \n",
    "    keras.layers.MaxPool2D(pool_size=(2, 1)),\n",
    "    keras.layers.Dropout(rate=0.5),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation='tanh',kernel_initializer=glorot_normal()), # glorot_uniform\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T11:08:41.955946Z",
     "iopub.status.busy": "2024-04-17T11:08:41.955323Z",
     "iopub.status.idle": "2024-04-17T11:08:41.961808Z",
     "shell.execute_reply": "2024-04-17T11:08:41.960915Z",
     "shell.execute_reply.started": "2024-04-17T11:08:41.955912Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "class TimingCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, logs={}):\n",
    "        self.logs=[]\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.starttime = timer()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(timer()-self.starttime)\n",
    "\n",
    "cb = TimingCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T12:21:00.818155Z",
     "iopub.status.busy": "2024-04-17T12:21:00.817333Z",
     "iopub.status.idle": "2024-04-17T12:21:00.845427Z",
     "shell.execute_reply": "2024-04-17T12:21:00.844499Z",
     "shell.execute_reply.started": "2024-04-17T12:21:00.818121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T11:09:46.989279Z",
     "iopub.status.busy": "2024-04-17T11:09:46.988908Z",
     "iopub.status.idle": "2024-04-17T11:09:47.006776Z",
     "shell.execute_reply": "2024-04-17T11:09:47.005901Z",
     "shell.execute_reply.started": "2024-04-17T11:09:46.989248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=lr)\n",
    "classifier_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T11:09:10.032379Z",
     "iopub.status.busy": "2024-04-17T11:09:10.032042Z",
     "iopub.status.idle": "2024-04-17T11:09:10.036593Z",
     "shell.execute_reply": "2024-04-17T11:09:10.035660Z",
     "shell.execute_reply.started": "2024-04-17T11:09:10.032354Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lr = 0.0002\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T11:09:53.567891Z",
     "iopub.status.busy": "2024-04-17T11:09:53.567444Z",
     "iopub.status.idle": "2024-04-17T11:12:55.878267Z",
     "shell.execute_reply": "2024-04-17T11:12:55.877454Z",
     "shell.execute_reply.started": "2024-04-17T11:09:53.567842Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "hist = classifier_model.fit(X_train, y_train, epochs=epochs,batch_size=1000 ,validation_data= (X_val, y_val), callbacks=[cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T11:13:01.106176Z",
     "iopub.status.busy": "2024-04-17T11:13:01.105833Z",
     "iopub.status.idle": "2024-04-17T11:13:01.111881Z",
     "shell.execute_reply": "2024-04-17T11:13:01.110823Z",
     "shell.execute_reply.started": "2024-04-17T11:13:01.106151Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(cb.logs)\n",
    "print(sum(cb.logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T11:13:04.858676Z",
     "iopub.status.busy": "2024-04-17T11:13:04.858293Z",
     "iopub.status.idle": "2024-04-17T11:13:05.211499Z",
     "shell.execute_reply": "2024-04-17T11:13:05.210613Z",
     "shell.execute_reply.started": "2024-04-17T11:13:04.858646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T11:13:08.832378Z",
     "iopub.status.busy": "2024-04-17T11:13:08.831995Z",
     "iopub.status.idle": "2024-04-17T11:13:08.838900Z",
     "shell.execute_reply": "2024-04-17T11:13:08.837975Z",
     "shell.execute_reply.started": "2024-04-17T11:13:08.832348Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loss[-1], val_loss[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T11:13:15.024256Z",
     "iopub.status.busy": "2024-04-17T11:13:15.023571Z",
     "iopub.status.idle": "2024-04-17T11:13:15.273548Z",
     "shell.execute_reply": "2024-04-17T11:13:15.272638Z",
     "shell.execute_reply.started": "2024-04-17T11:13:15.024224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_acc, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T11:13:18.366954Z",
     "iopub.status.busy": "2024-04-17T11:13:18.366131Z",
     "iopub.status.idle": "2024-04-17T11:13:18.372932Z",
     "shell.execute_reply": "2024-04-17T11:13:18.372021Z",
     "shell.execute_reply.started": "2024-04-17T11:13:18.366923Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_acc[-1], val_acc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T11:14:05.337792Z",
     "iopub.status.busy": "2024-04-17T11:14:05.337041Z",
     "iopub.status.idle": "2024-04-17T11:14:06.430788Z",
     "shell.execute_reply": "2024-04-17T11:14:06.429834Z",
     "shell.execute_reply.started": "2024-04-17T11:14:05.337760Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred = classifier_model.predict(X_test)\n",
    "\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "\n",
    "cm = cm/2000\n",
    "\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Spike\", \"Missing\", \"Normal\", \"Random\", \"Drift\"])\n",
    "\n",
    "disp.plot(cmap='Blues')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tp = np.diag(cm)\n",
    "fp = np.sum(cm, axis=0) - tp\n",
    "fn = np.sum(cm, axis=1) - tp\n",
    "tn = np.sum(cm) - (tp + fp + fn)\n",
    "\n",
    "tp = np.sum(tp)\n",
    "fp = np.sum(fp)\n",
    "fn = np.sum(fn)\n",
    "tn = np.sum(tn)\n",
    "tp, fp, fn, tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "precision = precision_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "recall = recall_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
    "f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "\n",
    "precision, recall, accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T15:32:16.543170Z",
     "iopub.status.busy": "2024-04-20T15:32:16.542305Z",
     "iopub.status.idle": "2024-04-20T15:33:54.703509Z",
     "shell.execute_reply": "2024-04-20T15:33:54.702675Z",
     "shell.execute_reply.started": "2024-04-20T15:32:16.543135Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- TRY 1 ----------------------------\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 15:32:17.320558: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_51/dropout_51/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 1.6198 - accuracy: 0.1333 - val_loss: 1.5451 - val_accuracy: 0.2000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5649 - accuracy: 0.2000 - val_loss: 1.4722 - val_accuracy: 0.2000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4991 - accuracy: 0.2111 - val_loss: 1.4108 - val_accuracy: 0.3000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4407 - accuracy: 0.3778 - val_loss: 1.3629 - val_accuracy: 0.3000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4021 - accuracy: 0.3389 - val_loss: 1.3245 - val_accuracy: 0.4000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3630 - accuracy: 0.4667 - val_loss: 1.2944 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3228 - accuracy: 0.5944 - val_loss: 1.2700 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2929 - accuracy: 0.5389 - val_loss: 1.2487 - val_accuracy: 0.3500\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2621 - accuracy: 0.5611 - val_loss: 1.2286 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2325 - accuracy: 0.5722 - val_loss: 1.2081 - val_accuracy: 0.4000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1976 - accuracy: 0.6167 - val_loss: 1.1860 - val_accuracy: 0.5000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1698 - accuracy: 0.6833 - val_loss: 1.1622 - val_accuracy: 0.6500\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1515 - accuracy: 0.6722 - val_loss: 1.1389 - val_accuracy: 0.7000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1308 - accuracy: 0.6889 - val_loss: 1.1141 - val_accuracy: 0.6500\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1033 - accuracy: 0.7111 - val_loss: 1.0884 - val_accuracy: 0.5500\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0771 - accuracy: 0.6944 - val_loss: 1.0632 - val_accuracy: 0.6000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0529 - accuracy: 0.7167 - val_loss: 1.0373 - val_accuracy: 0.6500\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0188 - accuracy: 0.7278 - val_loss: 1.0091 - val_accuracy: 0.5500\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9997 - accuracy: 0.7278 - val_loss: 0.9813 - val_accuracy: 0.6000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9653 - accuracy: 0.7444 - val_loss: 0.9514 - val_accuracy: 0.6000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9486 - accuracy: 0.7056 - val_loss: 0.9204 - val_accuracy: 0.6000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9180 - accuracy: 0.7111 - val_loss: 0.8875 - val_accuracy: 0.5500\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8833 - accuracy: 0.7167 - val_loss: 0.8623 - val_accuracy: 0.6000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8763 - accuracy: 0.7111 - val_loss: 0.8368 - val_accuracy: 0.6000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8300 - accuracy: 0.7667 - val_loss: 0.8107 - val_accuracy: 0.6500\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8242 - accuracy: 0.7278 - val_loss: 0.7932 - val_accuracy: 0.7000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7901 - accuracy: 0.7611 - val_loss: 0.7808 - val_accuracy: 0.7000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7769 - accuracy: 0.7556 - val_loss: 0.7632 - val_accuracy: 0.7500\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7747 - accuracy: 0.7500 - val_loss: 0.7356 - val_accuracy: 0.6500\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7293 - accuracy: 0.8056 - val_loss: 0.7143 - val_accuracy: 0.7000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7357 - accuracy: 0.7889 - val_loss: 0.7030 - val_accuracy: 0.7500\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7263 - accuracy: 0.7611 - val_loss: 0.6847 - val_accuracy: 0.7500\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6946 - accuracy: 0.7667 - val_loss: 0.6655 - val_accuracy: 0.7500\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6866 - accuracy: 0.7722 - val_loss: 0.6618 - val_accuracy: 0.7500\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6649 - accuracy: 0.7833 - val_loss: 0.6690 - val_accuracy: 0.7500\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6933 - accuracy: 0.8000 - val_loss: 0.6617 - val_accuracy: 0.7500\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6503 - accuracy: 0.8111 - val_loss: 0.6413 - val_accuracy: 0.7000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6223 - accuracy: 0.7833 - val_loss: 0.6262 - val_accuracy: 0.7000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6343 - accuracy: 0.8111 - val_loss: 0.6126 - val_accuracy: 0.7500\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6065 - accuracy: 0.7833 - val_loss: 0.6002 - val_accuracy: 0.7500\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6177 - accuracy: 0.7833 - val_loss: 0.5954 - val_accuracy: 0.7500\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5713 - accuracy: 0.7944 - val_loss: 0.5819 - val_accuracy: 0.7500\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6126 - accuracy: 0.7611 - val_loss: 0.5811 - val_accuracy: 0.7000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5879 - accuracy: 0.8000 - val_loss: 0.5952 - val_accuracy: 0.7500\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5545 - accuracy: 0.8222 - val_loss: 0.6049 - val_accuracy: 0.7500\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5699 - accuracy: 0.7944 - val_loss: 0.5980 - val_accuracy: 0.7500\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5792 - accuracy: 0.7889 - val_loss: 0.5717 - val_accuracy: 0.7500\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5560 - accuracy: 0.8222 - val_loss: 0.5665 - val_accuracy: 0.8000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5338 - accuracy: 0.8167 - val_loss: 0.5864 - val_accuracy: 0.7000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5128 - accuracy: 0.8278 - val_loss: 0.5797 - val_accuracy: 0.7500\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5151 - accuracy: 0.8278 - val_loss: 0.5513 - val_accuracy: 0.7500\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5090 - accuracy: 0.8111 - val_loss: 0.5452 - val_accuracy: 0.7000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5151 - accuracy: 0.8056 - val_loss: 0.5507 - val_accuracy: 0.7000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5014 - accuracy: 0.8167 - val_loss: 0.5661 - val_accuracy: 0.7000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4730 - accuracy: 0.8611 - val_loss: 0.5794 - val_accuracy: 0.7000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4740 - accuracy: 0.8556 - val_loss: 0.5580 - val_accuracy: 0.7500\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4877 - accuracy: 0.8167 - val_loss: 0.5424 - val_accuracy: 0.7500\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4658 - accuracy: 0.8278 - val_loss: 0.5481 - val_accuracy: 0.7000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4605 - accuracy: 0.8389 - val_loss: 0.5508 - val_accuracy: 0.7000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4616 - accuracy: 0.8278 - val_loss: 0.5524 - val_accuracy: 0.7000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4519 - accuracy: 0.8500 - val_loss: 0.5319 - val_accuracy: 0.7500\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4367 - accuracy: 0.8611 - val_loss: 0.5139 - val_accuracy: 0.7500\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4047 - accuracy: 0.8889 - val_loss: 0.5123 - val_accuracy: 0.7000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4299 - accuracy: 0.8611 - val_loss: 0.5336 - val_accuracy: 0.7000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4397 - accuracy: 0.8278 - val_loss: 0.5442 - val_accuracy: 0.7000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4060 - accuracy: 0.8333 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4201 - accuracy: 0.8611 - val_loss: 0.5367 - val_accuracy: 0.7000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4026 - accuracy: 0.8556 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4006 - accuracy: 0.8556 - val_loss: 0.5200 - val_accuracy: 0.8000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3926 - accuracy: 0.8833 - val_loss: 0.5260 - val_accuracy: 0.8000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3983 - accuracy: 0.8556 - val_loss: 0.5209 - val_accuracy: 0.8000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4129 - accuracy: 0.8444 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3769 - accuracy: 0.8944 - val_loss: 0.5148 - val_accuracy: 0.7000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3821 - accuracy: 0.8944 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3532 - accuracy: 0.8667 - val_loss: 0.5373 - val_accuracy: 0.7500\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3858 - accuracy: 0.8278 - val_loss: 0.5534 - val_accuracy: 0.7500\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3422 - accuracy: 0.9111 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3548 - accuracy: 0.8722 - val_loss: 0.4931 - val_accuracy: 0.8000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3751 - accuracy: 0.8444 - val_loss: 0.4987 - val_accuracy: 0.8000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3621 - accuracy: 0.8722 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3485 - accuracy: 0.8778 - val_loss: 0.5132 - val_accuracy: 0.7500\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3238 - accuracy: 0.8778 - val_loss: 0.5370 - val_accuracy: 0.7000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3448 - accuracy: 0.8889 - val_loss: 0.5469 - val_accuracy: 0.6500\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3210 - accuracy: 0.9056 - val_loss: 0.5339 - val_accuracy: 0.7500\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3201 - accuracy: 0.8889 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3195 - accuracy: 0.8722 - val_loss: 0.5102 - val_accuracy: 0.8000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3079 - accuracy: 0.8833 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3156 - accuracy: 0.8944 - val_loss: 0.5107 - val_accuracy: 0.8000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2896 - accuracy: 0.9000 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3116 - accuracy: 0.8833 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2915 - accuracy: 0.9056 - val_loss: 0.5283 - val_accuracy: 0.7500\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2886 - accuracy: 0.9056 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3088 - accuracy: 0.8833 - val_loss: 0.5335 - val_accuracy: 0.7500\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2966 - accuracy: 0.8944 - val_loss: 0.5429 - val_accuracy: 0.7500\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2835 - accuracy: 0.9000 - val_loss: 0.5518 - val_accuracy: 0.7000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3033 - accuracy: 0.9111 - val_loss: 0.5251 - val_accuracy: 0.8000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2874 - accuracy: 0.8944 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2952 - accuracy: 0.8889 - val_loss: 0.5368 - val_accuracy: 0.7500\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2903 - accuracy: 0.9000 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2762 - accuracy: 0.9000 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2457 - accuracy: 0.9222 - val_loss: 0.5286 - val_accuracy: 0.8000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2769 - accuracy: 0.8889 - val_loss: 0.5186 - val_accuracy: 0.8000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2438 - accuracy: 0.9500 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2167 - accuracy: 0.9556 - val_loss: 0.5451 - val_accuracy: 0.7000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2709 - accuracy: 0.8944 - val_loss: 0.5634 - val_accuracy: 0.7000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2499 - accuracy: 0.9222 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2407 - accuracy: 0.9111 - val_loss: 0.5379 - val_accuracy: 0.8000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2362 - accuracy: 0.9278 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2259 - accuracy: 0.9278 - val_loss: 0.5939 - val_accuracy: 0.7000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2357 - accuracy: 0.9167 - val_loss: 0.5509 - val_accuracy: 0.7500\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2537 - accuracy: 0.9000 - val_loss: 0.5226 - val_accuracy: 0.8000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2174 - accuracy: 0.9500 - val_loss: 0.5143 - val_accuracy: 0.8000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2147 - accuracy: 0.9111 - val_loss: 0.5368 - val_accuracy: 0.8000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2295 - accuracy: 0.9111 - val_loss: 0.5663 - val_accuracy: 0.7000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2247 - accuracy: 0.9389 - val_loss: 0.5409 - val_accuracy: 0.8000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2205 - accuracy: 0.9278 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2209 - accuracy: 0.9278 - val_loss: 0.5236 - val_accuracy: 0.8000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2552 - accuracy: 0.9000 - val_loss: 0.5559 - val_accuracy: 0.7000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2044 - accuracy: 0.9444 - val_loss: 0.5820 - val_accuracy: 0.7000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2450 - accuracy: 0.8778 - val_loss: 0.5716 - val_accuracy: 0.7000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2093 - accuracy: 0.9500 - val_loss: 0.5540 - val_accuracy: 0.8000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2247 - accuracy: 0.9167 - val_loss: 0.5485 - val_accuracy: 0.7000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2375 - accuracy: 0.8944 - val_loss: 0.5410 - val_accuracy: 0.8000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2429 - accuracy: 0.9278 - val_loss: 0.5810 - val_accuracy: 0.7000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2200 - accuracy: 0.9167 - val_loss: 0.5970 - val_accuracy: 0.7000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2208 - accuracy: 0.9333 - val_loss: 0.5443 - val_accuracy: 0.7000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1887 - accuracy: 0.9389 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2089 - accuracy: 0.9278 - val_loss: 0.5376 - val_accuracy: 0.7000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1990 - accuracy: 0.9167 - val_loss: 0.5525 - val_accuracy: 0.7000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1663 - accuracy: 0.9667 - val_loss: 0.5787 - val_accuracy: 0.7000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2012 - accuracy: 0.9333 - val_loss: 0.5698 - val_accuracy: 0.7000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2172 - accuracy: 0.8944 - val_loss: 0.5457 - val_accuracy: 0.7500\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1814 - accuracy: 0.9333 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1804 - accuracy: 0.9444 - val_loss: 0.5377 - val_accuracy: 0.7500\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1922 - accuracy: 0.9389 - val_loss: 0.5585 - val_accuracy: 0.7000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1632 - accuracy: 0.9611 - val_loss: 0.5872 - val_accuracy: 0.7000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1921 - accuracy: 0.9278 - val_loss: 0.5866 - val_accuracy: 0.7000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1754 - accuracy: 0.9611 - val_loss: 0.5506 - val_accuracy: 0.7000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1790 - accuracy: 0.9278 - val_loss: 0.5323 - val_accuracy: 0.7500\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1818 - accuracy: 0.9222 - val_loss: 0.5334 - val_accuracy: 0.7500\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2033 - accuracy: 0.9167 - val_loss: 0.5449 - val_accuracy: 0.7000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1813 - accuracy: 0.9278 - val_loss: 0.5624 - val_accuracy: 0.7000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1985 - accuracy: 0.9111 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1569 - accuracy: 0.9444 - val_loss: 0.5484 - val_accuracy: 0.7500\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1474 - accuracy: 0.9556 - val_loss: 0.5372 - val_accuracy: 0.7500\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1443 - accuracy: 0.9556 - val_loss: 0.5387 - val_accuracy: 0.7000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1763 - accuracy: 0.9278 - val_loss: 0.5551 - val_accuracy: 0.7500\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1842 - accuracy: 0.9278 - val_loss: 0.5982 - val_accuracy: 0.7000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1588 - accuracy: 0.9500 - val_loss: 0.6153 - val_accuracy: 0.7000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1925 - accuracy: 0.9222 - val_loss: 0.5674 - val_accuracy: 0.7000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1744 - accuracy: 0.9333 - val_loss: 0.5314 - val_accuracy: 0.7500\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1719 - accuracy: 0.9389 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1705 - accuracy: 0.9444 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1773 - accuracy: 0.9333 - val_loss: 0.5798 - val_accuracy: 0.7000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1385 - accuracy: 0.9667 - val_loss: 0.6166 - val_accuracy: 0.7000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1538 - accuracy: 0.9278 - val_loss: 0.5923 - val_accuracy: 0.7000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1610 - accuracy: 0.9333 - val_loss: 0.5582 - val_accuracy: 0.7500\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1462 - accuracy: 0.9556 - val_loss: 0.5479 - val_accuracy: 0.7000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1468 - accuracy: 0.9389 - val_loss: 0.5494 - val_accuracy: 0.7000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1689 - accuracy: 0.9333 - val_loss: 0.5703 - val_accuracy: 0.7500\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1445 - accuracy: 0.9333 - val_loss: 0.6220 - val_accuracy: 0.7000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1643 - accuracy: 0.9556 - val_loss: 0.6175 - val_accuracy: 0.7000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1692 - accuracy: 0.9389 - val_loss: 0.5579 - val_accuracy: 0.7500\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1628 - accuracy: 0.9333 - val_loss: 0.5327 - val_accuracy: 0.7000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1762 - accuracy: 0.9278 - val_loss: 0.5388 - val_accuracy: 0.7000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1490 - accuracy: 0.9222 - val_loss: 0.5684 - val_accuracy: 0.6500\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1281 - accuracy: 0.9556 - val_loss: 0.6058 - val_accuracy: 0.7000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1886 - accuracy: 0.9111 - val_loss: 0.6027 - val_accuracy: 0.6500\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1583 - accuracy: 0.9500 - val_loss: 0.5819 - val_accuracy: 0.7500\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1528 - accuracy: 0.9333 - val_loss: 0.5623 - val_accuracy: 0.7500\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1773 - accuracy: 0.9111 - val_loss: 0.5589 - val_accuracy: 0.7500\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1624 - accuracy: 0.9278 - val_loss: 0.5670 - val_accuracy: 0.7000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1256 - accuracy: 0.9333 - val_loss: 0.5815 - val_accuracy: 0.7000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1449 - accuracy: 0.9389 - val_loss: 0.6030 - val_accuracy: 0.7000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1286 - accuracy: 0.9389 - val_loss: 0.6207 - val_accuracy: 0.7000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1584 - accuracy: 0.9444 - val_loss: 0.6169 - val_accuracy: 0.7000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1543 - accuracy: 0.9278 - val_loss: 0.6170 - val_accuracy: 0.7000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1535 - accuracy: 0.9389 - val_loss: 0.6254 - val_accuracy: 0.6500\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1348 - accuracy: 0.9611 - val_loss: 0.6207 - val_accuracy: 0.7000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1290 - accuracy: 0.9556 - val_loss: 0.6045 - val_accuracy: 0.6500\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1417 - accuracy: 0.9444 - val_loss: 0.5847 - val_accuracy: 0.6500\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1347 - accuracy: 0.9500 - val_loss: 0.5670 - val_accuracy: 0.7000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1368 - accuracy: 0.9667 - val_loss: 0.5623 - val_accuracy: 0.7000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1484 - accuracy: 0.9444 - val_loss: 0.5795 - val_accuracy: 0.7000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1369 - accuracy: 0.9333 - val_loss: 0.5896 - val_accuracy: 0.7000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1439 - accuracy: 0.9500 - val_loss: 0.6152 - val_accuracy: 0.6500\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1260 - accuracy: 0.9444 - val_loss: 0.6461 - val_accuracy: 0.7000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1455 - accuracy: 0.9389 - val_loss: 0.6636 - val_accuracy: 0.7000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1198 - accuracy: 0.9611 - val_loss: 0.6726 - val_accuracy: 0.7000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1350 - accuracy: 0.9500 - val_loss: 0.6631 - val_accuracy: 0.7000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1558 - accuracy: 0.9278 - val_loss: 0.6277 - val_accuracy: 0.7500\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1209 - accuracy: 0.9611 - val_loss: 0.5961 - val_accuracy: 0.7000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1635 - accuracy: 0.9167 - val_loss: 0.5929 - val_accuracy: 0.7000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1418 - accuracy: 0.9389 - val_loss: 0.6058 - val_accuracy: 0.6500\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1309 - accuracy: 0.9444 - val_loss: 0.6347 - val_accuracy: 0.6500\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1442 - accuracy: 0.9444 - val_loss: 0.6408 - val_accuracy: 0.6500\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1542 - accuracy: 0.9444 - val_loss: 0.6284 - val_accuracy: 0.6500\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1250 - accuracy: 0.9389 - val_loss: 0.6235 - val_accuracy: 0.6500\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1457 - accuracy: 0.9444 - val_loss: 0.6257 - val_accuracy: 0.7500\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1323 - accuracy: 0.9444 - val_loss: 0.6260 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 24ms/step\n",
      "------------------- TRY 2 ----------------------------\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 15:32:27.091122: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_52/dropout_52/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 1.6082 - accuracy: 0.2111 - val_loss: 1.5328 - val_accuracy: 0.2000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5616 - accuracy: 0.2000 - val_loss: 1.4648 - val_accuracy: 0.2000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4983 - accuracy: 0.2611 - val_loss: 1.4011 - val_accuracy: 0.4500\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4429 - accuracy: 0.4333 - val_loss: 1.3469 - val_accuracy: 0.4500\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3934 - accuracy: 0.4722 - val_loss: 1.3006 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3433 - accuracy: 0.5611 - val_loss: 1.2596 - val_accuracy: 0.6500\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3070 - accuracy: 0.5778 - val_loss: 1.2235 - val_accuracy: 0.5500\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2627 - accuracy: 0.6667 - val_loss: 1.1913 - val_accuracy: 0.5500\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2140 - accuracy: 0.6556 - val_loss: 1.1600 - val_accuracy: 0.6500\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2011 - accuracy: 0.6500 - val_loss: 1.1303 - val_accuracy: 0.6000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1476 - accuracy: 0.7278 - val_loss: 1.1010 - val_accuracy: 0.6000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1189 - accuracy: 0.7444 - val_loss: 1.0702 - val_accuracy: 0.6000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0859 - accuracy: 0.6889 - val_loss: 1.0407 - val_accuracy: 0.7000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0581 - accuracy: 0.7222 - val_loss: 1.0147 - val_accuracy: 0.7000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0480 - accuracy: 0.7222 - val_loss: 0.9859 - val_accuracy: 0.7000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0084 - accuracy: 0.7389 - val_loss: 0.9530 - val_accuracy: 0.7000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9650 - accuracy: 0.7556 - val_loss: 0.9252 - val_accuracy: 0.6000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9394 - accuracy: 0.7278 - val_loss: 0.9022 - val_accuracy: 0.6000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9125 - accuracy: 0.7167 - val_loss: 0.8777 - val_accuracy: 0.7000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8879 - accuracy: 0.7000 - val_loss: 0.8467 - val_accuracy: 0.7500\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8680 - accuracy: 0.7278 - val_loss: 0.8123 - val_accuracy: 0.8000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8249 - accuracy: 0.7111 - val_loss: 0.7816 - val_accuracy: 0.7000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8092 - accuracy: 0.7500 - val_loss: 0.7627 - val_accuracy: 0.7500\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7842 - accuracy: 0.7833 - val_loss: 0.7516 - val_accuracy: 0.8000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7738 - accuracy: 0.7556 - val_loss: 0.7305 - val_accuracy: 0.8000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7486 - accuracy: 0.7556 - val_loss: 0.7087 - val_accuracy: 0.8500\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7231 - accuracy: 0.7722 - val_loss: 0.6867 - val_accuracy: 0.8000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7041 - accuracy: 0.7556 - val_loss: 0.6721 - val_accuracy: 0.8500\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7133 - accuracy: 0.8167 - val_loss: 0.6495 - val_accuracy: 0.8000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6857 - accuracy: 0.7778 - val_loss: 0.6499 - val_accuracy: 0.8000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6829 - accuracy: 0.7278 - val_loss: 0.6423 - val_accuracy: 0.8000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6710 - accuracy: 0.7611 - val_loss: 0.6401 - val_accuracy: 0.8000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6646 - accuracy: 0.8056 - val_loss: 0.6040 - val_accuracy: 0.8000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6546 - accuracy: 0.7556 - val_loss: 0.5865 - val_accuracy: 0.8500\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6271 - accuracy: 0.7778 - val_loss: 0.5936 - val_accuracy: 0.8000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6523 - accuracy: 0.7667 - val_loss: 0.6103 - val_accuracy: 0.8000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6218 - accuracy: 0.7667 - val_loss: 0.5996 - val_accuracy: 0.8500\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6109 - accuracy: 0.7556 - val_loss: 0.5928 - val_accuracy: 0.7500\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5932 - accuracy: 0.7833 - val_loss: 0.5926 - val_accuracy: 0.7500\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5999 - accuracy: 0.7889 - val_loss: 0.6035 - val_accuracy: 0.8000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5719 - accuracy: 0.8111 - val_loss: 0.5805 - val_accuracy: 0.7500\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5797 - accuracy: 0.7944 - val_loss: 0.5431 - val_accuracy: 0.7500\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5680 - accuracy: 0.7944 - val_loss: 0.5417 - val_accuracy: 0.8000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5705 - accuracy: 0.7889 - val_loss: 0.5676 - val_accuracy: 0.7500\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5461 - accuracy: 0.7889 - val_loss: 0.6039 - val_accuracy: 0.7000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5349 - accuracy: 0.7722 - val_loss: 0.5913 - val_accuracy: 0.8000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5325 - accuracy: 0.8056 - val_loss: 0.5553 - val_accuracy: 0.8000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5370 - accuracy: 0.7944 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5352 - accuracy: 0.8111 - val_loss: 0.5541 - val_accuracy: 0.8000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5018 - accuracy: 0.8278 - val_loss: 0.5615 - val_accuracy: 0.7500\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4986 - accuracy: 0.8389 - val_loss: 0.5421 - val_accuracy: 0.8000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4973 - accuracy: 0.8278 - val_loss: 0.5216 - val_accuracy: 0.8000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4920 - accuracy: 0.8167 - val_loss: 0.5290 - val_accuracy: 0.8000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4827 - accuracy: 0.8167 - val_loss: 0.5375 - val_accuracy: 0.8000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4452 - accuracy: 0.8500 - val_loss: 0.5543 - val_accuracy: 0.8000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4826 - accuracy: 0.8333 - val_loss: 0.5438 - val_accuracy: 0.8000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4804 - accuracy: 0.8389 - val_loss: 0.5334 - val_accuracy: 0.7500\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4823 - accuracy: 0.8000 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4552 - accuracy: 0.8444 - val_loss: 0.4864 - val_accuracy: 0.8000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4407 - accuracy: 0.8500 - val_loss: 0.4992 - val_accuracy: 0.8000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4389 - accuracy: 0.8389 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4220 - accuracy: 0.8667 - val_loss: 0.5273 - val_accuracy: 0.8000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4370 - accuracy: 0.8556 - val_loss: 0.5245 - val_accuracy: 0.8000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4231 - accuracy: 0.8778 - val_loss: 0.5135 - val_accuracy: 0.7500\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4505 - accuracy: 0.8000 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4182 - accuracy: 0.8778 - val_loss: 0.5161 - val_accuracy: 0.8000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4206 - accuracy: 0.8333 - val_loss: 0.5138 - val_accuracy: 0.8000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4048 - accuracy: 0.8500 - val_loss: 0.5030 - val_accuracy: 0.8000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3853 - accuracy: 0.8667 - val_loss: 0.5071 - val_accuracy: 0.8000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4051 - accuracy: 0.8389 - val_loss: 0.5130 - val_accuracy: 0.8000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4198 - accuracy: 0.8333 - val_loss: 0.5168 - val_accuracy: 0.8000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3928 - accuracy: 0.8389 - val_loss: 0.5286 - val_accuracy: 0.8000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3733 - accuracy: 0.8611 - val_loss: 0.5362 - val_accuracy: 0.8000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3888 - accuracy: 0.8500 - val_loss: 0.5288 - val_accuracy: 0.8000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3625 - accuracy: 0.8833 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3758 - accuracy: 0.8556 - val_loss: 0.4947 - val_accuracy: 0.8000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3595 - accuracy: 0.8611 - val_loss: 0.4953 - val_accuracy: 0.8000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3624 - accuracy: 0.8500 - val_loss: 0.5162 - val_accuracy: 0.8000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3546 - accuracy: 0.8833 - val_loss: 0.5441 - val_accuracy: 0.7000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3379 - accuracy: 0.9056 - val_loss: 0.5415 - val_accuracy: 0.7500\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3539 - accuracy: 0.8500 - val_loss: 0.5323 - val_accuracy: 0.7500\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3297 - accuracy: 0.8778 - val_loss: 0.5138 - val_accuracy: 0.8000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3350 - accuracy: 0.8611 - val_loss: 0.5059 - val_accuracy: 0.8000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3551 - accuracy: 0.8611 - val_loss: 0.5155 - val_accuracy: 0.8000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3212 - accuracy: 0.8944 - val_loss: 0.5131 - val_accuracy: 0.7500\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2930 - accuracy: 0.9167 - val_loss: 0.5228 - val_accuracy: 0.7500\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3237 - accuracy: 0.8889 - val_loss: 0.5088 - val_accuracy: 0.8000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3043 - accuracy: 0.9056 - val_loss: 0.4897 - val_accuracy: 0.8500\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3206 - accuracy: 0.8611 - val_loss: 0.4851 - val_accuracy: 0.7500\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3183 - accuracy: 0.8944 - val_loss: 0.5050 - val_accuracy: 0.8000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3186 - accuracy: 0.9000 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2982 - accuracy: 0.8778 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2971 - accuracy: 0.8833 - val_loss: 0.5165 - val_accuracy: 0.8000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3050 - accuracy: 0.8889 - val_loss: 0.4842 - val_accuracy: 0.8000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2890 - accuracy: 0.8778 - val_loss: 0.4819 - val_accuracy: 0.8000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2877 - accuracy: 0.9056 - val_loss: 0.4864 - val_accuracy: 0.8000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2834 - accuracy: 0.8944 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2434 - accuracy: 0.9444 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2708 - accuracy: 0.9111 - val_loss: 0.5024 - val_accuracy: 0.8000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2672 - accuracy: 0.9111 - val_loss: 0.4780 - val_accuracy: 0.7500\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2748 - accuracy: 0.9000 - val_loss: 0.4765 - val_accuracy: 0.7500\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2714 - accuracy: 0.9056 - val_loss: 0.4950 - val_accuracy: 0.8000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2941 - accuracy: 0.8833 - val_loss: 0.5317 - val_accuracy: 0.7500\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2652 - accuracy: 0.8944 - val_loss: 0.5484 - val_accuracy: 0.7500\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2674 - accuracy: 0.8833 - val_loss: 0.5399 - val_accuracy: 0.8000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2688 - accuracy: 0.9167 - val_loss: 0.4994 - val_accuracy: 0.8000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2455 - accuracy: 0.9000 - val_loss: 0.4715 - val_accuracy: 0.8000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2470 - accuracy: 0.9111 - val_loss: 0.4791 - val_accuracy: 0.7500\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2553 - accuracy: 0.8889 - val_loss: 0.5074 - val_accuracy: 0.7000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2410 - accuracy: 0.9111 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2352 - accuracy: 0.9111 - val_loss: 0.5302 - val_accuracy: 0.8000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2617 - accuracy: 0.9056 - val_loss: 0.5168 - val_accuracy: 0.8000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2226 - accuracy: 0.9056 - val_loss: 0.5090 - val_accuracy: 0.7500\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2529 - accuracy: 0.9111 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2230 - accuracy: 0.9222 - val_loss: 0.5133 - val_accuracy: 0.8000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2236 - accuracy: 0.9333 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2052 - accuracy: 0.9444 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2349 - accuracy: 0.9000 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2203 - accuracy: 0.9389 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1999 - accuracy: 0.9333 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2211 - accuracy: 0.9278 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2254 - accuracy: 0.9111 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2311 - accuracy: 0.8889 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2004 - accuracy: 0.9444 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1981 - accuracy: 0.9278 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2173 - accuracy: 0.9167 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2114 - accuracy: 0.9222 - val_loss: 0.5123 - val_accuracy: 0.8000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2052 - accuracy: 0.9500 - val_loss: 0.5057 - val_accuracy: 0.8000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1966 - accuracy: 0.9389 - val_loss: 0.4932 - val_accuracy: 0.8000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1930 - accuracy: 0.9444 - val_loss: 0.4841 - val_accuracy: 0.8000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1949 - accuracy: 0.9389 - val_loss: 0.4797 - val_accuracy: 0.8000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1959 - accuracy: 0.9167 - val_loss: 0.4933 - val_accuracy: 0.8000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1813 - accuracy: 0.9444 - val_loss: 0.5108 - val_accuracy: 0.8000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1919 - accuracy: 0.9278 - val_loss: 0.5181 - val_accuracy: 0.8000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2092 - accuracy: 0.9111 - val_loss: 0.5203 - val_accuracy: 0.8000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1756 - accuracy: 0.9389 - val_loss: 0.5367 - val_accuracy: 0.8000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1806 - accuracy: 0.9278 - val_loss: 0.5556 - val_accuracy: 0.7500\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1932 - accuracy: 0.9333 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1608 - accuracy: 0.9389 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1767 - accuracy: 0.9278 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1647 - accuracy: 0.9500 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1712 - accuracy: 0.9556 - val_loss: 0.5555 - val_accuracy: 0.8000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1872 - accuracy: 0.9389 - val_loss: 0.5840 - val_accuracy: 0.7000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1967 - accuracy: 0.9278 - val_loss: 0.5819 - val_accuracy: 0.7000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1564 - accuracy: 0.9333 - val_loss: 0.5530 - val_accuracy: 0.8000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1833 - accuracy: 0.9167 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1717 - accuracy: 0.9333 - val_loss: 0.4932 - val_accuracy: 0.8000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1872 - accuracy: 0.9333 - val_loss: 0.4855 - val_accuracy: 0.8000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1955 - accuracy: 0.9222 - val_loss: 0.4847 - val_accuracy: 0.8000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1666 - accuracy: 0.9167 - val_loss: 0.5121 - val_accuracy: 0.8000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1588 - accuracy: 0.9333 - val_loss: 0.5543 - val_accuracy: 0.7500\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1731 - accuracy: 0.9333 - val_loss: 0.5750 - val_accuracy: 0.7500\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1675 - accuracy: 0.9389 - val_loss: 0.5515 - val_accuracy: 0.7000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1743 - accuracy: 0.9278 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1601 - accuracy: 0.9500 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1553 - accuracy: 0.9278 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1666 - accuracy: 0.9500 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1641 - accuracy: 0.9389 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1415 - accuracy: 0.9611 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1439 - accuracy: 0.9444 - val_loss: 0.5629 - val_accuracy: 0.7000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1520 - accuracy: 0.9389 - val_loss: 0.5981 - val_accuracy: 0.7500\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1477 - accuracy: 0.9500 - val_loss: 0.6082 - val_accuracy: 0.7500\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1425 - accuracy: 0.9500 - val_loss: 0.5866 - val_accuracy: 0.7500\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1559 - accuracy: 0.9500 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1577 - accuracy: 0.9222 - val_loss: 0.5276 - val_accuracy: 0.8000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1522 - accuracy: 0.9389 - val_loss: 0.5089 - val_accuracy: 0.8000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1463 - accuracy: 0.9611 - val_loss: 0.5000 - val_accuracy: 0.8000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1606 - accuracy: 0.9333 - val_loss: 0.5023 - val_accuracy: 0.8000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1519 - accuracy: 0.9389 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1417 - accuracy: 0.9333 - val_loss: 0.5757 - val_accuracy: 0.7500\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1430 - accuracy: 0.9389 - val_loss: 0.6078 - val_accuracy: 0.7500\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1292 - accuracy: 0.9389 - val_loss: 0.6088 - val_accuracy: 0.7500\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1466 - accuracy: 0.9389 - val_loss: 0.6108 - val_accuracy: 0.7000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1376 - accuracy: 0.9444 - val_loss: 0.6022 - val_accuracy: 0.7500\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1424 - accuracy: 0.9278 - val_loss: 0.5928 - val_accuracy: 0.7500\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1284 - accuracy: 0.9500 - val_loss: 0.5651 - val_accuracy: 0.7500\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1605 - accuracy: 0.9500 - val_loss: 0.5206 - val_accuracy: 0.8000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1570 - accuracy: 0.9333 - val_loss: 0.4989 - val_accuracy: 0.8000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1422 - accuracy: 0.9389 - val_loss: 0.5009 - val_accuracy: 0.8000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1581 - accuracy: 0.9167 - val_loss: 0.5356 - val_accuracy: 0.8000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1366 - accuracy: 0.9500 - val_loss: 0.5896 - val_accuracy: 0.7500\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1253 - accuracy: 0.9556 - val_loss: 0.6052 - val_accuracy: 0.7500\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1317 - accuracy: 0.9389 - val_loss: 0.5841 - val_accuracy: 0.7500\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1535 - accuracy: 0.9444 - val_loss: 0.5679 - val_accuracy: 0.7500\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1326 - accuracy: 0.9556 - val_loss: 0.5558 - val_accuracy: 0.7000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1236 - accuracy: 0.9556 - val_loss: 0.5537 - val_accuracy: 0.7000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1192 - accuracy: 0.9556 - val_loss: 0.5612 - val_accuracy: 0.7500\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1436 - accuracy: 0.9333 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1660 - accuracy: 0.9056 - val_loss: 0.5033 - val_accuracy: 0.8000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1353 - accuracy: 0.9333 - val_loss: 0.5048 - val_accuracy: 0.8000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1483 - accuracy: 0.9333 - val_loss: 0.5273 - val_accuracy: 0.8000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1125 - accuracy: 0.9556 - val_loss: 0.5648 - val_accuracy: 0.7000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0998 - accuracy: 0.9778 - val_loss: 0.6052 - val_accuracy: 0.7000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1383 - accuracy: 0.9611 - val_loss: 0.6027 - val_accuracy: 0.7000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1228 - accuracy: 0.9556 - val_loss: 0.5947 - val_accuracy: 0.7000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1121 - accuracy: 0.9500 - val_loss: 0.5823 - val_accuracy: 0.7000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1373 - accuracy: 0.9500 - val_loss: 0.5768 - val_accuracy: 0.7000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1228 - accuracy: 0.9556 - val_loss: 0.5831 - val_accuracy: 0.7500\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1343 - accuracy: 0.9556 - val_loss: 0.5946 - val_accuracy: 0.7500\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1453 - accuracy: 0.9556 - val_loss: 0.6004 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "------------------- TRY 3 ----------------------------\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 15:32:36.635737: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_53/dropout_53/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 1.6215 - accuracy: 0.1389 - val_loss: 1.5779 - val_accuracy: 0.2000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5917 - accuracy: 0.2000 - val_loss: 1.4558 - val_accuracy: 0.3000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.4893 - accuracy: 0.3500 - val_loss: 1.3919 - val_accuracy: 0.4000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4393 - accuracy: 0.4167 - val_loss: 1.3377 - val_accuracy: 0.5500\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3966 - accuracy: 0.4389 - val_loss: 1.2932 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3525 - accuracy: 0.4667 - val_loss: 1.2645 - val_accuracy: 0.5500\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3078 - accuracy: 0.5278 - val_loss: 1.2409 - val_accuracy: 0.4500\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2751 - accuracy: 0.6222 - val_loss: 1.2118 - val_accuracy: 0.5500\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2492 - accuracy: 0.6056 - val_loss: 1.1787 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2014 - accuracy: 0.6667 - val_loss: 1.1469 - val_accuracy: 0.4500\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1740 - accuracy: 0.5944 - val_loss: 1.1180 - val_accuracy: 0.5500\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1465 - accuracy: 0.6278 - val_loss: 1.0915 - val_accuracy: 0.7000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1253 - accuracy: 0.6778 - val_loss: 1.0674 - val_accuracy: 0.7000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0903 - accuracy: 0.7167 - val_loss: 1.0458 - val_accuracy: 0.6000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0667 - accuracy: 0.7389 - val_loss: 1.0267 - val_accuracy: 0.6500\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0422 - accuracy: 0.7889 - val_loss: 1.0076 - val_accuracy: 0.6500\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0107 - accuracy: 0.7722 - val_loss: 0.9871 - val_accuracy: 0.6500\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9866 - accuracy: 0.7333 - val_loss: 0.9630 - val_accuracy: 0.7000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9715 - accuracy: 0.7944 - val_loss: 0.9346 - val_accuracy: 0.6000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9277 - accuracy: 0.7778 - val_loss: 0.9052 - val_accuracy: 0.6500\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9127 - accuracy: 0.7444 - val_loss: 0.8764 - val_accuracy: 0.6500\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8818 - accuracy: 0.7167 - val_loss: 0.8500 - val_accuracy: 0.6500\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8639 - accuracy: 0.7611 - val_loss: 0.8298 - val_accuracy: 0.6500\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8270 - accuracy: 0.7667 - val_loss: 0.8160 - val_accuracy: 0.6500\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8136 - accuracy: 0.7611 - val_loss: 0.8006 - val_accuracy: 0.7500\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7909 - accuracy: 0.7611 - val_loss: 0.7807 - val_accuracy: 0.6500\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7683 - accuracy: 0.7444 - val_loss: 0.7623 - val_accuracy: 0.6500\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7415 - accuracy: 0.7500 - val_loss: 0.7384 - val_accuracy: 0.6500\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7135 - accuracy: 0.7444 - val_loss: 0.7180 - val_accuracy: 0.7500\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7019 - accuracy: 0.7889 - val_loss: 0.7040 - val_accuracy: 0.7500\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7052 - accuracy: 0.7556 - val_loss: 0.6859 - val_accuracy: 0.7500\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6800 - accuracy: 0.7889 - val_loss: 0.6767 - val_accuracy: 0.7000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6650 - accuracy: 0.7500 - val_loss: 0.6734 - val_accuracy: 0.7500\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6311 - accuracy: 0.7722 - val_loss: 0.6603 - val_accuracy: 0.7500\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6422 - accuracy: 0.7833 - val_loss: 0.6420 - val_accuracy: 0.7500\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6470 - accuracy: 0.7667 - val_loss: 0.6293 - val_accuracy: 0.7500\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6318 - accuracy: 0.7889 - val_loss: 0.6211 - val_accuracy: 0.8000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6147 - accuracy: 0.8167 - val_loss: 0.6202 - val_accuracy: 0.7500\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5898 - accuracy: 0.8389 - val_loss: 0.6100 - val_accuracy: 0.8500\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5635 - accuracy: 0.8222 - val_loss: 0.6068 - val_accuracy: 0.8000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5716 - accuracy: 0.8167 - val_loss: 0.5954 - val_accuracy: 0.8000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5841 - accuracy: 0.7444 - val_loss: 0.5813 - val_accuracy: 0.8000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5470 - accuracy: 0.8111 - val_loss: 0.5650 - val_accuracy: 0.8000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5526 - accuracy: 0.8000 - val_loss: 0.5539 - val_accuracy: 0.8500\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5170 - accuracy: 0.8222 - val_loss: 0.5531 - val_accuracy: 0.8000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5266 - accuracy: 0.8000 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4990 - accuracy: 0.8111 - val_loss: 0.5569 - val_accuracy: 0.7500\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4964 - accuracy: 0.8222 - val_loss: 0.5545 - val_accuracy: 0.7500\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5154 - accuracy: 0.8278 - val_loss: 0.5457 - val_accuracy: 0.8500\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4723 - accuracy: 0.8444 - val_loss: 0.5365 - val_accuracy: 0.8000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4800 - accuracy: 0.8278 - val_loss: 0.5289 - val_accuracy: 0.8500\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4634 - accuracy: 0.8500 - val_loss: 0.5214 - val_accuracy: 0.8500\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4610 - accuracy: 0.8444 - val_loss: 0.5310 - val_accuracy: 0.8500\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4618 - accuracy: 0.8333 - val_loss: 0.5321 - val_accuracy: 0.8500\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4722 - accuracy: 0.8278 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4398 - accuracy: 0.8556 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4285 - accuracy: 0.8722 - val_loss: 0.5217 - val_accuracy: 0.8500\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4154 - accuracy: 0.8667 - val_loss: 0.5206 - val_accuracy: 0.8500\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4172 - accuracy: 0.8611 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3973 - accuracy: 0.8944 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4117 - accuracy: 0.8611 - val_loss: 0.4939 - val_accuracy: 0.8000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4148 - accuracy: 0.8667 - val_loss: 0.5022 - val_accuracy: 0.7500\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3681 - accuracy: 0.9056 - val_loss: 0.5131 - val_accuracy: 0.7500\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3848 - accuracy: 0.8778 - val_loss: 0.5204 - val_accuracy: 0.8000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3591 - accuracy: 0.8611 - val_loss: 0.5081 - val_accuracy: 0.8000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3737 - accuracy: 0.8833 - val_loss: 0.4797 - val_accuracy: 0.8000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3704 - accuracy: 0.8500 - val_loss: 0.4863 - val_accuracy: 0.7500\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3746 - accuracy: 0.8944 - val_loss: 0.4925 - val_accuracy: 0.7500\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3409 - accuracy: 0.8778 - val_loss: 0.4929 - val_accuracy: 0.8000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3634 - accuracy: 0.8778 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3588 - accuracy: 0.8722 - val_loss: 0.4928 - val_accuracy: 0.8000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3164 - accuracy: 0.9167 - val_loss: 0.4956 - val_accuracy: 0.8000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3298 - accuracy: 0.8722 - val_loss: 0.5018 - val_accuracy: 0.8500\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3396 - accuracy: 0.8722 - val_loss: 0.4893 - val_accuracy: 0.8000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3235 - accuracy: 0.9000 - val_loss: 0.4796 - val_accuracy: 0.8000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3170 - accuracy: 0.8833 - val_loss: 0.4751 - val_accuracy: 0.8000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3112 - accuracy: 0.8889 - val_loss: 0.4842 - val_accuracy: 0.7500\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3235 - accuracy: 0.8722 - val_loss: 0.5018 - val_accuracy: 0.8500\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3273 - accuracy: 0.8833 - val_loss: 0.5003 - val_accuracy: 0.8500\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3023 - accuracy: 0.8833 - val_loss: 0.5003 - val_accuracy: 0.8000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2902 - accuracy: 0.8778 - val_loss: 0.4875 - val_accuracy: 0.8000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3174 - accuracy: 0.8833 - val_loss: 0.4775 - val_accuracy: 0.8000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2920 - accuracy: 0.9056 - val_loss: 0.4730 - val_accuracy: 0.7500\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2749 - accuracy: 0.9167 - val_loss: 0.4783 - val_accuracy: 0.7500\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2891 - accuracy: 0.8889 - val_loss: 0.4822 - val_accuracy: 0.8000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2728 - accuracy: 0.9111 - val_loss: 0.4953 - val_accuracy: 0.8000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2716 - accuracy: 0.9278 - val_loss: 0.4877 - val_accuracy: 0.8000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2517 - accuracy: 0.9333 - val_loss: 0.4785 - val_accuracy: 0.8500\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2479 - accuracy: 0.9333 - val_loss: 0.4739 - val_accuracy: 0.9000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2500 - accuracy: 0.9000 - val_loss: 0.4679 - val_accuracy: 0.8500\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2456 - accuracy: 0.9111 - val_loss: 0.4726 - val_accuracy: 0.8500\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2508 - accuracy: 0.8944 - val_loss: 0.4817 - val_accuracy: 0.8500\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2670 - accuracy: 0.9000 - val_loss: 0.4832 - val_accuracy: 0.8000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2541 - accuracy: 0.9278 - val_loss: 0.4842 - val_accuracy: 0.7500\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2474 - accuracy: 0.9222 - val_loss: 0.4743 - val_accuracy: 0.7500\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2240 - accuracy: 0.9278 - val_loss: 0.4573 - val_accuracy: 0.8000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2177 - accuracy: 0.9333 - val_loss: 0.4537 - val_accuracy: 0.8500\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2224 - accuracy: 0.9278 - val_loss: 0.4653 - val_accuracy: 0.8500\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2426 - accuracy: 0.9111 - val_loss: 0.4800 - val_accuracy: 0.8500\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2050 - accuracy: 0.9389 - val_loss: 0.4790 - val_accuracy: 0.8000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2012 - accuracy: 0.9389 - val_loss: 0.4670 - val_accuracy: 0.8000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2292 - accuracy: 0.9111 - val_loss: 0.4537 - val_accuracy: 0.8000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2265 - accuracy: 0.9056 - val_loss: 0.4429 - val_accuracy: 0.8500\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2225 - accuracy: 0.9111 - val_loss: 0.4428 - val_accuracy: 0.8000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1723 - accuracy: 0.9556 - val_loss: 0.4487 - val_accuracy: 0.8000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2001 - accuracy: 0.9222 - val_loss: 0.4646 - val_accuracy: 0.8000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2160 - accuracy: 0.9222 - val_loss: 0.4640 - val_accuracy: 0.8000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2145 - accuracy: 0.9222 - val_loss: 0.4559 - val_accuracy: 0.8000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1893 - accuracy: 0.9500 - val_loss: 0.4462 - val_accuracy: 0.8000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2014 - accuracy: 0.9278 - val_loss: 0.4500 - val_accuracy: 0.8000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1926 - accuracy: 0.9167 - val_loss: 0.4490 - val_accuracy: 0.8000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1871 - accuracy: 0.9389 - val_loss: 0.4477 - val_accuracy: 0.8000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2002 - accuracy: 0.9389 - val_loss: 0.4564 - val_accuracy: 0.7500\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1781 - accuracy: 0.9333 - val_loss: 0.4611 - val_accuracy: 0.7500\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1960 - accuracy: 0.9167 - val_loss: 0.4622 - val_accuracy: 0.8000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1802 - accuracy: 0.9444 - val_loss: 0.4673 - val_accuracy: 0.8000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1717 - accuracy: 0.9500 - val_loss: 0.4687 - val_accuracy: 0.8000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2042 - accuracy: 0.9222 - val_loss: 0.4435 - val_accuracy: 0.8000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1799 - accuracy: 0.9333 - val_loss: 0.4372 - val_accuracy: 0.8000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1701 - accuracy: 0.9500 - val_loss: 0.4458 - val_accuracy: 0.8000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1535 - accuracy: 0.9444 - val_loss: 0.4457 - val_accuracy: 0.8500\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1699 - accuracy: 0.9389 - val_loss: 0.4320 - val_accuracy: 0.8000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1616 - accuracy: 0.9222 - val_loss: 0.4285 - val_accuracy: 0.8000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1619 - accuracy: 0.9333 - val_loss: 0.4442 - val_accuracy: 0.8000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1513 - accuracy: 0.9611 - val_loss: 0.4664 - val_accuracy: 0.8000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1915 - accuracy: 0.9389 - val_loss: 0.4658 - val_accuracy: 0.8000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1687 - accuracy: 0.9389 - val_loss: 0.4746 - val_accuracy: 0.8000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1668 - accuracy: 0.9444 - val_loss: 0.4558 - val_accuracy: 0.8000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1820 - accuracy: 0.9167 - val_loss: 0.4297 - val_accuracy: 0.8000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1514 - accuracy: 0.9444 - val_loss: 0.4194 - val_accuracy: 0.8000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1573 - accuracy: 0.9444 - val_loss: 0.4205 - val_accuracy: 0.8500\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1547 - accuracy: 0.9389 - val_loss: 0.4254 - val_accuracy: 0.8000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1571 - accuracy: 0.9333 - val_loss: 0.4450 - val_accuracy: 0.8000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1479 - accuracy: 0.9444 - val_loss: 0.4694 - val_accuracy: 0.8000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1595 - accuracy: 0.9222 - val_loss: 0.4748 - val_accuracy: 0.8000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1564 - accuracy: 0.9500 - val_loss: 0.4666 - val_accuracy: 0.8000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1652 - accuracy: 0.9389 - val_loss: 0.4492 - val_accuracy: 0.8000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1573 - accuracy: 0.9389 - val_loss: 0.4377 - val_accuracy: 0.8000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1524 - accuracy: 0.9111 - val_loss: 0.4373 - val_accuracy: 0.8000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1311 - accuracy: 0.9611 - val_loss: 0.4458 - val_accuracy: 0.8000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1442 - accuracy: 0.9500 - val_loss: 0.4467 - val_accuracy: 0.8000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1385 - accuracy: 0.9444 - val_loss: 0.4398 - val_accuracy: 0.8000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1383 - accuracy: 0.9389 - val_loss: 0.4376 - val_accuracy: 0.8000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1514 - accuracy: 0.9333 - val_loss: 0.4405 - val_accuracy: 0.8000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1485 - accuracy: 0.9444 - val_loss: 0.4450 - val_accuracy: 0.8000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1514 - accuracy: 0.9222 - val_loss: 0.4413 - val_accuracy: 0.8000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1217 - accuracy: 0.9444 - val_loss: 0.4382 - val_accuracy: 0.8500\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1487 - accuracy: 0.9333 - val_loss: 0.4415 - val_accuracy: 0.8000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1215 - accuracy: 0.9667 - val_loss: 0.4442 - val_accuracy: 0.7500\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1536 - accuracy: 0.9444 - val_loss: 0.4410 - val_accuracy: 0.7500\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1532 - accuracy: 0.9167 - val_loss: 0.4367 - val_accuracy: 0.8000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1558 - accuracy: 0.9278 - val_loss: 0.4365 - val_accuracy: 0.8000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1335 - accuracy: 0.9500 - val_loss: 0.4406 - val_accuracy: 0.8500\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1297 - accuracy: 0.9556 - val_loss: 0.4471 - val_accuracy: 0.8500\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1518 - accuracy: 0.9389 - val_loss: 0.4490 - val_accuracy: 0.8500\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1429 - accuracy: 0.9389 - val_loss: 0.4477 - val_accuracy: 0.8000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1285 - accuracy: 0.9500 - val_loss: 0.4503 - val_accuracy: 0.8000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1312 - accuracy: 0.9389 - val_loss: 0.4583 - val_accuracy: 0.8000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1393 - accuracy: 0.9278 - val_loss: 0.4469 - val_accuracy: 0.8000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1262 - accuracy: 0.9667 - val_loss: 0.4341 - val_accuracy: 0.8000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1545 - accuracy: 0.9111 - val_loss: 0.4338 - val_accuracy: 0.8000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1191 - accuracy: 0.9389 - val_loss: 0.4408 - val_accuracy: 0.8000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1070 - accuracy: 0.9778 - val_loss: 0.4500 - val_accuracy: 0.8000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1228 - accuracy: 0.9500 - val_loss: 0.4748 - val_accuracy: 0.8000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1334 - accuracy: 0.9333 - val_loss: 0.4876 - val_accuracy: 0.8000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1204 - accuracy: 0.9611 - val_loss: 0.4801 - val_accuracy: 0.8000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1301 - accuracy: 0.9278 - val_loss: 0.4581 - val_accuracy: 0.8000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1238 - accuracy: 0.9556 - val_loss: 0.4402 - val_accuracy: 0.8500\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1479 - accuracy: 0.9333 - val_loss: 0.4234 - val_accuracy: 0.8000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1403 - accuracy: 0.9222 - val_loss: 0.4185 - val_accuracy: 0.8000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1387 - accuracy: 0.9278 - val_loss: 0.4316 - val_accuracy: 0.8000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1228 - accuracy: 0.9500 - val_loss: 0.4481 - val_accuracy: 0.8000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1273 - accuracy: 0.9444 - val_loss: 0.4530 - val_accuracy: 0.8000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1188 - accuracy: 0.9667 - val_loss: 0.4555 - val_accuracy: 0.8500\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1127 - accuracy: 0.9667 - val_loss: 0.4552 - val_accuracy: 0.8500\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1101 - accuracy: 0.9444 - val_loss: 0.4497 - val_accuracy: 0.8500\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1115 - accuracy: 0.9500 - val_loss: 0.4418 - val_accuracy: 0.8000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1330 - accuracy: 0.9444 - val_loss: 0.4532 - val_accuracy: 0.8000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1167 - accuracy: 0.9389 - val_loss: 0.4701 - val_accuracy: 0.8000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1303 - accuracy: 0.9444 - val_loss: 0.4710 - val_accuracy: 0.8000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1128 - accuracy: 0.9444 - val_loss: 0.4553 - val_accuracy: 0.8000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1282 - accuracy: 0.9389 - val_loss: 0.4528 - val_accuracy: 0.8000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1217 - accuracy: 0.9389 - val_loss: 0.4571 - val_accuracy: 0.8500\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1257 - accuracy: 0.9556 - val_loss: 0.4613 - val_accuracy: 0.8500\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1095 - accuracy: 0.9444 - val_loss: 0.4665 - val_accuracy: 0.8000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1120 - accuracy: 0.9500 - val_loss: 0.4692 - val_accuracy: 0.8000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1214 - accuracy: 0.9444 - val_loss: 0.4797 - val_accuracy: 0.8000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1320 - accuracy: 0.9333 - val_loss: 0.4753 - val_accuracy: 0.8000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1102 - accuracy: 0.9500 - val_loss: 0.4611 - val_accuracy: 0.8000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1339 - accuracy: 0.9389 - val_loss: 0.4542 - val_accuracy: 0.8000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1150 - accuracy: 0.9556 - val_loss: 0.4533 - val_accuracy: 0.8000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1227 - accuracy: 0.9556 - val_loss: 0.4556 - val_accuracy: 0.8000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1247 - accuracy: 0.9222 - val_loss: 0.4627 - val_accuracy: 0.8000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1068 - accuracy: 0.9556 - val_loss: 0.4685 - val_accuracy: 0.8000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1115 - accuracy: 0.9556 - val_loss: 0.4645 - val_accuracy: 0.8000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1262 - accuracy: 0.9444 - val_loss: 0.4482 - val_accuracy: 0.8000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1414 - accuracy: 0.9278 - val_loss: 0.4337 - val_accuracy: 0.8000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1222 - accuracy: 0.9389 - val_loss: 0.4313 - val_accuracy: 0.8500\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1378 - accuracy: 0.9333 - val_loss: 0.4322 - val_accuracy: 0.8500\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1134 - accuracy: 0.9556 - val_loss: 0.4351 - val_accuracy: 0.8500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "------------------- TRY 4 ----------------------------\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 15:32:46.462815: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_54/dropout_54/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 1.6098 - accuracy: 0.1444 - val_loss: 1.5397 - val_accuracy: 0.2000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5555 - accuracy: 0.2167 - val_loss: 1.4769 - val_accuracy: 0.2000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5053 - accuracy: 0.2278 - val_loss: 1.4146 - val_accuracy: 0.4500\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4543 - accuracy: 0.4167 - val_loss: 1.3576 - val_accuracy: 0.4500\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4033 - accuracy: 0.4944 - val_loss: 1.3057 - val_accuracy: 0.4500\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3458 - accuracy: 0.5500 - val_loss: 1.2601 - val_accuracy: 0.4500\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3050 - accuracy: 0.5111 - val_loss: 1.2218 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2639 - accuracy: 0.5667 - val_loss: 1.1895 - val_accuracy: 0.5500\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2323 - accuracy: 0.6056 - val_loss: 1.1610 - val_accuracy: 0.6000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2011 - accuracy: 0.6333 - val_loss: 1.1340 - val_accuracy: 0.7000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1553 - accuracy: 0.7167 - val_loss: 1.1064 - val_accuracy: 0.7000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1275 - accuracy: 0.7611 - val_loss: 1.0800 - val_accuracy: 0.6000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0987 - accuracy: 0.7611 - val_loss: 1.0527 - val_accuracy: 0.6500\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0600 - accuracy: 0.7556 - val_loss: 1.0247 - val_accuracy: 0.6500\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0443 - accuracy: 0.7444 - val_loss: 0.9991 - val_accuracy: 0.7000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9955 - accuracy: 0.7333 - val_loss: 0.9727 - val_accuracy: 0.6500\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9818 - accuracy: 0.7556 - val_loss: 0.9464 - val_accuracy: 0.6500\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9570 - accuracy: 0.7500 - val_loss: 0.9203 - val_accuracy: 0.6000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9218 - accuracy: 0.7333 - val_loss: 0.8943 - val_accuracy: 0.6000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8975 - accuracy: 0.7833 - val_loss: 0.8663 - val_accuracy: 0.6500\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8629 - accuracy: 0.7389 - val_loss: 0.8391 - val_accuracy: 0.6500\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8543 - accuracy: 0.7611 - val_loss: 0.8143 - val_accuracy: 0.6500\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8048 - accuracy: 0.7611 - val_loss: 0.7929 - val_accuracy: 0.6500\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7914 - accuracy: 0.7667 - val_loss: 0.7665 - val_accuracy: 0.6500\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7807 - accuracy: 0.7333 - val_loss: 0.7438 - val_accuracy: 0.6500\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7623 - accuracy: 0.7611 - val_loss: 0.7238 - val_accuracy: 0.7500\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7571 - accuracy: 0.7722 - val_loss: 0.7023 - val_accuracy: 0.7000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7009 - accuracy: 0.7944 - val_loss: 0.6880 - val_accuracy: 0.7000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7140 - accuracy: 0.7278 - val_loss: 0.6881 - val_accuracy: 0.7000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6950 - accuracy: 0.7167 - val_loss: 0.6534 - val_accuracy: 0.7500\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6501 - accuracy: 0.7944 - val_loss: 0.6444 - val_accuracy: 0.7500\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6748 - accuracy: 0.7500 - val_loss: 0.6360 - val_accuracy: 0.7000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6515 - accuracy: 0.7833 - val_loss: 0.6350 - val_accuracy: 0.7500\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6319 - accuracy: 0.8000 - val_loss: 0.6419 - val_accuracy: 0.7500\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6269 - accuracy: 0.7667 - val_loss: 0.6130 - val_accuracy: 0.8000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6190 - accuracy: 0.7778 - val_loss: 0.5984 - val_accuracy: 0.7000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6314 - accuracy: 0.7833 - val_loss: 0.5970 - val_accuracy: 0.7500\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5783 - accuracy: 0.8167 - val_loss: 0.6029 - val_accuracy: 0.8000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5819 - accuracy: 0.8167 - val_loss: 0.6187 - val_accuracy: 0.7500\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5989 - accuracy: 0.7333 - val_loss: 0.6194 - val_accuracy: 0.7500\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5695 - accuracy: 0.7778 - val_loss: 0.6002 - val_accuracy: 0.8000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5704 - accuracy: 0.8111 - val_loss: 0.6030 - val_accuracy: 0.7000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5930 - accuracy: 0.7778 - val_loss: 0.5835 - val_accuracy: 0.8000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5347 - accuracy: 0.8167 - val_loss: 0.5659 - val_accuracy: 0.8000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8278 - val_loss: 0.5768 - val_accuracy: 0.7500\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5016 - accuracy: 0.8611 - val_loss: 0.5834 - val_accuracy: 0.7500\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5050 - accuracy: 0.8000 - val_loss: 0.5833 - val_accuracy: 0.8000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5048 - accuracy: 0.8222 - val_loss: 0.5709 - val_accuracy: 0.8000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5253 - accuracy: 0.8056 - val_loss: 0.5649 - val_accuracy: 0.7500\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5171 - accuracy: 0.8056 - val_loss: 0.5616 - val_accuracy: 0.8000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4847 - accuracy: 0.8389 - val_loss: 0.5669 - val_accuracy: 0.8000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4862 - accuracy: 0.8222 - val_loss: 0.5661 - val_accuracy: 0.7500\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4485 - accuracy: 0.8500 - val_loss: 0.5604 - val_accuracy: 0.7500\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4705 - accuracy: 0.8278 - val_loss: 0.5400 - val_accuracy: 0.8000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4457 - accuracy: 0.8667 - val_loss: 0.5288 - val_accuracy: 0.8000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4323 - accuracy: 0.8500 - val_loss: 0.5284 - val_accuracy: 0.7500\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4088 - accuracy: 0.8667 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4492 - accuracy: 0.8500 - val_loss: 0.5301 - val_accuracy: 0.8000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4274 - accuracy: 0.8667 - val_loss: 0.5178 - val_accuracy: 0.8000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4002 - accuracy: 0.8722 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3992 - accuracy: 0.8722 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4094 - accuracy: 0.8556 - val_loss: 0.5234 - val_accuracy: 0.8000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4142 - accuracy: 0.8722 - val_loss: 0.5065 - val_accuracy: 0.8000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4141 - accuracy: 0.8611 - val_loss: 0.5060 - val_accuracy: 0.8000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4066 - accuracy: 0.8333 - val_loss: 0.5038 - val_accuracy: 0.8000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3855 - accuracy: 0.8333 - val_loss: 0.5076 - val_accuracy: 0.8000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3864 - accuracy: 0.8611 - val_loss: 0.5096 - val_accuracy: 0.8000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3761 - accuracy: 0.8722 - val_loss: 0.5249 - val_accuracy: 0.8500\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3516 - accuracy: 0.8556 - val_loss: 0.5152 - val_accuracy: 0.8500\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3657 - accuracy: 0.8667 - val_loss: 0.4908 - val_accuracy: 0.8500\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3777 - accuracy: 0.8444 - val_loss: 0.4886 - val_accuracy: 0.8000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3419 - accuracy: 0.8889 - val_loss: 0.5037 - val_accuracy: 0.8000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3539 - accuracy: 0.8833 - val_loss: 0.5226 - val_accuracy: 0.8000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3447 - accuracy: 0.8944 - val_loss: 0.5097 - val_accuracy: 0.8000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3258 - accuracy: 0.9111 - val_loss: 0.4989 - val_accuracy: 0.8000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3653 - accuracy: 0.8667 - val_loss: 0.4942 - val_accuracy: 0.8000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3253 - accuracy: 0.8833 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3124 - accuracy: 0.8722 - val_loss: 0.5333 - val_accuracy: 0.8000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2976 - accuracy: 0.9111 - val_loss: 0.5219 - val_accuracy: 0.8000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3393 - accuracy: 0.8833 - val_loss: 0.5016 - val_accuracy: 0.8500\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2961 - accuracy: 0.9222 - val_loss: 0.4941 - val_accuracy: 0.8500\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3124 - accuracy: 0.8889 - val_loss: 0.4988 - val_accuracy: 0.8500\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3163 - accuracy: 0.8778 - val_loss: 0.5125 - val_accuracy: 0.8500\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2857 - accuracy: 0.9056 - val_loss: 0.5296 - val_accuracy: 0.8500\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3168 - accuracy: 0.8833 - val_loss: 0.5200 - val_accuracy: 0.8000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2907 - accuracy: 0.8889 - val_loss: 0.5084 - val_accuracy: 0.8000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2865 - accuracy: 0.9000 - val_loss: 0.5207 - val_accuracy: 0.8000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2908 - accuracy: 0.8778 - val_loss: 0.5266 - val_accuracy: 0.8000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2872 - accuracy: 0.8944 - val_loss: 0.5352 - val_accuracy: 0.8000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2571 - accuracy: 0.9222 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2620 - accuracy: 0.9111 - val_loss: 0.5274 - val_accuracy: 0.7500\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2696 - accuracy: 0.9167 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2497 - accuracy: 0.9056 - val_loss: 0.5148 - val_accuracy: 0.8000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2609 - accuracy: 0.9000 - val_loss: 0.5125 - val_accuracy: 0.8000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2653 - accuracy: 0.9222 - val_loss: 0.5170 - val_accuracy: 0.8000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2561 - accuracy: 0.9167 - val_loss: 0.5213 - val_accuracy: 0.8500\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2679 - accuracy: 0.9000 - val_loss: 0.5371 - val_accuracy: 0.8500\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2621 - accuracy: 0.9111 - val_loss: 0.5432 - val_accuracy: 0.8500\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2647 - accuracy: 0.8944 - val_loss: 0.5392 - val_accuracy: 0.8000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2556 - accuracy: 0.9111 - val_loss: 0.5288 - val_accuracy: 0.8000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2371 - accuracy: 0.9333 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2303 - accuracy: 0.9167 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2139 - accuracy: 0.9444 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2402 - accuracy: 0.9111 - val_loss: 0.5345 - val_accuracy: 0.7500\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2144 - accuracy: 0.9500 - val_loss: 0.5508 - val_accuracy: 0.8500\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2232 - accuracy: 0.9111 - val_loss: 0.5411 - val_accuracy: 0.8500\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2322 - accuracy: 0.9333 - val_loss: 0.5295 - val_accuracy: 0.8000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2225 - accuracy: 0.9167 - val_loss: 0.5276 - val_accuracy: 0.8000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2199 - accuracy: 0.9500 - val_loss: 0.5172 - val_accuracy: 0.8000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2238 - accuracy: 0.9167 - val_loss: 0.5119 - val_accuracy: 0.8000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2326 - accuracy: 0.9167 - val_loss: 0.5274 - val_accuracy: 0.8500\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2358 - accuracy: 0.9278 - val_loss: 0.5373 - val_accuracy: 0.8000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2256 - accuracy: 0.9056 - val_loss: 0.5556 - val_accuracy: 0.8000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1957 - accuracy: 0.9611 - val_loss: 0.5533 - val_accuracy: 0.8000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1918 - accuracy: 0.9444 - val_loss: 0.5378 - val_accuracy: 0.8000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1846 - accuracy: 0.9444 - val_loss: 0.5285 - val_accuracy: 0.8000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2073 - accuracy: 0.9056 - val_loss: 0.5345 - val_accuracy: 0.8000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2095 - accuracy: 0.9167 - val_loss: 0.5366 - val_accuracy: 0.8500\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1944 - accuracy: 0.9444 - val_loss: 0.5467 - val_accuracy: 0.8000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1787 - accuracy: 0.9333 - val_loss: 0.5500 - val_accuracy: 0.8000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2024 - accuracy: 0.9389 - val_loss: 0.5324 - val_accuracy: 0.8000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2001 - accuracy: 0.9278 - val_loss: 0.5213 - val_accuracy: 0.8000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1896 - accuracy: 0.9278 - val_loss: 0.5226 - val_accuracy: 0.8500\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1953 - accuracy: 0.9278 - val_loss: 0.5353 - val_accuracy: 0.8500\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1749 - accuracy: 0.9389 - val_loss: 0.5503 - val_accuracy: 0.8000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1684 - accuracy: 0.9444 - val_loss: 0.5751 - val_accuracy: 0.8000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1688 - accuracy: 0.9556 - val_loss: 0.5835 - val_accuracy: 0.7500\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1992 - accuracy: 0.9389 - val_loss: 0.5688 - val_accuracy: 0.8000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1925 - accuracy: 0.9500 - val_loss: 0.5663 - val_accuracy: 0.8000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1852 - accuracy: 0.9111 - val_loss: 0.5682 - val_accuracy: 0.8000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1792 - accuracy: 0.9278 - val_loss: 0.5597 - val_accuracy: 0.7500\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1672 - accuracy: 0.9444 - val_loss: 0.5713 - val_accuracy: 0.8000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1940 - accuracy: 0.9167 - val_loss: 0.5850 - val_accuracy: 0.8000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2126 - accuracy: 0.9111 - val_loss: 0.5739 - val_accuracy: 0.8000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1938 - accuracy: 0.9167 - val_loss: 0.5661 - val_accuracy: 0.8000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1731 - accuracy: 0.9389 - val_loss: 0.5801 - val_accuracy: 0.7500\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1696 - accuracy: 0.9389 - val_loss: 0.5922 - val_accuracy: 0.7500\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1809 - accuracy: 0.9500 - val_loss: 0.5958 - val_accuracy: 0.8000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1585 - accuracy: 0.9500 - val_loss: 0.5897 - val_accuracy: 0.8000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1699 - accuracy: 0.9389 - val_loss: 0.5885 - val_accuracy: 0.8000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1709 - accuracy: 0.9278 - val_loss: 0.5796 - val_accuracy: 0.8000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1690 - accuracy: 0.9167 - val_loss: 0.5769 - val_accuracy: 0.8000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1761 - accuracy: 0.9333 - val_loss: 0.5816 - val_accuracy: 0.8000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1588 - accuracy: 0.9278 - val_loss: 0.5913 - val_accuracy: 0.8000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1592 - accuracy: 0.9278 - val_loss: 0.5977 - val_accuracy: 0.8000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1559 - accuracy: 0.9444 - val_loss: 0.5952 - val_accuracy: 0.8000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1463 - accuracy: 0.9556 - val_loss: 0.5857 - val_accuracy: 0.8000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1633 - accuracy: 0.9167 - val_loss: 0.5832 - val_accuracy: 0.8000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1597 - accuracy: 0.9389 - val_loss: 0.5867 - val_accuracy: 0.8000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1599 - accuracy: 0.9389 - val_loss: 0.5900 - val_accuracy: 0.8000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1330 - accuracy: 0.9556 - val_loss: 0.5931 - val_accuracy: 0.8000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1564 - accuracy: 0.9222 - val_loss: 0.6039 - val_accuracy: 0.8500\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1283 - accuracy: 0.9667 - val_loss: 0.6139 - val_accuracy: 0.8500\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1610 - accuracy: 0.9389 - val_loss: 0.6148 - val_accuracy: 0.8500\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1587 - accuracy: 0.9222 - val_loss: 0.6113 - val_accuracy: 0.8000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1495 - accuracy: 0.9389 - val_loss: 0.5875 - val_accuracy: 0.8000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1297 - accuracy: 0.9611 - val_loss: 0.5689 - val_accuracy: 0.8000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1557 - accuracy: 0.9278 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1709 - accuracy: 0.9111 - val_loss: 0.5617 - val_accuracy: 0.8000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1458 - accuracy: 0.9389 - val_loss: 0.5738 - val_accuracy: 0.8000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1445 - accuracy: 0.9500 - val_loss: 0.5987 - val_accuracy: 0.8000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1472 - accuracy: 0.9556 - val_loss: 0.6177 - val_accuracy: 0.8000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1366 - accuracy: 0.9556 - val_loss: 0.6286 - val_accuracy: 0.8500\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1237 - accuracy: 0.9722 - val_loss: 0.6314 - val_accuracy: 0.8500\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1444 - accuracy: 0.9389 - val_loss: 0.6242 - val_accuracy: 0.8500\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1199 - accuracy: 0.9778 - val_loss: 0.6100 - val_accuracy: 0.8500\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1194 - accuracy: 0.9778 - val_loss: 0.5940 - val_accuracy: 0.8000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1244 - accuracy: 0.9500 - val_loss: 0.5829 - val_accuracy: 0.8000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1548 - accuracy: 0.9333 - val_loss: 0.5824 - val_accuracy: 0.8000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1258 - accuracy: 0.9444 - val_loss: 0.5897 - val_accuracy: 0.8000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1412 - accuracy: 0.9333 - val_loss: 0.5993 - val_accuracy: 0.8000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1343 - accuracy: 0.9500 - val_loss: 0.6157 - val_accuracy: 0.8000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1426 - accuracy: 0.9389 - val_loss: 0.6426 - val_accuracy: 0.8500\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1262 - accuracy: 0.9556 - val_loss: 0.6664 - val_accuracy: 0.8500\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1353 - accuracy: 0.9556 - val_loss: 0.6817 - val_accuracy: 0.8500\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1301 - accuracy: 0.9556 - val_loss: 0.6654 - val_accuracy: 0.8500\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1266 - accuracy: 0.9556 - val_loss: 0.6482 - val_accuracy: 0.8000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1315 - accuracy: 0.9333 - val_loss: 0.6204 - val_accuracy: 0.8000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1280 - accuracy: 0.9556 - val_loss: 0.5993 - val_accuracy: 0.8000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1289 - accuracy: 0.9500 - val_loss: 0.5930 - val_accuracy: 0.8000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1284 - accuracy: 0.9444 - val_loss: 0.5926 - val_accuracy: 0.8000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1502 - accuracy: 0.9444 - val_loss: 0.6034 - val_accuracy: 0.8000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1327 - accuracy: 0.9500 - val_loss: 0.6289 - val_accuracy: 0.8000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1421 - accuracy: 0.9333 - val_loss: 0.6647 - val_accuracy: 0.8500\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1378 - accuracy: 0.9444 - val_loss: 0.7006 - val_accuracy: 0.8500\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1527 - accuracy: 0.9278 - val_loss: 0.7250 - val_accuracy: 0.8500\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1226 - accuracy: 0.9611 - val_loss: 0.7226 - val_accuracy: 0.8500\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0995 - accuracy: 0.9667 - val_loss: 0.7131 - val_accuracy: 0.8500\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1380 - accuracy: 0.9333 - val_loss: 0.6796 - val_accuracy: 0.8500\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1450 - accuracy: 0.9278 - val_loss: 0.6414 - val_accuracy: 0.8000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1066 - accuracy: 0.9500 - val_loss: 0.6209 - val_accuracy: 0.8000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1224 - accuracy: 0.9500 - val_loss: 0.6186 - val_accuracy: 0.8000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1300 - accuracy: 0.9389 - val_loss: 0.6188 - val_accuracy: 0.8000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1448 - accuracy: 0.9278 - val_loss: 0.6201 - val_accuracy: 0.8000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1170 - accuracy: 0.9722 - val_loss: 0.6339 - val_accuracy: 0.8000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1261 - accuracy: 0.9556 - val_loss: 0.6565 - val_accuracy: 0.8000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1223 - accuracy: 0.9444 - val_loss: 0.6789 - val_accuracy: 0.8500\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1226 - accuracy: 0.9444 - val_loss: 0.7050 - val_accuracy: 0.8500\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1425 - accuracy: 0.9222 - val_loss: 0.7148 - val_accuracy: 0.8500\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1438 - accuracy: 0.9389 - val_loss: 0.7117 - val_accuracy: 0.8500\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "------------------- TRY 5 ----------------------------\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 15:32:56.108834: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_55/dropout_55/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 1.6204 - accuracy: 0.1889 - val_loss: 1.5735 - val_accuracy: 0.2000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.5949 - accuracy: 0.2000 - val_loss: 1.4382 - val_accuracy: 0.3000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4764 - accuracy: 0.3611 - val_loss: 1.3761 - val_accuracy: 0.4500\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4234 - accuracy: 0.4556 - val_loss: 1.3327 - val_accuracy: 0.4500\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3809 - accuracy: 0.4444 - val_loss: 1.2931 - val_accuracy: 0.4500\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3415 - accuracy: 0.4278 - val_loss: 1.2621 - val_accuracy: 0.4500\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3056 - accuracy: 0.4500 - val_loss: 1.2402 - val_accuracy: 0.4500\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2625 - accuracy: 0.4944 - val_loss: 1.2207 - val_accuracy: 0.3000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2335 - accuracy: 0.3833 - val_loss: 1.1951 - val_accuracy: 0.3000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2124 - accuracy: 0.3889 - val_loss: 1.1644 - val_accuracy: 0.4500\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1755 - accuracy: 0.5611 - val_loss: 1.1345 - val_accuracy: 0.6500\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1553 - accuracy: 0.6444 - val_loss: 1.1086 - val_accuracy: 0.6500\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1154 - accuracy: 0.7111 - val_loss: 1.0829 - val_accuracy: 0.7000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0993 - accuracy: 0.7556 - val_loss: 1.0575 - val_accuracy: 0.6500\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0726 - accuracy: 0.7500 - val_loss: 1.0360 - val_accuracy: 0.6500\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0511 - accuracy: 0.6833 - val_loss: 1.0190 - val_accuracy: 0.7000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0059 - accuracy: 0.7056 - val_loss: 1.0005 - val_accuracy: 0.7000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9971 - accuracy: 0.7500 - val_loss: 0.9775 - val_accuracy: 0.7500\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9699 - accuracy: 0.7667 - val_loss: 0.9504 - val_accuracy: 0.6500\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9292 - accuracy: 0.7111 - val_loss: 0.9166 - val_accuracy: 0.6500\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9207 - accuracy: 0.7556 - val_loss: 0.8834 - val_accuracy: 0.7500\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8889 - accuracy: 0.7500 - val_loss: 0.8589 - val_accuracy: 0.7000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8708 - accuracy: 0.7500 - val_loss: 0.8378 - val_accuracy: 0.6500\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8279 - accuracy: 0.7222 - val_loss: 0.8160 - val_accuracy: 0.7500\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8177 - accuracy: 0.7722 - val_loss: 0.7953 - val_accuracy: 0.8000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7931 - accuracy: 0.7722 - val_loss: 0.7784 - val_accuracy: 0.7500\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7650 - accuracy: 0.7389 - val_loss: 0.7603 - val_accuracy: 0.7500\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7580 - accuracy: 0.7667 - val_loss: 0.7350 - val_accuracy: 0.8000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7305 - accuracy: 0.8167 - val_loss: 0.7105 - val_accuracy: 0.8000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7155 - accuracy: 0.7611 - val_loss: 0.6922 - val_accuracy: 0.8000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7051 - accuracy: 0.7944 - val_loss: 0.6780 - val_accuracy: 0.7500\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6801 - accuracy: 0.7611 - val_loss: 0.6727 - val_accuracy: 0.8000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6701 - accuracy: 0.7389 - val_loss: 0.6688 - val_accuracy: 0.8500\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6544 - accuracy: 0.8222 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6535 - accuracy: 0.7556 - val_loss: 0.6479 - val_accuracy: 0.8000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6502 - accuracy: 0.7889 - val_loss: 0.6242 - val_accuracy: 0.8000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6314 - accuracy: 0.7722 - val_loss: 0.6095 - val_accuracy: 0.7500\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5988 - accuracy: 0.8056 - val_loss: 0.5913 - val_accuracy: 0.8000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5901 - accuracy: 0.8222 - val_loss: 0.5828 - val_accuracy: 0.8000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5944 - accuracy: 0.7944 - val_loss: 0.5877 - val_accuracy: 0.8000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5732 - accuracy: 0.8056 - val_loss: 0.5887 - val_accuracy: 0.8000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5585 - accuracy: 0.8111 - val_loss: 0.5900 - val_accuracy: 0.8000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5562 - accuracy: 0.7944 - val_loss: 0.5798 - val_accuracy: 0.8000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5538 - accuracy: 0.8222 - val_loss: 0.5744 - val_accuracy: 0.8500\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5421 - accuracy: 0.8111 - val_loss: 0.5635 - val_accuracy: 0.8500\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5637 - accuracy: 0.7944 - val_loss: 0.5465 - val_accuracy: 0.8000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5334 - accuracy: 0.7667 - val_loss: 0.5407 - val_accuracy: 0.8000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5140 - accuracy: 0.8278 - val_loss: 0.5419 - val_accuracy: 0.8000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5226 - accuracy: 0.8167 - val_loss: 0.5511 - val_accuracy: 0.8500\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5134 - accuracy: 0.8167 - val_loss: 0.5548 - val_accuracy: 0.8500\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5020 - accuracy: 0.8222 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4740 - accuracy: 0.8556 - val_loss: 0.5506 - val_accuracy: 0.8000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4795 - accuracy: 0.8500 - val_loss: 0.5161 - val_accuracy: 0.8000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4834 - accuracy: 0.8167 - val_loss: 0.4886 - val_accuracy: 0.8000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4494 - accuracy: 0.8278 - val_loss: 0.4811 - val_accuracy: 0.8500\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4267 - accuracy: 0.8444 - val_loss: 0.4850 - val_accuracy: 0.8500\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4409 - accuracy: 0.8444 - val_loss: 0.4931 - val_accuracy: 0.8000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4565 - accuracy: 0.8389 - val_loss: 0.5028 - val_accuracy: 0.8000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4262 - accuracy: 0.8389 - val_loss: 0.4982 - val_accuracy: 0.8000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4389 - accuracy: 0.8278 - val_loss: 0.4930 - val_accuracy: 0.8500\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4162 - accuracy: 0.8556 - val_loss: 0.4917 - val_accuracy: 0.8000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4173 - accuracy: 0.8556 - val_loss: 0.4703 - val_accuracy: 0.8000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4469 - accuracy: 0.8389 - val_loss: 0.4493 - val_accuracy: 0.8000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3993 - accuracy: 0.8444 - val_loss: 0.4475 - val_accuracy: 0.8000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4388 - accuracy: 0.8500 - val_loss: 0.4628 - val_accuracy: 0.8000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3731 - accuracy: 0.8667 - val_loss: 0.4730 - val_accuracy: 0.8500\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3883 - accuracy: 0.8333 - val_loss: 0.4679 - val_accuracy: 0.8500\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3938 - accuracy: 0.8611 - val_loss: 0.4601 - val_accuracy: 0.8000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3781 - accuracy: 0.8778 - val_loss: 0.4553 - val_accuracy: 0.8000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3677 - accuracy: 0.8722 - val_loss: 0.4544 - val_accuracy: 0.8000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3506 - accuracy: 0.8778 - val_loss: 0.4614 - val_accuracy: 0.8000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3571 - accuracy: 0.8778 - val_loss: 0.4479 - val_accuracy: 0.8000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3700 - accuracy: 0.8500 - val_loss: 0.4419 - val_accuracy: 0.8000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3646 - accuracy: 0.8667 - val_loss: 0.4489 - val_accuracy: 0.8000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3497 - accuracy: 0.8722 - val_loss: 0.4653 - val_accuracy: 0.8500\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3520 - accuracy: 0.8778 - val_loss: 0.4817 - val_accuracy: 0.8000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3582 - accuracy: 0.8556 - val_loss: 0.4715 - val_accuracy: 0.8500\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3554 - accuracy: 0.8444 - val_loss: 0.4612 - val_accuracy: 0.8000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3274 - accuracy: 0.9000 - val_loss: 0.4467 - val_accuracy: 0.8000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3307 - accuracy: 0.8778 - val_loss: 0.4383 - val_accuracy: 0.8000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3403 - accuracy: 0.8778 - val_loss: 0.4409 - val_accuracy: 0.8000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3129 - accuracy: 0.8889 - val_loss: 0.4477 - val_accuracy: 0.8000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3363 - accuracy: 0.8222 - val_loss: 0.4484 - val_accuracy: 0.8500\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3098 - accuracy: 0.8833 - val_loss: 0.4445 - val_accuracy: 0.8000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3082 - accuracy: 0.9000 - val_loss: 0.4417 - val_accuracy: 0.8000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3001 - accuracy: 0.9056 - val_loss: 0.4459 - val_accuracy: 0.8500\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3133 - accuracy: 0.9056 - val_loss: 0.4460 - val_accuracy: 0.8500\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3178 - accuracy: 0.8667 - val_loss: 0.4494 - val_accuracy: 0.8000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2832 - accuracy: 0.9000 - val_loss: 0.4560 - val_accuracy: 0.8000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2773 - accuracy: 0.9000 - val_loss: 0.4558 - val_accuracy: 0.8000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2929 - accuracy: 0.8722 - val_loss: 0.4402 - val_accuracy: 0.8000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2860 - accuracy: 0.9000 - val_loss: 0.4307 - val_accuracy: 0.8500\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2494 - accuracy: 0.9222 - val_loss: 0.4299 - val_accuracy: 0.8000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2784 - accuracy: 0.9056 - val_loss: 0.4404 - val_accuracy: 0.8000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2791 - accuracy: 0.8833 - val_loss: 0.4461 - val_accuracy: 0.8000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2545 - accuracy: 0.9056 - val_loss: 0.4483 - val_accuracy: 0.8000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2562 - accuracy: 0.9333 - val_loss: 0.4554 - val_accuracy: 0.8000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2648 - accuracy: 0.9167 - val_loss: 0.4561 - val_accuracy: 0.8000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2480 - accuracy: 0.9167 - val_loss: 0.4546 - val_accuracy: 0.8000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2379 - accuracy: 0.9389 - val_loss: 0.4382 - val_accuracy: 0.8000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2372 - accuracy: 0.9278 - val_loss: 0.4258 - val_accuracy: 0.8000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2420 - accuracy: 0.9278 - val_loss: 0.4150 - val_accuracy: 0.8000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2369 - accuracy: 0.9444 - val_loss: 0.4188 - val_accuracy: 0.7500\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2283 - accuracy: 0.9000 - val_loss: 0.4352 - val_accuracy: 0.8000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2411 - accuracy: 0.9111 - val_loss: 0.4468 - val_accuracy: 0.8000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2431 - accuracy: 0.9278 - val_loss: 0.4508 - val_accuracy: 0.8000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2179 - accuracy: 0.9333 - val_loss: 0.4405 - val_accuracy: 0.8000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2121 - accuracy: 0.9333 - val_loss: 0.4244 - val_accuracy: 0.7500\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2295 - accuracy: 0.9222 - val_loss: 0.4165 - val_accuracy: 0.7500\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2387 - accuracy: 0.9167 - val_loss: 0.4212 - val_accuracy: 0.7500\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1982 - accuracy: 0.9167 - val_loss: 0.4213 - val_accuracy: 0.7500\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2296 - accuracy: 0.9056 - val_loss: 0.4336 - val_accuracy: 0.7500\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2081 - accuracy: 0.9389 - val_loss: 0.4475 - val_accuracy: 0.8000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1944 - accuracy: 0.9389 - val_loss: 0.4560 - val_accuracy: 0.8000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1938 - accuracy: 0.9333 - val_loss: 0.4503 - val_accuracy: 0.8000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1908 - accuracy: 0.9444 - val_loss: 0.4334 - val_accuracy: 0.8000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1879 - accuracy: 0.9444 - val_loss: 0.4217 - val_accuracy: 0.7500\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2021 - accuracy: 0.9278 - val_loss: 0.4216 - val_accuracy: 0.7500\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1872 - accuracy: 0.9500 - val_loss: 0.4258 - val_accuracy: 0.7500\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2041 - accuracy: 0.9222 - val_loss: 0.4371 - val_accuracy: 0.8000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1924 - accuracy: 0.9333 - val_loss: 0.4600 - val_accuracy: 0.8000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2087 - accuracy: 0.9167 - val_loss: 0.4737 - val_accuracy: 0.7500\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2079 - accuracy: 0.9000 - val_loss: 0.4625 - val_accuracy: 0.7500\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1650 - accuracy: 0.9389 - val_loss: 0.4402 - val_accuracy: 0.8000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1715 - accuracy: 0.9444 - val_loss: 0.4175 - val_accuracy: 0.8500\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1913 - accuracy: 0.9444 - val_loss: 0.3988 - val_accuracy: 0.8500\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1870 - accuracy: 0.9556 - val_loss: 0.3949 - val_accuracy: 0.8500\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1706 - accuracy: 0.9500 - val_loss: 0.4079 - val_accuracy: 0.8500\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1702 - accuracy: 0.9333 - val_loss: 0.4306 - val_accuracy: 0.7500\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1493 - accuracy: 0.9500 - val_loss: 0.4499 - val_accuracy: 0.7500\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1834 - accuracy: 0.9500 - val_loss: 0.4569 - val_accuracy: 0.8000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1556 - accuracy: 0.9389 - val_loss: 0.4551 - val_accuracy: 0.7500\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1526 - accuracy: 0.9444 - val_loss: 0.4492 - val_accuracy: 0.7500\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1744 - accuracy: 0.9167 - val_loss: 0.4342 - val_accuracy: 0.8000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1751 - accuracy: 0.9111 - val_loss: 0.4238 - val_accuracy: 0.8500\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1710 - accuracy: 0.9444 - val_loss: 0.4091 - val_accuracy: 0.8500\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1680 - accuracy: 0.9389 - val_loss: 0.3979 - val_accuracy: 0.8500\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1687 - accuracy: 0.9389 - val_loss: 0.4073 - val_accuracy: 0.8500\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1474 - accuracy: 0.9556 - val_loss: 0.4280 - val_accuracy: 0.8500\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1502 - accuracy: 0.9500 - val_loss: 0.4496 - val_accuracy: 0.8000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1565 - accuracy: 0.9278 - val_loss: 0.4634 - val_accuracy: 0.7500\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1482 - accuracy: 0.9333 - val_loss: 0.4665 - val_accuracy: 0.7500\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1525 - accuracy: 0.9444 - val_loss: 0.4541 - val_accuracy: 0.7500\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1574 - accuracy: 0.9278 - val_loss: 0.4385 - val_accuracy: 0.7500\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1119 - accuracy: 0.9722 - val_loss: 0.4270 - val_accuracy: 0.7500\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1681 - accuracy: 0.9278 - val_loss: 0.4133 - val_accuracy: 0.8000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1645 - accuracy: 0.9333 - val_loss: 0.4138 - val_accuracy: 0.8500\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1267 - accuracy: 0.9556 - val_loss: 0.4229 - val_accuracy: 0.8500\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1536 - accuracy: 0.9500 - val_loss: 0.4278 - val_accuracy: 0.8500\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1484 - accuracy: 0.9389 - val_loss: 0.4439 - val_accuracy: 0.8500\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1458 - accuracy: 0.9278 - val_loss: 0.4534 - val_accuracy: 0.8500\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1609 - accuracy: 0.9333 - val_loss: 0.4490 - val_accuracy: 0.8500\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1489 - accuracy: 0.9389 - val_loss: 0.4455 - val_accuracy: 0.8500\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1402 - accuracy: 0.9500 - val_loss: 0.4426 - val_accuracy: 0.8500\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1238 - accuracy: 0.9444 - val_loss: 0.4426 - val_accuracy: 0.8000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1452 - accuracy: 0.9333 - val_loss: 0.4482 - val_accuracy: 0.8000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1311 - accuracy: 0.9444 - val_loss: 0.4574 - val_accuracy: 0.8000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1227 - accuracy: 0.9611 - val_loss: 0.4569 - val_accuracy: 0.8000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1146 - accuracy: 0.9611 - val_loss: 0.4536 - val_accuracy: 0.8000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1343 - accuracy: 0.9500 - val_loss: 0.4413 - val_accuracy: 0.8000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1403 - accuracy: 0.9333 - val_loss: 0.4263 - val_accuracy: 0.8000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1372 - accuracy: 0.9444 - val_loss: 0.4157 - val_accuracy: 0.8000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0990 - accuracy: 0.9667 - val_loss: 0.4141 - val_accuracy: 0.8500\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1269 - accuracy: 0.9444 - val_loss: 0.4164 - val_accuracy: 0.8500\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1311 - accuracy: 0.9500 - val_loss: 0.4226 - val_accuracy: 0.8500\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1264 - accuracy: 0.9556 - val_loss: 0.4283 - val_accuracy: 0.8500\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1330 - accuracy: 0.9444 - val_loss: 0.4388 - val_accuracy: 0.8000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1338 - accuracy: 0.9389 - val_loss: 0.4669 - val_accuracy: 0.8000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1649 - accuracy: 0.9389 - val_loss: 0.4598 - val_accuracy: 0.8000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1452 - accuracy: 0.9389 - val_loss: 0.4385 - val_accuracy: 0.8000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1248 - accuracy: 0.9556 - val_loss: 0.4311 - val_accuracy: 0.8500\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1299 - accuracy: 0.9444 - val_loss: 0.4311 - val_accuracy: 0.8500\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1216 - accuracy: 0.9500 - val_loss: 0.4278 - val_accuracy: 0.8500\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1249 - accuracy: 0.9556 - val_loss: 0.4311 - val_accuracy: 0.8000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1247 - accuracy: 0.9500 - val_loss: 0.4498 - val_accuracy: 0.8000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1403 - accuracy: 0.9333 - val_loss: 0.4581 - val_accuracy: 0.8000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1241 - accuracy: 0.9556 - val_loss: 0.4718 - val_accuracy: 0.8500\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1189 - accuracy: 0.9611 - val_loss: 0.4888 - val_accuracy: 0.8500\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1052 - accuracy: 0.9611 - val_loss: 0.4999 - val_accuracy: 0.8500\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1149 - accuracy: 0.9500 - val_loss: 0.4842 - val_accuracy: 0.8500\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1104 - accuracy: 0.9667 - val_loss: 0.4620 - val_accuracy: 0.8500\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1110 - accuracy: 0.9500 - val_loss: 0.4348 - val_accuracy: 0.8500\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1312 - accuracy: 0.9444 - val_loss: 0.4169 - val_accuracy: 0.8500\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1441 - accuracy: 0.9333 - val_loss: 0.4037 - val_accuracy: 0.8500\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1160 - accuracy: 0.9444 - val_loss: 0.3962 - val_accuracy: 0.8500\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1353 - accuracy: 0.9444 - val_loss: 0.4025 - val_accuracy: 0.8500\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1439 - accuracy: 0.9222 - val_loss: 0.4223 - val_accuracy: 0.8500\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1199 - accuracy: 0.9444 - val_loss: 0.4562 - val_accuracy: 0.8000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1058 - accuracy: 0.9556 - val_loss: 0.4934 - val_accuracy: 0.8000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1191 - accuracy: 0.9556 - val_loss: 0.5157 - val_accuracy: 0.7500\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1194 - accuracy: 0.9444 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1264 - accuracy: 0.9333 - val_loss: 0.5365 - val_accuracy: 0.7500\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1245 - accuracy: 0.9500 - val_loss: 0.5138 - val_accuracy: 0.8000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1210 - accuracy: 0.9389 - val_loss: 0.4765 - val_accuracy: 0.8000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1106 - accuracy: 0.9500 - val_loss: 0.4487 - val_accuracy: 0.8000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1163 - accuracy: 0.9556 - val_loss: 0.4379 - val_accuracy: 0.8000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1100 - accuracy: 0.9556 - val_loss: 0.4344 - val_accuracy: 0.8000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1528 - accuracy: 0.9389 - val_loss: 0.4376 - val_accuracy: 0.8000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1096 - accuracy: 0.9500 - val_loss: 0.4451 - val_accuracy: 0.8000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1046 - accuracy: 0.9444 - val_loss: 0.4555 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "------------------- TRY 6 ----------------------------\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 15:33:05.686165: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_56/dropout_56/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 1.6190 - accuracy: 0.2111 - val_loss: 1.5539 - val_accuracy: 0.2000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5671 - accuracy: 0.2000 - val_loss: 1.4939 - val_accuracy: 0.2000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5186 - accuracy: 0.2278 - val_loss: 1.4308 - val_accuracy: 0.3500\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4592 - accuracy: 0.4000 - val_loss: 1.3770 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4146 - accuracy: 0.4889 - val_loss: 1.3307 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3582 - accuracy: 0.6333 - val_loss: 1.2873 - val_accuracy: 0.5500\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3198 - accuracy: 0.6611 - val_loss: 1.2456 - val_accuracy: 0.5500\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2830 - accuracy: 0.6889 - val_loss: 1.2081 - val_accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2412 - accuracy: 0.6667 - val_loss: 1.1760 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2087 - accuracy: 0.6667 - val_loss: 1.1476 - val_accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1683 - accuracy: 0.6389 - val_loss: 1.1193 - val_accuracy: 0.5000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1415 - accuracy: 0.7056 - val_loss: 1.0906 - val_accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1101 - accuracy: 0.7722 - val_loss: 1.0620 - val_accuracy: 0.6000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0726 - accuracy: 0.7722 - val_loss: 1.0322 - val_accuracy: 0.6500\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0451 - accuracy: 0.7833 - val_loss: 1.0004 - val_accuracy: 0.6500\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0205 - accuracy: 0.7444 - val_loss: 0.9717 - val_accuracy: 0.6500\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9736 - accuracy: 0.7833 - val_loss: 0.9451 - val_accuracy: 0.6000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9543 - accuracy: 0.7500 - val_loss: 0.9202 - val_accuracy: 0.6000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9263 - accuracy: 0.8111 - val_loss: 0.8974 - val_accuracy: 0.6000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8924 - accuracy: 0.7611 - val_loss: 0.8727 - val_accuracy: 0.6500\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8723 - accuracy: 0.7722 - val_loss: 0.8436 - val_accuracy: 0.6500\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8361 - accuracy: 0.7722 - val_loss: 0.8124 - val_accuracy: 0.6500\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8204 - accuracy: 0.7667 - val_loss: 0.7824 - val_accuracy: 0.6000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7832 - accuracy: 0.7389 - val_loss: 0.7549 - val_accuracy: 0.6000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7439 - accuracy: 0.7833 - val_loss: 0.7334 - val_accuracy: 0.6500\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7423 - accuracy: 0.7778 - val_loss: 0.7204 - val_accuracy: 0.7000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7194 - accuracy: 0.7667 - val_loss: 0.7066 - val_accuracy: 0.7500\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6937 - accuracy: 0.7833 - val_loss: 0.6880 - val_accuracy: 0.7000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6860 - accuracy: 0.7222 - val_loss: 0.6672 - val_accuracy: 0.7500\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6632 - accuracy: 0.7778 - val_loss: 0.6483 - val_accuracy: 0.8000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6468 - accuracy: 0.8111 - val_loss: 0.6264 - val_accuracy: 0.7500\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6457 - accuracy: 0.8056 - val_loss: 0.6118 - val_accuracy: 0.7500\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6157 - accuracy: 0.8111 - val_loss: 0.6073 - val_accuracy: 0.7000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6030 - accuracy: 0.7833 - val_loss: 0.6096 - val_accuracy: 0.7500\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5988 - accuracy: 0.8056 - val_loss: 0.6118 - val_accuracy: 0.8000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5972 - accuracy: 0.8111 - val_loss: 0.6119 - val_accuracy: 0.8000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5667 - accuracy: 0.8167 - val_loss: 0.5995 - val_accuracy: 0.8000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5768 - accuracy: 0.8222 - val_loss: 0.5896 - val_accuracy: 0.7000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5163 - accuracy: 0.8278 - val_loss: 0.5850 - val_accuracy: 0.7500\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5199 - accuracy: 0.8389 - val_loss: 0.5782 - val_accuracy: 0.8000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5457 - accuracy: 0.8278 - val_loss: 0.5639 - val_accuracy: 0.8000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5356 - accuracy: 0.8333 - val_loss: 0.5567 - val_accuracy: 0.8000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4941 - accuracy: 0.8389 - val_loss: 0.5700 - val_accuracy: 0.7500\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5078 - accuracy: 0.8000 - val_loss: 0.5875 - val_accuracy: 0.8000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4592 - accuracy: 0.8611 - val_loss: 0.5946 - val_accuracy: 0.8000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4999 - accuracy: 0.8111 - val_loss: 0.5773 - val_accuracy: 0.8000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4691 - accuracy: 0.8500 - val_loss: 0.5533 - val_accuracy: 0.8000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4690 - accuracy: 0.8278 - val_loss: 0.5494 - val_accuracy: 0.7000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4732 - accuracy: 0.8333 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4702 - accuracy: 0.7889 - val_loss: 0.5657 - val_accuracy: 0.8000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4332 - accuracy: 0.8278 - val_loss: 0.5417 - val_accuracy: 0.7500\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4251 - accuracy: 0.8389 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3995 - accuracy: 0.8778 - val_loss: 0.5279 - val_accuracy: 0.7500\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4114 - accuracy: 0.8222 - val_loss: 0.5341 - val_accuracy: 0.8000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3950 - accuracy: 0.8667 - val_loss: 0.5466 - val_accuracy: 0.8000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4120 - accuracy: 0.8444 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4036 - accuracy: 0.8389 - val_loss: 0.5551 - val_accuracy: 0.7500\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3779 - accuracy: 0.8889 - val_loss: 0.5492 - val_accuracy: 0.7500\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3932 - accuracy: 0.8667 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3570 - accuracy: 0.9056 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3590 - accuracy: 0.9000 - val_loss: 0.5246 - val_accuracy: 0.7500\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3440 - accuracy: 0.8722 - val_loss: 0.5277 - val_accuracy: 0.7500\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3639 - accuracy: 0.8833 - val_loss: 0.5370 - val_accuracy: 0.7500\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3511 - accuracy: 0.8944 - val_loss: 0.5584 - val_accuracy: 0.7500\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3683 - accuracy: 0.8778 - val_loss: 0.5508 - val_accuracy: 0.7500\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3634 - accuracy: 0.8611 - val_loss: 0.5343 - val_accuracy: 0.7500\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3664 - accuracy: 0.8500 - val_loss: 0.5279 - val_accuracy: 0.7500\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3602 - accuracy: 0.8611 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3557 - accuracy: 0.8667 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3359 - accuracy: 0.8833 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3235 - accuracy: 0.8889 - val_loss: 0.5274 - val_accuracy: 0.7500\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3218 - accuracy: 0.8889 - val_loss: 0.5452 - val_accuracy: 0.7000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3184 - accuracy: 0.8778 - val_loss: 0.5506 - val_accuracy: 0.7000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3077 - accuracy: 0.9056 - val_loss: 0.5561 - val_accuracy: 0.7500\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3018 - accuracy: 0.8944 - val_loss: 0.5708 - val_accuracy: 0.7500\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2825 - accuracy: 0.9167 - val_loss: 0.5685 - val_accuracy: 0.7000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3012 - accuracy: 0.9056 - val_loss: 0.5488 - val_accuracy: 0.7500\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2783 - accuracy: 0.9111 - val_loss: 0.5407 - val_accuracy: 0.8000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2820 - accuracy: 0.9000 - val_loss: 0.5519 - val_accuracy: 0.7500\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2684 - accuracy: 0.8889 - val_loss: 0.5553 - val_accuracy: 0.7000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2573 - accuracy: 0.9167 - val_loss: 0.5696 - val_accuracy: 0.7500\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2703 - accuracy: 0.9111 - val_loss: 0.5607 - val_accuracy: 0.7500\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2862 - accuracy: 0.9056 - val_loss: 0.5501 - val_accuracy: 0.7500\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2548 - accuracy: 0.9000 - val_loss: 0.5576 - val_accuracy: 0.7500\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2478 - accuracy: 0.9056 - val_loss: 0.5837 - val_accuracy: 0.7000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2812 - accuracy: 0.8833 - val_loss: 0.6018 - val_accuracy: 0.7000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2569 - accuracy: 0.9222 - val_loss: 0.6189 - val_accuracy: 0.7500\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2243 - accuracy: 0.9444 - val_loss: 0.6207 - val_accuracy: 0.7500\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2518 - accuracy: 0.8944 - val_loss: 0.6171 - val_accuracy: 0.7500\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2360 - accuracy: 0.9111 - val_loss: 0.5973 - val_accuracy: 0.7500\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2395 - accuracy: 0.9222 - val_loss: 0.5895 - val_accuracy: 0.8000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2316 - accuracy: 0.9278 - val_loss: 0.5881 - val_accuracy: 0.7500\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2197 - accuracy: 0.9389 - val_loss: 0.5818 - val_accuracy: 0.7500\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2325 - accuracy: 0.9222 - val_loss: 0.5782 - val_accuracy: 0.7500\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2058 - accuracy: 0.9389 - val_loss: 0.5803 - val_accuracy: 0.7500\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2204 - accuracy: 0.9333 - val_loss: 0.5875 - val_accuracy: 0.7500\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2304 - accuracy: 0.9278 - val_loss: 0.5964 - val_accuracy: 0.7000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2120 - accuracy: 0.9389 - val_loss: 0.6120 - val_accuracy: 0.7500\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1930 - accuracy: 0.9500 - val_loss: 0.6279 - val_accuracy: 0.7500\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2479 - accuracy: 0.9111 - val_loss: 0.6575 - val_accuracy: 0.7500\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2141 - accuracy: 0.9333 - val_loss: 0.6626 - val_accuracy: 0.8000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2159 - accuracy: 0.9167 - val_loss: 0.6393 - val_accuracy: 0.8000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2055 - accuracy: 0.9333 - val_loss: 0.5982 - val_accuracy: 0.8000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1683 - accuracy: 0.9722 - val_loss: 0.5774 - val_accuracy: 0.7500\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1920 - accuracy: 0.9278 - val_loss: 0.5761 - val_accuracy: 0.7000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1956 - accuracy: 0.9333 - val_loss: 0.5836 - val_accuracy: 0.7000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1636 - accuracy: 0.9389 - val_loss: 0.5918 - val_accuracy: 0.7500\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2032 - accuracy: 0.9111 - val_loss: 0.6030 - val_accuracy: 0.8500\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2017 - accuracy: 0.9333 - val_loss: 0.6017 - val_accuracy: 0.7500\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2170 - accuracy: 0.9278 - val_loss: 0.6039 - val_accuracy: 0.8000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1848 - accuracy: 0.9389 - val_loss: 0.6217 - val_accuracy: 0.8000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1687 - accuracy: 0.9556 - val_loss: 0.6340 - val_accuracy: 0.7000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1838 - accuracy: 0.9389 - val_loss: 0.6356 - val_accuracy: 0.7000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1939 - accuracy: 0.9222 - val_loss: 0.6237 - val_accuracy: 0.7000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1776 - accuracy: 0.9278 - val_loss: 0.6108 - val_accuracy: 0.7500\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1762 - accuracy: 0.9500 - val_loss: 0.6135 - val_accuracy: 0.8500\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1707 - accuracy: 0.9556 - val_loss: 0.6244 - val_accuracy: 0.8500\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1742 - accuracy: 0.9333 - val_loss: 0.6329 - val_accuracy: 0.8000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1789 - accuracy: 0.9333 - val_loss: 0.6530 - val_accuracy: 0.8000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1645 - accuracy: 0.9500 - val_loss: 0.6725 - val_accuracy: 0.8500\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1473 - accuracy: 0.9444 - val_loss: 0.6864 - val_accuracy: 0.7500\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1664 - accuracy: 0.9389 - val_loss: 0.6632 - val_accuracy: 0.7500\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1628 - accuracy: 0.9278 - val_loss: 0.6340 - val_accuracy: 0.8000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1585 - accuracy: 0.9667 - val_loss: 0.6215 - val_accuracy: 0.8000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1558 - accuracy: 0.9556 - val_loss: 0.6376 - val_accuracy: 0.8000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1621 - accuracy: 0.9278 - val_loss: 0.6701 - val_accuracy: 0.7500\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1626 - accuracy: 0.9444 - val_loss: 0.7003 - val_accuracy: 0.7500\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1544 - accuracy: 0.9500 - val_loss: 0.7256 - val_accuracy: 0.7500\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1408 - accuracy: 0.9444 - val_loss: 0.7338 - val_accuracy: 0.7500\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1555 - accuracy: 0.9278 - val_loss: 0.7115 - val_accuracy: 0.7500\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1377 - accuracy: 0.9444 - val_loss: 0.6947 - val_accuracy: 0.7500\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1869 - accuracy: 0.9000 - val_loss: 0.6912 - val_accuracy: 0.7500\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1482 - accuracy: 0.9444 - val_loss: 0.6923 - val_accuracy: 0.7500\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1599 - accuracy: 0.9278 - val_loss: 0.6924 - val_accuracy: 0.7500\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1481 - accuracy: 0.9222 - val_loss: 0.6979 - val_accuracy: 0.7500\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1586 - accuracy: 0.9333 - val_loss: 0.7048 - val_accuracy: 0.7500\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1429 - accuracy: 0.9444 - val_loss: 0.7115 - val_accuracy: 0.7500\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1283 - accuracy: 0.9556 - val_loss: 0.7041 - val_accuracy: 0.7500\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1445 - accuracy: 0.9389 - val_loss: 0.7074 - val_accuracy: 0.7500\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1414 - accuracy: 0.9444 - val_loss: 0.7202 - val_accuracy: 0.7500\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1558 - accuracy: 0.9167 - val_loss: 0.7366 - val_accuracy: 0.7500\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1481 - accuracy: 0.9389 - val_loss: 0.7423 - val_accuracy: 0.7500\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1373 - accuracy: 0.9389 - val_loss: 0.7384 - val_accuracy: 0.7500\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1501 - accuracy: 0.9444 - val_loss: 0.7367 - val_accuracy: 0.7500\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1343 - accuracy: 0.9667 - val_loss: 0.7255 - val_accuracy: 0.8000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1366 - accuracy: 0.9556 - val_loss: 0.7184 - val_accuracy: 0.8000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1357 - accuracy: 0.9444 - val_loss: 0.7185 - val_accuracy: 0.8000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1250 - accuracy: 0.9611 - val_loss: 0.7194 - val_accuracy: 0.8500\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1273 - accuracy: 0.9667 - val_loss: 0.7141 - val_accuracy: 0.8500\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1101 - accuracy: 0.9556 - val_loss: 0.7139 - val_accuracy: 0.8000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1147 - accuracy: 0.9556 - val_loss: 0.7250 - val_accuracy: 0.8000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1317 - accuracy: 0.9500 - val_loss: 0.7428 - val_accuracy: 0.8000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1259 - accuracy: 0.9722 - val_loss: 0.7597 - val_accuracy: 0.7500\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1140 - accuracy: 0.9722 - val_loss: 0.7863 - val_accuracy: 0.7500\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1093 - accuracy: 0.9778 - val_loss: 0.7981 - val_accuracy: 0.7500\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1307 - accuracy: 0.9444 - val_loss: 0.7927 - val_accuracy: 0.7500\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0993 - accuracy: 0.9778 - val_loss: 0.7944 - val_accuracy: 0.7500\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1174 - accuracy: 0.9556 - val_loss: 0.7837 - val_accuracy: 0.7500\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1380 - accuracy: 0.9389 - val_loss: 0.7582 - val_accuracy: 0.7500\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1393 - accuracy: 0.9444 - val_loss: 0.7419 - val_accuracy: 0.8000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1213 - accuracy: 0.9556 - val_loss: 0.7509 - val_accuracy: 0.7500\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1271 - accuracy: 0.9389 - val_loss: 0.7712 - val_accuracy: 0.7500\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1255 - accuracy: 0.9500 - val_loss: 0.7833 - val_accuracy: 0.7500\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1396 - accuracy: 0.9444 - val_loss: 0.7849 - val_accuracy: 0.7500\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1221 - accuracy: 0.9500 - val_loss: 0.7892 - val_accuracy: 0.8000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1566 - accuracy: 0.9444 - val_loss: 0.7860 - val_accuracy: 0.8000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1213 - accuracy: 0.9389 - val_loss: 0.7896 - val_accuracy: 0.8000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1072 - accuracy: 0.9556 - val_loss: 0.8062 - val_accuracy: 0.8000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1108 - accuracy: 0.9556 - val_loss: 0.8167 - val_accuracy: 0.8500\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1548 - accuracy: 0.9167 - val_loss: 0.8180 - val_accuracy: 0.8000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1175 - accuracy: 0.9444 - val_loss: 0.8119 - val_accuracy: 0.8000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1143 - accuracy: 0.9500 - val_loss: 0.8093 - val_accuracy: 0.8500\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1402 - accuracy: 0.9222 - val_loss: 0.7933 - val_accuracy: 0.8500\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1324 - accuracy: 0.9500 - val_loss: 0.7919 - val_accuracy: 0.8500\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1092 - accuracy: 0.9444 - val_loss: 0.8025 - val_accuracy: 0.8500\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1269 - accuracy: 0.9222 - val_loss: 0.8113 - val_accuracy: 0.8500\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1348 - accuracy: 0.9389 - val_loss: 0.8182 - val_accuracy: 0.8500\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1180 - accuracy: 0.9556 - val_loss: 0.8213 - val_accuracy: 0.8500\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1232 - accuracy: 0.9500 - val_loss: 0.8209 - val_accuracy: 0.8500\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1201 - accuracy: 0.9500 - val_loss: 0.7994 - val_accuracy: 0.8500\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1168 - accuracy: 0.9556 - val_loss: 0.7853 - val_accuracy: 0.8500\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1049 - accuracy: 0.9500 - val_loss: 0.7771 - val_accuracy: 0.8500\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1256 - accuracy: 0.9444 - val_loss: 0.7912 - val_accuracy: 0.8500\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1256 - accuracy: 0.9444 - val_loss: 0.8300 - val_accuracy: 0.7500\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1114 - accuracy: 0.9500 - val_loss: 0.8525 - val_accuracy: 0.7500\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1249 - accuracy: 0.9556 - val_loss: 0.8480 - val_accuracy: 0.8000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1202 - accuracy: 0.9444 - val_loss: 0.8542 - val_accuracy: 0.8000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1230 - accuracy: 0.9500 - val_loss: 0.8522 - val_accuracy: 0.8000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1156 - accuracy: 0.9556 - val_loss: 0.8390 - val_accuracy: 0.8000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1447 - accuracy: 0.9333 - val_loss: 0.8285 - val_accuracy: 0.8000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1206 - accuracy: 0.9556 - val_loss: 0.8190 - val_accuracy: 0.8000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1098 - accuracy: 0.9556 - val_loss: 0.8141 - val_accuracy: 0.8500\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1443 - accuracy: 0.9278 - val_loss: 0.8229 - val_accuracy: 0.8500\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1167 - accuracy: 0.9444 - val_loss: 0.8268 - val_accuracy: 0.8000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1342 - accuracy: 0.9278 - val_loss: 0.7993 - val_accuracy: 0.8500\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1226 - accuracy: 0.9500 - val_loss: 0.7880 - val_accuracy: 0.8500\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1261 - accuracy: 0.9333 - val_loss: 0.7919 - val_accuracy: 0.8500\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1367 - accuracy: 0.9389 - val_loss: 0.8251 - val_accuracy: 0.7500\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1225 - accuracy: 0.9333 - val_loss: 0.8522 - val_accuracy: 0.7500\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1053 - accuracy: 0.9667 - val_loss: 0.8639 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "------------------- TRY 7 ----------------------------\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 15:33:15.227869: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_57/dropout_57/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 1.6133 - accuracy: 0.2056 - val_loss: 1.5864 - val_accuracy: 0.2000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5973 - accuracy: 0.2000 - val_loss: 1.4653 - val_accuracy: 0.3000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4942 - accuracy: 0.3222 - val_loss: 1.4038 - val_accuracy: 0.4500\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4525 - accuracy: 0.4222 - val_loss: 1.3583 - val_accuracy: 0.4500\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4066 - accuracy: 0.3889 - val_loss: 1.3121 - val_accuracy: 0.4500\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3569 - accuracy: 0.4889 - val_loss: 1.2766 - val_accuracy: 0.4500\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3047 - accuracy: 0.5167 - val_loss: 1.2487 - val_accuracy: 0.4500\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2850 - accuracy: 0.4556 - val_loss: 1.2186 - val_accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2543 - accuracy: 0.4444 - val_loss: 1.1838 - val_accuracy: 0.4500\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2236 - accuracy: 0.4389 - val_loss: 1.1472 - val_accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1779 - accuracy: 0.5944 - val_loss: 1.1183 - val_accuracy: 0.6000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1624 - accuracy: 0.5722 - val_loss: 1.0929 - val_accuracy: 0.6500\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1351 - accuracy: 0.6000 - val_loss: 1.0632 - val_accuracy: 0.6500\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0990 - accuracy: 0.6611 - val_loss: 1.0379 - val_accuracy: 0.6500\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0632 - accuracy: 0.7000 - val_loss: 1.0222 - val_accuracy: 0.6500\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0280 - accuracy: 0.6889 - val_loss: 1.0001 - val_accuracy: 0.6500\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0232 - accuracy: 0.6611 - val_loss: 0.9687 - val_accuracy: 0.6000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9813 - accuracy: 0.7056 - val_loss: 0.9381 - val_accuracy: 0.7000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9574 - accuracy: 0.7500 - val_loss: 0.9084 - val_accuracy: 0.6500\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9302 - accuracy: 0.7222 - val_loss: 0.8789 - val_accuracy: 0.6500\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8938 - accuracy: 0.7278 - val_loss: 0.8582 - val_accuracy: 0.7000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8859 - accuracy: 0.7889 - val_loss: 0.8358 - val_accuracy: 0.6000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8495 - accuracy: 0.7222 - val_loss: 0.8105 - val_accuracy: 0.6000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8285 - accuracy: 0.7444 - val_loss: 0.7828 - val_accuracy: 0.7000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8260 - accuracy: 0.7389 - val_loss: 0.7615 - val_accuracy: 0.7500\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8237 - accuracy: 0.7556 - val_loss: 0.7456 - val_accuracy: 0.8500\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7880 - accuracy: 0.7778 - val_loss: 0.7295 - val_accuracy: 0.8500\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7526 - accuracy: 0.7389 - val_loss: 0.7045 - val_accuracy: 0.8000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7589 - accuracy: 0.7611 - val_loss: 0.6798 - val_accuracy: 0.8500\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7444 - accuracy: 0.7389 - val_loss: 0.6633 - val_accuracy: 0.8000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7273 - accuracy: 0.7389 - val_loss: 0.6556 - val_accuracy: 0.7500\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6999 - accuracy: 0.7556 - val_loss: 0.6443 - val_accuracy: 0.8500\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6913 - accuracy: 0.7333 - val_loss: 0.6383 - val_accuracy: 0.8500\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6549 - accuracy: 0.8000 - val_loss: 0.6287 - val_accuracy: 0.8500\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6518 - accuracy: 0.7889 - val_loss: 0.6203 - val_accuracy: 0.8000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6416 - accuracy: 0.7833 - val_loss: 0.6182 - val_accuracy: 0.7000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6607 - accuracy: 0.7500 - val_loss: 0.6157 - val_accuracy: 0.7500\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6406 - accuracy: 0.7556 - val_loss: 0.6040 - val_accuracy: 0.8500\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6192 - accuracy: 0.7722 - val_loss: 0.5827 - val_accuracy: 0.8500\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5973 - accuracy: 0.7778 - val_loss: 0.5779 - val_accuracy: 0.7500\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5699 - accuracy: 0.8444 - val_loss: 0.5692 - val_accuracy: 0.7500\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5577 - accuracy: 0.8222 - val_loss: 0.5722 - val_accuracy: 0.7500\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5693 - accuracy: 0.7889 - val_loss: 0.5687 - val_accuracy: 0.8000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5595 - accuracy: 0.7833 - val_loss: 0.5708 - val_accuracy: 0.8000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5707 - accuracy: 0.8222 - val_loss: 0.5877 - val_accuracy: 0.8000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5520 - accuracy: 0.8333 - val_loss: 0.5810 - val_accuracy: 0.8000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5328 - accuracy: 0.8278 - val_loss: 0.5550 - val_accuracy: 0.8000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5323 - accuracy: 0.8167 - val_loss: 0.5506 - val_accuracy: 0.8000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5437 - accuracy: 0.8111 - val_loss: 0.5550 - val_accuracy: 0.8000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5019 - accuracy: 0.8056 - val_loss: 0.5512 - val_accuracy: 0.8000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5155 - accuracy: 0.8056 - val_loss: 0.5553 - val_accuracy: 0.8500\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4954 - accuracy: 0.8222 - val_loss: 0.5508 - val_accuracy: 0.8500\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5014 - accuracy: 0.8278 - val_loss: 0.5451 - val_accuracy: 0.8000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4545 - accuracy: 0.8667 - val_loss: 0.5295 - val_accuracy: 0.8500\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4810 - accuracy: 0.8500 - val_loss: 0.5285 - val_accuracy: 0.8500\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4545 - accuracy: 0.8556 - val_loss: 0.5286 - val_accuracy: 0.7500\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4812 - accuracy: 0.8389 - val_loss: 0.5138 - val_accuracy: 0.8000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4400 - accuracy: 0.8444 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4745 - accuracy: 0.8111 - val_loss: 0.5206 - val_accuracy: 0.8000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4464 - accuracy: 0.8667 - val_loss: 0.5369 - val_accuracy: 0.8000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4394 - accuracy: 0.8889 - val_loss: 0.5376 - val_accuracy: 0.8000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4370 - accuracy: 0.8389 - val_loss: 0.5183 - val_accuracy: 0.8000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4057 - accuracy: 0.8944 - val_loss: 0.4940 - val_accuracy: 0.8000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4193 - accuracy: 0.8611 - val_loss: 0.4967 - val_accuracy: 0.8000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4281 - accuracy: 0.8444 - val_loss: 0.5086 - val_accuracy: 0.8000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3913 - accuracy: 0.8556 - val_loss: 0.5177 - val_accuracy: 0.8000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3894 - accuracy: 0.8722 - val_loss: 0.5110 - val_accuracy: 0.8000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3770 - accuracy: 0.8889 - val_loss: 0.5041 - val_accuracy: 0.8000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3960 - accuracy: 0.8444 - val_loss: 0.5062 - val_accuracy: 0.8000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3949 - accuracy: 0.8667 - val_loss: 0.5215 - val_accuracy: 0.8000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3953 - accuracy: 0.8556 - val_loss: 0.5409 - val_accuracy: 0.7000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3928 - accuracy: 0.8833 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3629 - accuracy: 0.8889 - val_loss: 0.4955 - val_accuracy: 0.8000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3731 - accuracy: 0.9056 - val_loss: 0.4844 - val_accuracy: 0.8500\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3534 - accuracy: 0.9000 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3568 - accuracy: 0.8722 - val_loss: 0.5465 - val_accuracy: 0.7000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3656 - accuracy: 0.8778 - val_loss: 0.5585 - val_accuracy: 0.7000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3155 - accuracy: 0.9000 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3358 - accuracy: 0.8889 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3560 - accuracy: 0.8722 - val_loss: 0.5151 - val_accuracy: 0.7000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3145 - accuracy: 0.8722 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3358 - accuracy: 0.8778 - val_loss: 0.5271 - val_accuracy: 0.7000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3175 - accuracy: 0.9167 - val_loss: 0.5172 - val_accuracy: 0.7000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3189 - accuracy: 0.8944 - val_loss: 0.4968 - val_accuracy: 0.8000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3149 - accuracy: 0.9056 - val_loss: 0.5049 - val_accuracy: 0.8000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3234 - accuracy: 0.8778 - val_loss: 0.5380 - val_accuracy: 0.7000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3142 - accuracy: 0.8778 - val_loss: 0.5662 - val_accuracy: 0.7000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3312 - accuracy: 0.8722 - val_loss: 0.5627 - val_accuracy: 0.7500\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3030 - accuracy: 0.9167 - val_loss: 0.5513 - val_accuracy: 0.7000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2998 - accuracy: 0.8833 - val_loss: 0.5138 - val_accuracy: 0.6500\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3095 - accuracy: 0.8722 - val_loss: 0.4890 - val_accuracy: 0.7500\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2913 - accuracy: 0.8833 - val_loss: 0.5055 - val_accuracy: 0.8000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2902 - accuracy: 0.8778 - val_loss: 0.5484 - val_accuracy: 0.7000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2707 - accuracy: 0.9167 - val_loss: 0.5976 - val_accuracy: 0.6500\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2710 - accuracy: 0.9222 - val_loss: 0.5775 - val_accuracy: 0.7000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2745 - accuracy: 0.9278 - val_loss: 0.5335 - val_accuracy: 0.8000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2619 - accuracy: 0.9222 - val_loss: 0.5157 - val_accuracy: 0.7500\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2495 - accuracy: 0.9167 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2641 - accuracy: 0.9000 - val_loss: 0.5255 - val_accuracy: 0.8000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2689 - accuracy: 0.9000 - val_loss: 0.5619 - val_accuracy: 0.7500\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2527 - accuracy: 0.9000 - val_loss: 0.5952 - val_accuracy: 0.7000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2338 - accuracy: 0.9222 - val_loss: 0.6009 - val_accuracy: 0.7000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2433 - accuracy: 0.9222 - val_loss: 0.5888 - val_accuracy: 0.7000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2483 - accuracy: 0.9111 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2408 - accuracy: 0.9333 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2358 - accuracy: 0.9278 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2583 - accuracy: 0.9000 - val_loss: 0.5234 - val_accuracy: 0.7000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2192 - accuracy: 0.9389 - val_loss: 0.5487 - val_accuracy: 0.7500\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2153 - accuracy: 0.9444 - val_loss: 0.5735 - val_accuracy: 0.7000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2233 - accuracy: 0.9167 - val_loss: 0.5947 - val_accuracy: 0.7000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2321 - accuracy: 0.9222 - val_loss: 0.5853 - val_accuracy: 0.7000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2241 - accuracy: 0.9222 - val_loss: 0.5744 - val_accuracy: 0.7000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2032 - accuracy: 0.9333 - val_loss: 0.5610 - val_accuracy: 0.7500\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1944 - accuracy: 0.9444 - val_loss: 0.5496 - val_accuracy: 0.8000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2116 - accuracy: 0.9333 - val_loss: 0.5556 - val_accuracy: 0.7000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2067 - accuracy: 0.9167 - val_loss: 0.5715 - val_accuracy: 0.7000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2169 - accuracy: 0.9333 - val_loss: 0.5767 - val_accuracy: 0.7500\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2115 - accuracy: 0.9389 - val_loss: 0.5709 - val_accuracy: 0.8000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1820 - accuracy: 0.9500 - val_loss: 0.5687 - val_accuracy: 0.7500\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1842 - accuracy: 0.9278 - val_loss: 0.5676 - val_accuracy: 0.7000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1977 - accuracy: 0.9389 - val_loss: 0.5680 - val_accuracy: 0.7000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1960 - accuracy: 0.9500 - val_loss: 0.5719 - val_accuracy: 0.7500\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1923 - accuracy: 0.9167 - val_loss: 0.5802 - val_accuracy: 0.7500\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1883 - accuracy: 0.9389 - val_loss: 0.5821 - val_accuracy: 0.7500\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1868 - accuracy: 0.9611 - val_loss: 0.5519 - val_accuracy: 0.8000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1965 - accuracy: 0.9111 - val_loss: 0.5480 - val_accuracy: 0.8000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1862 - accuracy: 0.9278 - val_loss: 0.5491 - val_accuracy: 0.8000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1707 - accuracy: 0.9500 - val_loss: 0.5693 - val_accuracy: 0.8000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1944 - accuracy: 0.9278 - val_loss: 0.5847 - val_accuracy: 0.7500\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1756 - accuracy: 0.9444 - val_loss: 0.5883 - val_accuracy: 0.7000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1747 - accuracy: 0.9389 - val_loss: 0.5798 - val_accuracy: 0.7500\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1701 - accuracy: 0.9333 - val_loss: 0.5750 - val_accuracy: 0.7500\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1690 - accuracy: 0.9444 - val_loss: 0.5801 - val_accuracy: 0.7000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1690 - accuracy: 0.9333 - val_loss: 0.5842 - val_accuracy: 0.7500\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1809 - accuracy: 0.9222 - val_loss: 0.5535 - val_accuracy: 0.8000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1683 - accuracy: 0.9278 - val_loss: 0.5423 - val_accuracy: 0.8000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1804 - accuracy: 0.9278 - val_loss: 0.5533 - val_accuracy: 0.8000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1664 - accuracy: 0.9389 - val_loss: 0.5832 - val_accuracy: 0.7500\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1591 - accuracy: 0.9667 - val_loss: 0.5806 - val_accuracy: 0.7500\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1493 - accuracy: 0.9556 - val_loss: 0.5815 - val_accuracy: 0.8000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1640 - accuracy: 0.9167 - val_loss: 0.5699 - val_accuracy: 0.8000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1584 - accuracy: 0.9389 - val_loss: 0.5628 - val_accuracy: 0.8000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1585 - accuracy: 0.9278 - val_loss: 0.5542 - val_accuracy: 0.8000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1714 - accuracy: 0.9444 - val_loss: 0.5611 - val_accuracy: 0.8000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1731 - accuracy: 0.9222 - val_loss: 0.5818 - val_accuracy: 0.8000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1744 - accuracy: 0.9389 - val_loss: 0.6119 - val_accuracy: 0.7000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1503 - accuracy: 0.9333 - val_loss: 0.6254 - val_accuracy: 0.7000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1491 - accuracy: 0.9389 - val_loss: 0.6344 - val_accuracy: 0.7000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1518 - accuracy: 0.9444 - val_loss: 0.6261 - val_accuracy: 0.7500\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1699 - accuracy: 0.9333 - val_loss: 0.6092 - val_accuracy: 0.8000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1592 - accuracy: 0.9333 - val_loss: 0.5854 - val_accuracy: 0.8000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1319 - accuracy: 0.9556 - val_loss: 0.5570 - val_accuracy: 0.7500\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1584 - accuracy: 0.9333 - val_loss: 0.5860 - val_accuracy: 0.7000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1836 - accuracy: 0.9333 - val_loss: 0.6112 - val_accuracy: 0.7000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1560 - accuracy: 0.9278 - val_loss: 0.6102 - val_accuracy: 0.7000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1473 - accuracy: 0.9333 - val_loss: 0.5930 - val_accuracy: 0.8000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1750 - accuracy: 0.9222 - val_loss: 0.6035 - val_accuracy: 0.8000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1416 - accuracy: 0.9444 - val_loss: 0.6285 - val_accuracy: 0.7500\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1520 - accuracy: 0.9389 - val_loss: 0.6807 - val_accuracy: 0.7000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1387 - accuracy: 0.9611 - val_loss: 0.7015 - val_accuracy: 0.7000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1481 - accuracy: 0.9444 - val_loss: 0.6604 - val_accuracy: 0.7500\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1463 - accuracy: 0.9556 - val_loss: 0.6112 - val_accuracy: 0.8000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1566 - accuracy: 0.9389 - val_loss: 0.5921 - val_accuracy: 0.8500\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1219 - accuracy: 0.9556 - val_loss: 0.5992 - val_accuracy: 0.7500\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1467 - accuracy: 0.9333 - val_loss: 0.6004 - val_accuracy: 0.7500\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1407 - accuracy: 0.9500 - val_loss: 0.6122 - val_accuracy: 0.7500\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1336 - accuracy: 0.9556 - val_loss: 0.6376 - val_accuracy: 0.7000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1331 - accuracy: 0.9389 - val_loss: 0.6502 - val_accuracy: 0.7000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1465 - accuracy: 0.9278 - val_loss: 0.6481 - val_accuracy: 0.8000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1212 - accuracy: 0.9611 - val_loss: 0.6435 - val_accuracy: 0.8500\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1354 - accuracy: 0.9444 - val_loss: 0.6435 - val_accuracy: 0.8500\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1387 - accuracy: 0.9500 - val_loss: 0.6554 - val_accuracy: 0.8500\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1441 - accuracy: 0.9389 - val_loss: 0.6778 - val_accuracy: 0.7500\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1307 - accuracy: 0.9556 - val_loss: 0.6855 - val_accuracy: 0.7500\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1211 - accuracy: 0.9556 - val_loss: 0.6542 - val_accuracy: 0.8000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1488 - accuracy: 0.9167 - val_loss: 0.6242 - val_accuracy: 0.8500\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1252 - accuracy: 0.9389 - val_loss: 0.6122 - val_accuracy: 0.8500\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1289 - accuracy: 0.9444 - val_loss: 0.6334 - val_accuracy: 0.8000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1309 - accuracy: 0.9500 - val_loss: 0.6563 - val_accuracy: 0.8000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1236 - accuracy: 0.9611 - val_loss: 0.6606 - val_accuracy: 0.8000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1351 - accuracy: 0.9389 - val_loss: 0.6571 - val_accuracy: 0.8500\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1313 - accuracy: 0.9333 - val_loss: 0.6330 - val_accuracy: 0.9000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1133 - accuracy: 0.9611 - val_loss: 0.6277 - val_accuracy: 0.9000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1135 - accuracy: 0.9667 - val_loss: 0.6320 - val_accuracy: 0.9000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1140 - accuracy: 0.9556 - val_loss: 0.6609 - val_accuracy: 0.8000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1349 - accuracy: 0.9500 - val_loss: 0.6665 - val_accuracy: 0.8000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1271 - accuracy: 0.9500 - val_loss: 0.6607 - val_accuracy: 0.8000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1489 - accuracy: 0.9222 - val_loss: 0.6435 - val_accuracy: 0.8500\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1202 - accuracy: 0.9278 - val_loss: 0.6290 - val_accuracy: 0.7500\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1242 - accuracy: 0.9333 - val_loss: 0.6320 - val_accuracy: 0.8000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1349 - accuracy: 0.9389 - val_loss: 0.6455 - val_accuracy: 0.8000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1170 - accuracy: 0.9389 - val_loss: 0.6354 - val_accuracy: 0.8500\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1285 - accuracy: 0.9389 - val_loss: 0.6392 - val_accuracy: 0.8000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1338 - accuracy: 0.9444 - val_loss: 0.6436 - val_accuracy: 0.8000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1313 - accuracy: 0.9333 - val_loss: 0.6428 - val_accuracy: 0.8000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1319 - accuracy: 0.9222 - val_loss: 0.6416 - val_accuracy: 0.8500\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1222 - accuracy: 0.9444 - val_loss: 0.6411 - val_accuracy: 0.9000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1019 - accuracy: 0.9667 - val_loss: 0.6289 - val_accuracy: 0.9000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1218 - accuracy: 0.9444 - val_loss: 0.6305 - val_accuracy: 0.9000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1256 - accuracy: 0.9444 - val_loss: 0.6626 - val_accuracy: 0.9000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "------------------- TRY 8 ----------------------------\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 15:33:25.451288: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_58/dropout_58/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 1.6082 - accuracy: 0.2000 - val_loss: 1.5435 - val_accuracy: 0.2000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5625 - accuracy: 0.2111 - val_loss: 1.4854 - val_accuracy: 0.2000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.5085 - accuracy: 0.2667 - val_loss: 1.4241 - val_accuracy: 0.4000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4601 - accuracy: 0.4056 - val_loss: 1.3669 - val_accuracy: 0.4500\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4058 - accuracy: 0.5833 - val_loss: 1.3148 - val_accuracy: 0.4000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3642 - accuracy: 0.5833 - val_loss: 1.2669 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.3118 - accuracy: 0.6889 - val_loss: 1.2226 - val_accuracy: 0.5500\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.2659 - accuracy: 0.7833 - val_loss: 1.1820 - val_accuracy: 0.6000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2249 - accuracy: 0.7278 - val_loss: 1.1460 - val_accuracy: 0.6500\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1886 - accuracy: 0.7389 - val_loss: 1.1132 - val_accuracy: 0.6500\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1516 - accuracy: 0.7056 - val_loss: 1.0819 - val_accuracy: 0.6000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1086 - accuracy: 0.7444 - val_loss: 1.0507 - val_accuracy: 0.6500\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0766 - accuracy: 0.8056 - val_loss: 1.0201 - val_accuracy: 0.6500\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0500 - accuracy: 0.7556 - val_loss: 0.9914 - val_accuracy: 0.6500\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0188 - accuracy: 0.7556 - val_loss: 0.9654 - val_accuracy: 0.6500\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9775 - accuracy: 0.7389 - val_loss: 0.9396 - val_accuracy: 0.7000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9580 - accuracy: 0.7556 - val_loss: 0.9141 - val_accuracy: 0.7000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9225 - accuracy: 0.7167 - val_loss: 0.8865 - val_accuracy: 0.6500\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8943 - accuracy: 0.7722 - val_loss: 0.8560 - val_accuracy: 0.6500\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8654 - accuracy: 0.7556 - val_loss: 0.8266 - val_accuracy: 0.7000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8469 - accuracy: 0.7389 - val_loss: 0.8031 - val_accuracy: 0.7000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8175 - accuracy: 0.7611 - val_loss: 0.7878 - val_accuracy: 0.7500\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7934 - accuracy: 0.7944 - val_loss: 0.7688 - val_accuracy: 0.8000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7704 - accuracy: 0.7889 - val_loss: 0.7443 - val_accuracy: 0.8000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7531 - accuracy: 0.7611 - val_loss: 0.7305 - val_accuracy: 0.7500\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7282 - accuracy: 0.8167 - val_loss: 0.7032 - val_accuracy: 0.8000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7054 - accuracy: 0.7833 - val_loss: 0.6786 - val_accuracy: 0.8000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7042 - accuracy: 0.7944 - val_loss: 0.6629 - val_accuracy: 0.7000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6720 - accuracy: 0.7889 - val_loss: 0.6608 - val_accuracy: 0.7000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6582 - accuracy: 0.7833 - val_loss: 0.6576 - val_accuracy: 0.7500\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6662 - accuracy: 0.7833 - val_loss: 0.6457 - val_accuracy: 0.7500\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6416 - accuracy: 0.8000 - val_loss: 0.6369 - val_accuracy: 0.7500\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6252 - accuracy: 0.8278 - val_loss: 0.6228 - val_accuracy: 0.7500\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6258 - accuracy: 0.8167 - val_loss: 0.6082 - val_accuracy: 0.7500\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6027 - accuracy: 0.8333 - val_loss: 0.6022 - val_accuracy: 0.8000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6089 - accuracy: 0.8167 - val_loss: 0.5930 - val_accuracy: 0.8000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5855 - accuracy: 0.8000 - val_loss: 0.6065 - val_accuracy: 0.8000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5833 - accuracy: 0.8111 - val_loss: 0.6173 - val_accuracy: 0.8000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5498 - accuracy: 0.8333 - val_loss: 0.5853 - val_accuracy: 0.8000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5751 - accuracy: 0.8111 - val_loss: 0.5579 - val_accuracy: 0.7500\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5403 - accuracy: 0.8222 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5134 - accuracy: 0.8389 - val_loss: 0.5737 - val_accuracy: 0.8500\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5183 - accuracy: 0.8500 - val_loss: 0.5581 - val_accuracy: 0.8000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5050 - accuracy: 0.8056 - val_loss: 0.5430 - val_accuracy: 0.8000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5123 - accuracy: 0.8278 - val_loss: 0.5479 - val_accuracy: 0.8000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4826 - accuracy: 0.8611 - val_loss: 0.5605 - val_accuracy: 0.8000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4821 - accuracy: 0.8778 - val_loss: 0.5497 - val_accuracy: 0.8500\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4789 - accuracy: 0.8500 - val_loss: 0.5410 - val_accuracy: 0.8500\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4784 - accuracy: 0.8333 - val_loss: 0.5204 - val_accuracy: 0.8000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4545 - accuracy: 0.8444 - val_loss: 0.5209 - val_accuracy: 0.8000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4782 - accuracy: 0.8056 - val_loss: 0.5368 - val_accuracy: 0.8000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4505 - accuracy: 0.8556 - val_loss: 0.5582 - val_accuracy: 0.8500\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4394 - accuracy: 0.8556 - val_loss: 0.5439 - val_accuracy: 0.8500\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4404 - accuracy: 0.8500 - val_loss: 0.5113 - val_accuracy: 0.8000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4111 - accuracy: 0.8667 - val_loss: 0.4908 - val_accuracy: 0.8000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3953 - accuracy: 0.8667 - val_loss: 0.4933 - val_accuracy: 0.8000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4001 - accuracy: 0.8556 - val_loss: 0.5121 - val_accuracy: 0.8000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3996 - accuracy: 0.8778 - val_loss: 0.5042 - val_accuracy: 0.8500\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4227 - accuracy: 0.8500 - val_loss: 0.5033 - val_accuracy: 0.8500\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4094 - accuracy: 0.8667 - val_loss: 0.5032 - val_accuracy: 0.8000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3896 - accuracy: 0.8944 - val_loss: 0.5100 - val_accuracy: 0.8000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3860 - accuracy: 0.8944 - val_loss: 0.5089 - val_accuracy: 0.8000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3875 - accuracy: 0.8556 - val_loss: 0.4959 - val_accuracy: 0.8000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3722 - accuracy: 0.8889 - val_loss: 0.4828 - val_accuracy: 0.8500\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3537 - accuracy: 0.8778 - val_loss: 0.4875 - val_accuracy: 0.8500\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3562 - accuracy: 0.8778 - val_loss: 0.4992 - val_accuracy: 0.8000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3589 - accuracy: 0.8889 - val_loss: 0.5255 - val_accuracy: 0.8000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3493 - accuracy: 0.8722 - val_loss: 0.5230 - val_accuracy: 0.8000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3177 - accuracy: 0.9056 - val_loss: 0.5015 - val_accuracy: 0.8000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3503 - accuracy: 0.8889 - val_loss: 0.4839 - val_accuracy: 0.8000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3145 - accuracy: 0.9222 - val_loss: 0.4747 - val_accuracy: 0.8000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2858 - accuracy: 0.9000 - val_loss: 0.4744 - val_accuracy: 0.8000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3293 - accuracy: 0.8556 - val_loss: 0.4817 - val_accuracy: 0.8000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3335 - accuracy: 0.8889 - val_loss: 0.4844 - val_accuracy: 0.8500\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3082 - accuracy: 0.9056 - val_loss: 0.5030 - val_accuracy: 0.8500\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2962 - accuracy: 0.9111 - val_loss: 0.5224 - val_accuracy: 0.8500\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3046 - accuracy: 0.9111 - val_loss: 0.5039 - val_accuracy: 0.8500\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2805 - accuracy: 0.9167 - val_loss: 0.4879 - val_accuracy: 0.8000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2685 - accuracy: 0.9389 - val_loss: 0.4846 - val_accuracy: 0.8000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2728 - accuracy: 0.9167 - val_loss: 0.4822 - val_accuracy: 0.8500\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2711 - accuracy: 0.9167 - val_loss: 0.4923 - val_accuracy: 0.8500\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2433 - accuracy: 0.9389 - val_loss: 0.5034 - val_accuracy: 0.8500\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2725 - accuracy: 0.9278 - val_loss: 0.5119 - val_accuracy: 0.8500\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2480 - accuracy: 0.9389 - val_loss: 0.5146 - val_accuracy: 0.8000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2693 - accuracy: 0.9278 - val_loss: 0.4992 - val_accuracy: 0.8000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2608 - accuracy: 0.9222 - val_loss: 0.4847 - val_accuracy: 0.8000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2308 - accuracy: 0.9222 - val_loss: 0.4794 - val_accuracy: 0.8000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2366 - accuracy: 0.9167 - val_loss: 0.4867 - val_accuracy: 0.8500\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2390 - accuracy: 0.9222 - val_loss: 0.4921 - val_accuracy: 0.8500\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2472 - accuracy: 0.9000 - val_loss: 0.5144 - val_accuracy: 0.8000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2472 - accuracy: 0.9056 - val_loss: 0.5324 - val_accuracy: 0.8500\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2295 - accuracy: 0.9444 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2255 - accuracy: 0.9167 - val_loss: 0.5126 - val_accuracy: 0.8500\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2037 - accuracy: 0.9444 - val_loss: 0.5166 - val_accuracy: 0.8500\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2223 - accuracy: 0.9389 - val_loss: 0.5091 - val_accuracy: 0.8500\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2431 - accuracy: 0.9000 - val_loss: 0.4958 - val_accuracy: 0.8000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2244 - accuracy: 0.9111 - val_loss: 0.5103 - val_accuracy: 0.8000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2085 - accuracy: 0.9444 - val_loss: 0.5065 - val_accuracy: 0.8000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2004 - accuracy: 0.9389 - val_loss: 0.5017 - val_accuracy: 0.8000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2083 - accuracy: 0.9222 - val_loss: 0.5074 - val_accuracy: 0.8500\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2178 - accuracy: 0.9333 - val_loss: 0.5174 - val_accuracy: 0.8500\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1908 - accuracy: 0.9333 - val_loss: 0.5185 - val_accuracy: 0.8500\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2119 - accuracy: 0.9167 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1973 - accuracy: 0.9333 - val_loss: 0.5192 - val_accuracy: 0.8000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1964 - accuracy: 0.9444 - val_loss: 0.5182 - val_accuracy: 0.8000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1940 - accuracy: 0.9389 - val_loss: 0.5145 - val_accuracy: 0.8000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1875 - accuracy: 0.9333 - val_loss: 0.5152 - val_accuracy: 0.8500\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1922 - accuracy: 0.9333 - val_loss: 0.5153 - val_accuracy: 0.9000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1917 - accuracy: 0.9444 - val_loss: 0.5194 - val_accuracy: 0.8000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1761 - accuracy: 0.9333 - val_loss: 0.5198 - val_accuracy: 0.8000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2089 - accuracy: 0.9278 - val_loss: 0.5121 - val_accuracy: 0.8000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1862 - accuracy: 0.9278 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1764 - accuracy: 0.9444 - val_loss: 0.5234 - val_accuracy: 0.8000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1824 - accuracy: 0.9389 - val_loss: 0.5348 - val_accuracy: 0.8000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1723 - accuracy: 0.9500 - val_loss: 0.5413 - val_accuracy: 0.8000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1674 - accuracy: 0.9556 - val_loss: 0.5443 - val_accuracy: 0.8000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1607 - accuracy: 0.9444 - val_loss: 0.5505 - val_accuracy: 0.8000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1701 - accuracy: 0.9333 - val_loss: 0.5429 - val_accuracy: 0.8000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1729 - accuracy: 0.9333 - val_loss: 0.5368 - val_accuracy: 0.8500\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1890 - accuracy: 0.9167 - val_loss: 0.5355 - val_accuracy: 0.8000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1704 - accuracy: 0.9444 - val_loss: 0.5530 - val_accuracy: 0.8500\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1708 - accuracy: 0.9444 - val_loss: 0.5677 - val_accuracy: 0.8500\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1681 - accuracy: 0.9333 - val_loss: 0.5680 - val_accuracy: 0.9000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1555 - accuracy: 0.9333 - val_loss: 0.5589 - val_accuracy: 0.9000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1529 - accuracy: 0.9500 - val_loss: 0.5490 - val_accuracy: 0.9000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1660 - accuracy: 0.9500 - val_loss: 0.5428 - val_accuracy: 0.9000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1371 - accuracy: 0.9611 - val_loss: 0.5437 - val_accuracy: 0.8500\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1380 - accuracy: 0.9611 - val_loss: 0.5485 - val_accuracy: 0.8500\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1513 - accuracy: 0.9444 - val_loss: 0.5615 - val_accuracy: 0.8500\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1348 - accuracy: 0.9667 - val_loss: 0.5652 - val_accuracy: 0.9000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1415 - accuracy: 0.9556 - val_loss: 0.5664 - val_accuracy: 0.8500\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1419 - accuracy: 0.9444 - val_loss: 0.5648 - val_accuracy: 0.8500\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1435 - accuracy: 0.9444 - val_loss: 0.5700 - val_accuracy: 0.8000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1542 - accuracy: 0.9278 - val_loss: 0.5733 - val_accuracy: 0.8000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1314 - accuracy: 0.9556 - val_loss: 0.5693 - val_accuracy: 0.8500\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1335 - accuracy: 0.9333 - val_loss: 0.5623 - val_accuracy: 0.8500\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1545 - accuracy: 0.9222 - val_loss: 0.5612 - val_accuracy: 0.8500\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1466 - accuracy: 0.9444 - val_loss: 0.5597 - val_accuracy: 0.8000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1558 - accuracy: 0.9389 - val_loss: 0.5695 - val_accuracy: 0.8500\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1526 - accuracy: 0.9222 - val_loss: 0.5783 - val_accuracy: 0.8500\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1550 - accuracy: 0.9222 - val_loss: 0.5969 - val_accuracy: 0.8500\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1315 - accuracy: 0.9500 - val_loss: 0.6031 - val_accuracy: 0.8500\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1428 - accuracy: 0.9500 - val_loss: 0.6054 - val_accuracy: 0.8500\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1689 - accuracy: 0.9056 - val_loss: 0.5987 - val_accuracy: 0.8500\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1380 - accuracy: 0.9556 - val_loss: 0.5867 - val_accuracy: 0.8500\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1487 - accuracy: 0.9222 - val_loss: 0.5840 - val_accuracy: 0.8500\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1400 - accuracy: 0.9333 - val_loss: 0.5865 - val_accuracy: 0.8500\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1308 - accuracy: 0.9444 - val_loss: 0.5825 - val_accuracy: 0.8500\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1273 - accuracy: 0.9611 - val_loss: 0.5812 - val_accuracy: 0.8500\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1268 - accuracy: 0.9500 - val_loss: 0.5920 - val_accuracy: 0.8500\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1383 - accuracy: 0.9556 - val_loss: 0.6219 - val_accuracy: 0.8500\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1281 - accuracy: 0.9389 - val_loss: 0.6497 - val_accuracy: 0.8500\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1262 - accuracy: 0.9444 - val_loss: 0.6570 - val_accuracy: 0.8500\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1375 - accuracy: 0.9444 - val_loss: 0.6518 - val_accuracy: 0.8500\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1323 - accuracy: 0.9444 - val_loss: 0.6220 - val_accuracy: 0.8500\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1171 - accuracy: 0.9500 - val_loss: 0.5925 - val_accuracy: 0.8500\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1314 - accuracy: 0.9500 - val_loss: 0.5837 - val_accuracy: 0.8500\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1181 - accuracy: 0.9500 - val_loss: 0.5915 - val_accuracy: 0.8000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1470 - accuracy: 0.9278 - val_loss: 0.6155 - val_accuracy: 0.8000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1261 - accuracy: 0.9611 - val_loss: 0.6453 - val_accuracy: 0.8500\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1317 - accuracy: 0.9222 - val_loss: 0.6676 - val_accuracy: 0.8500\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1401 - accuracy: 0.9278 - val_loss: 0.6803 - val_accuracy: 0.9000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1100 - accuracy: 0.9611 - val_loss: 0.6899 - val_accuracy: 0.9000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1352 - accuracy: 0.9222 - val_loss: 0.6827 - val_accuracy: 0.9000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1234 - accuracy: 0.9611 - val_loss: 0.6598 - val_accuracy: 0.8500\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1211 - accuracy: 0.9444 - val_loss: 0.6461 - val_accuracy: 0.8500\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1398 - accuracy: 0.9278 - val_loss: 0.6274 - val_accuracy: 0.8500\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1279 - accuracy: 0.9444 - val_loss: 0.6136 - val_accuracy: 0.8500\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1130 - accuracy: 0.9556 - val_loss: 0.6070 - val_accuracy: 0.8500\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1217 - accuracy: 0.9500 - val_loss: 0.6148 - val_accuracy: 0.8500\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1326 - accuracy: 0.9389 - val_loss: 0.6281 - val_accuracy: 0.8500\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1283 - accuracy: 0.9333 - val_loss: 0.6445 - val_accuracy: 0.8500\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1114 - accuracy: 0.9611 - val_loss: 0.6647 - val_accuracy: 0.8500\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1280 - accuracy: 0.9500 - val_loss: 0.6821 - val_accuracy: 0.8500\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1188 - accuracy: 0.9389 - val_loss: 0.6915 - val_accuracy: 0.8500\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1420 - accuracy: 0.9278 - val_loss: 0.6842 - val_accuracy: 0.8500\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1018 - accuracy: 0.9556 - val_loss: 0.6811 - val_accuracy: 0.8500\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1173 - accuracy: 0.9611 - val_loss: 0.6806 - val_accuracy: 0.8500\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1115 - accuracy: 0.9444 - val_loss: 0.6752 - val_accuracy: 0.8500\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1088 - accuracy: 0.9611 - val_loss: 0.6696 - val_accuracy: 0.8500\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1190 - accuracy: 0.9444 - val_loss: 0.6636 - val_accuracy: 0.8500\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1179 - accuracy: 0.9389 - val_loss: 0.6625 - val_accuracy: 0.8500\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1070 - accuracy: 0.9500 - val_loss: 0.6640 - val_accuracy: 0.8500\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1175 - accuracy: 0.9500 - val_loss: 0.6711 - val_accuracy: 0.8500\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1117 - accuracy: 0.9500 - val_loss: 0.6832 - val_accuracy: 0.8500\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1049 - accuracy: 0.9722 - val_loss: 0.6911 - val_accuracy: 0.8500\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1074 - accuracy: 0.9556 - val_loss: 0.6926 - val_accuracy: 0.9000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1116 - accuracy: 0.9444 - val_loss: 0.6959 - val_accuracy: 0.9000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1074 - accuracy: 0.9500 - val_loss: 0.6955 - val_accuracy: 0.8500\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1233 - accuracy: 0.9444 - val_loss: 0.7086 - val_accuracy: 0.8500\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0964 - accuracy: 0.9611 - val_loss: 0.7154 - val_accuracy: 0.8500\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1159 - accuracy: 0.9500 - val_loss: 0.7071 - val_accuracy: 0.8500\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1044 - accuracy: 0.9611 - val_loss: 0.6966 - val_accuracy: 0.8500\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1056 - accuracy: 0.9556 - val_loss: 0.6907 - val_accuracy: 0.8500\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1141 - accuracy: 0.9444 - val_loss: 0.6878 - val_accuracy: 0.8500\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1044 - accuracy: 0.9611 - val_loss: 0.6885 - val_accuracy: 0.8500\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1100 - accuracy: 0.9278 - val_loss: 0.7044 - val_accuracy: 0.8500\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1004 - accuracy: 0.9611 - val_loss: 0.7166 - val_accuracy: 0.8500\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1058 - accuracy: 0.9500 - val_loss: 0.7150 - val_accuracy: 0.8500\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0964 - accuracy: 0.9611 - val_loss: 0.7153 - val_accuracy: 0.8500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "------------------- TRY 9 ----------------------------\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 15:33:35.688468: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_59/dropout_59/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 1.6141 - accuracy: 0.1722 - val_loss: 1.5518 - val_accuracy: 0.2000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5651 - accuracy: 0.2000 - val_loss: 1.4787 - val_accuracy: 0.2500\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4986 - accuracy: 0.3111 - val_loss: 1.4154 - val_accuracy: 0.3000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4376 - accuracy: 0.4056 - val_loss: 1.3640 - val_accuracy: 0.4500\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3957 - accuracy: 0.4500 - val_loss: 1.3224 - val_accuracy: 0.4000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3531 - accuracy: 0.5333 - val_loss: 1.2877 - val_accuracy: 0.4000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3147 - accuracy: 0.5667 - val_loss: 1.2568 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2697 - accuracy: 0.6444 - val_loss: 1.2273 - val_accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2406 - accuracy: 0.6111 - val_loss: 1.1994 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2123 - accuracy: 0.5944 - val_loss: 1.1723 - val_accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1775 - accuracy: 0.6611 - val_loss: 1.1456 - val_accuracy: 0.4500\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1569 - accuracy: 0.6389 - val_loss: 1.1187 - val_accuracy: 0.6000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1088 - accuracy: 0.7389 - val_loss: 1.0906 - val_accuracy: 0.6000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0834 - accuracy: 0.7500 - val_loss: 1.0630 - val_accuracy: 0.6500\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0462 - accuracy: 0.7889 - val_loss: 1.0341 - val_accuracy: 0.6500\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0171 - accuracy: 0.7500 - val_loss: 1.0025 - val_accuracy: 0.6500\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9854 - accuracy: 0.7389 - val_loss: 0.9707 - val_accuracy: 0.7000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9574 - accuracy: 0.7500 - val_loss: 0.9400 - val_accuracy: 0.5500\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9350 - accuracy: 0.7667 - val_loss: 0.9069 - val_accuracy: 0.6000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9059 - accuracy: 0.7444 - val_loss: 0.8725 - val_accuracy: 0.5500\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8550 - accuracy: 0.7556 - val_loss: 0.8414 - val_accuracy: 0.6500\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8388 - accuracy: 0.7222 - val_loss: 0.8149 - val_accuracy: 0.6500\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8177 - accuracy: 0.7667 - val_loss: 0.7951 - val_accuracy: 0.7000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7812 - accuracy: 0.7611 - val_loss: 0.7781 - val_accuracy: 0.7000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7676 - accuracy: 0.7444 - val_loss: 0.7566 - val_accuracy: 0.6500\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7412 - accuracy: 0.7944 - val_loss: 0.7357 - val_accuracy: 0.6000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7220 - accuracy: 0.7611 - val_loss: 0.7090 - val_accuracy: 0.6500\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7222 - accuracy: 0.7556 - val_loss: 0.6816 - val_accuracy: 0.7000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6939 - accuracy: 0.7778 - val_loss: 0.6614 - val_accuracy: 0.7500\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6792 - accuracy: 0.7833 - val_loss: 0.6536 - val_accuracy: 0.7000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6567 - accuracy: 0.7833 - val_loss: 0.6426 - val_accuracy: 0.6500\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6425 - accuracy: 0.7778 - val_loss: 0.6358 - val_accuracy: 0.6500\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6545 - accuracy: 0.7833 - val_loss: 0.6334 - val_accuracy: 0.7500\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6297 - accuracy: 0.7778 - val_loss: 0.6262 - val_accuracy: 0.7500\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6173 - accuracy: 0.8167 - val_loss: 0.6065 - val_accuracy: 0.7500\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5873 - accuracy: 0.8333 - val_loss: 0.5806 - val_accuracy: 0.6500\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5995 - accuracy: 0.8111 - val_loss: 0.5796 - val_accuracy: 0.7000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5835 - accuracy: 0.8167 - val_loss: 0.5689 - val_accuracy: 0.7000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6028 - accuracy: 0.7833 - val_loss: 0.5675 - val_accuracy: 0.7500\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5561 - accuracy: 0.8056 - val_loss: 0.5784 - val_accuracy: 0.7500\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5515 - accuracy: 0.8111 - val_loss: 0.5769 - val_accuracy: 0.7500\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5688 - accuracy: 0.7889 - val_loss: 0.5645 - val_accuracy: 0.7500\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5437 - accuracy: 0.8111 - val_loss: 0.5525 - val_accuracy: 0.7500\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5344 - accuracy: 0.8389 - val_loss: 0.5660 - val_accuracy: 0.7500\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5313 - accuracy: 0.8222 - val_loss: 0.5612 - val_accuracy: 0.7500\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4969 - accuracy: 0.8444 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5290 - accuracy: 0.8056 - val_loss: 0.5328 - val_accuracy: 0.8000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5259 - accuracy: 0.8167 - val_loss: 0.5576 - val_accuracy: 0.7500\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4932 - accuracy: 0.8333 - val_loss: 0.5631 - val_accuracy: 0.7500\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4631 - accuracy: 0.8611 - val_loss: 0.5566 - val_accuracy: 0.7500\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4661 - accuracy: 0.8000 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4758 - accuracy: 0.8333 - val_loss: 0.5358 - val_accuracy: 0.8000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4449 - accuracy: 0.8444 - val_loss: 0.5523 - val_accuracy: 0.7500\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4545 - accuracy: 0.8444 - val_loss: 0.5572 - val_accuracy: 0.7500\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4502 - accuracy: 0.8389 - val_loss: 0.5465 - val_accuracy: 0.7000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4183 - accuracy: 0.8722 - val_loss: 0.5243 - val_accuracy: 0.7500\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3999 - accuracy: 0.8500 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4294 - accuracy: 0.8111 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4258 - accuracy: 0.8611 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4029 - accuracy: 0.8722 - val_loss: 0.5274 - val_accuracy: 0.7500\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3844 - accuracy: 0.8500 - val_loss: 0.5233 - val_accuracy: 0.7500\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3801 - accuracy: 0.8556 - val_loss: 0.5370 - val_accuracy: 0.7500\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3874 - accuracy: 0.9000 - val_loss: 0.5545 - val_accuracy: 0.7000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3683 - accuracy: 0.8833 - val_loss: 0.5326 - val_accuracy: 0.7000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3911 - accuracy: 0.8944 - val_loss: 0.5107 - val_accuracy: 0.7000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3651 - accuracy: 0.8944 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3734 - accuracy: 0.8667 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3775 - accuracy: 0.8500 - val_loss: 0.5418 - val_accuracy: 0.7500\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3535 - accuracy: 0.8667 - val_loss: 0.5428 - val_accuracy: 0.7000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3953 - accuracy: 0.8444 - val_loss: 0.5314 - val_accuracy: 0.7000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3515 - accuracy: 0.8889 - val_loss: 0.5203 - val_accuracy: 0.7000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3432 - accuracy: 0.8889 - val_loss: 0.5099 - val_accuracy: 0.7000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3398 - accuracy: 0.8778 - val_loss: 0.5113 - val_accuracy: 0.7000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3341 - accuracy: 0.8889 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3331 - accuracy: 0.9111 - val_loss: 0.5153 - val_accuracy: 0.7000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3247 - accuracy: 0.8833 - val_loss: 0.5338 - val_accuracy: 0.7000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3118 - accuracy: 0.9167 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3237 - accuracy: 0.8778 - val_loss: 0.5180 - val_accuracy: 0.7000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3304 - accuracy: 0.8722 - val_loss: 0.5034 - val_accuracy: 0.7000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3029 - accuracy: 0.8833 - val_loss: 0.5004 - val_accuracy: 0.7000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3030 - accuracy: 0.8944 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3204 - accuracy: 0.8833 - val_loss: 0.5296 - val_accuracy: 0.7000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3021 - accuracy: 0.9000 - val_loss: 0.5543 - val_accuracy: 0.7500\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2766 - accuracy: 0.9000 - val_loss: 0.5499 - val_accuracy: 0.7500\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3072 - accuracy: 0.9000 - val_loss: 0.5254 - val_accuracy: 0.8000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3098 - accuracy: 0.8833 - val_loss: 0.5061 - val_accuracy: 0.8000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3104 - accuracy: 0.8778 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2759 - accuracy: 0.9111 - val_loss: 0.5243 - val_accuracy: 0.7500\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2679 - accuracy: 0.9056 - val_loss: 0.5359 - val_accuracy: 0.7500\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2290 - accuracy: 0.9500 - val_loss: 0.5383 - val_accuracy: 0.8000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2736 - accuracy: 0.8833 - val_loss: 0.5361 - val_accuracy: 0.8500\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2422 - accuracy: 0.9111 - val_loss: 0.5304 - val_accuracy: 0.8000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2429 - accuracy: 0.9167 - val_loss: 0.5246 - val_accuracy: 0.7500\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2470 - accuracy: 0.9167 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2334 - accuracy: 0.9222 - val_loss: 0.5244 - val_accuracy: 0.7000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2513 - accuracy: 0.9222 - val_loss: 0.5408 - val_accuracy: 0.7000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2550 - accuracy: 0.9111 - val_loss: 0.5579 - val_accuracy: 0.7500\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2191 - accuracy: 0.9222 - val_loss: 0.5541 - val_accuracy: 0.7500\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2412 - accuracy: 0.9056 - val_loss: 0.5482 - val_accuracy: 0.8000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2290 - accuracy: 0.9056 - val_loss: 0.5497 - val_accuracy: 0.8000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2155 - accuracy: 0.9444 - val_loss: 0.5568 - val_accuracy: 0.8000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2078 - accuracy: 0.9389 - val_loss: 0.5612 - val_accuracy: 0.8000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1834 - accuracy: 0.9500 - val_loss: 0.5678 - val_accuracy: 0.8000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2272 - accuracy: 0.9278 - val_loss: 0.5626 - val_accuracy: 0.8000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2017 - accuracy: 0.9389 - val_loss: 0.5635 - val_accuracy: 0.7500\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1960 - accuracy: 0.9333 - val_loss: 0.5667 - val_accuracy: 0.7500\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2230 - accuracy: 0.9278 - val_loss: 0.5655 - val_accuracy: 0.8000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1928 - accuracy: 0.9556 - val_loss: 0.5686 - val_accuracy: 0.8000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1913 - accuracy: 0.9389 - val_loss: 0.5716 - val_accuracy: 0.8000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1831 - accuracy: 0.9333 - val_loss: 0.5731 - val_accuracy: 0.8000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1894 - accuracy: 0.9389 - val_loss: 0.5741 - val_accuracy: 0.8000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1815 - accuracy: 0.9444 - val_loss: 0.5654 - val_accuracy: 0.8000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1916 - accuracy: 0.9333 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1840 - accuracy: 0.9278 - val_loss: 0.5709 - val_accuracy: 0.7500\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1787 - accuracy: 0.9389 - val_loss: 0.5822 - val_accuracy: 0.7500\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1648 - accuracy: 0.9500 - val_loss: 0.5764 - val_accuracy: 0.8000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1866 - accuracy: 0.9222 - val_loss: 0.5805 - val_accuracy: 0.8000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1779 - accuracy: 0.9500 - val_loss: 0.5801 - val_accuracy: 0.8000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1796 - accuracy: 0.9222 - val_loss: 0.5739 - val_accuracy: 0.8000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1831 - accuracy: 0.9222 - val_loss: 0.5857 - val_accuracy: 0.8000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1623 - accuracy: 0.9333 - val_loss: 0.6109 - val_accuracy: 0.8000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1710 - accuracy: 0.9278 - val_loss: 0.6294 - val_accuracy: 0.8000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1705 - accuracy: 0.9444 - val_loss: 0.6360 - val_accuracy: 0.8000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1793 - accuracy: 0.9222 - val_loss: 0.6279 - val_accuracy: 0.8000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1784 - accuracy: 0.9389 - val_loss: 0.6070 - val_accuracy: 0.8000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1525 - accuracy: 0.9722 - val_loss: 0.5931 - val_accuracy: 0.8000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1607 - accuracy: 0.9500 - val_loss: 0.5888 - val_accuracy: 0.8000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1856 - accuracy: 0.9333 - val_loss: 0.6038 - val_accuracy: 0.8000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1571 - accuracy: 0.9500 - val_loss: 0.6194 - val_accuracy: 0.8000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1714 - accuracy: 0.9111 - val_loss: 0.6263 - val_accuracy: 0.8000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1558 - accuracy: 0.9333 - val_loss: 0.6308 - val_accuracy: 0.8000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1431 - accuracy: 0.9389 - val_loss: 0.6428 - val_accuracy: 0.7000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1678 - accuracy: 0.9167 - val_loss: 0.6347 - val_accuracy: 0.8000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1602 - accuracy: 0.9389 - val_loss: 0.6102 - val_accuracy: 0.8000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1654 - accuracy: 0.9389 - val_loss: 0.6097 - val_accuracy: 0.8000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1358 - accuracy: 0.9444 - val_loss: 0.6176 - val_accuracy: 0.8000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1702 - accuracy: 0.9389 - val_loss: 0.6425 - val_accuracy: 0.8000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1154 - accuracy: 0.9833 - val_loss: 0.6551 - val_accuracy: 0.8000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1564 - accuracy: 0.9167 - val_loss: 0.6671 - val_accuracy: 0.7500\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1693 - accuracy: 0.9222 - val_loss: 0.6711 - val_accuracy: 0.7500\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1439 - accuracy: 0.9444 - val_loss: 0.6684 - val_accuracy: 0.8000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1361 - accuracy: 0.9556 - val_loss: 0.6630 - val_accuracy: 0.8000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1267 - accuracy: 0.9611 - val_loss: 0.6739 - val_accuracy: 0.8000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1648 - accuracy: 0.9278 - val_loss: 0.6860 - val_accuracy: 0.8000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1588 - accuracy: 0.9278 - val_loss: 0.6928 - val_accuracy: 0.8000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1387 - accuracy: 0.9444 - val_loss: 0.6844 - val_accuracy: 0.8000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1393 - accuracy: 0.9444 - val_loss: 0.6992 - val_accuracy: 0.7500\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1390 - accuracy: 0.9333 - val_loss: 0.7119 - val_accuracy: 0.7500\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1565 - accuracy: 0.9222 - val_loss: 0.7087 - val_accuracy: 0.7500\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1390 - accuracy: 0.9333 - val_loss: 0.6920 - val_accuracy: 0.8000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1263 - accuracy: 0.9667 - val_loss: 0.6719 - val_accuracy: 0.8000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1251 - accuracy: 0.9389 - val_loss: 0.6632 - val_accuracy: 0.8000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1295 - accuracy: 0.9500 - val_loss: 0.6510 - val_accuracy: 0.8000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1467 - accuracy: 0.9389 - val_loss: 0.6541 - val_accuracy: 0.8000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1454 - accuracy: 0.9389 - val_loss: 0.6799 - val_accuracy: 0.8000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1201 - accuracy: 0.9556 - val_loss: 0.7091 - val_accuracy: 0.8000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1427 - accuracy: 0.9556 - val_loss: 0.7375 - val_accuracy: 0.8000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1851 - accuracy: 0.9167 - val_loss: 0.7426 - val_accuracy: 0.8000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1492 - accuracy: 0.9278 - val_loss: 0.7375 - val_accuracy: 0.8000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1410 - accuracy: 0.9667 - val_loss: 0.7161 - val_accuracy: 0.8000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1442 - accuracy: 0.9278 - val_loss: 0.6920 - val_accuracy: 0.8000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1088 - accuracy: 0.9500 - val_loss: 0.6886 - val_accuracy: 0.8000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1100 - accuracy: 0.9556 - val_loss: 0.6847 - val_accuracy: 0.8000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1139 - accuracy: 0.9500 - val_loss: 0.6843 - val_accuracy: 0.8000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1160 - accuracy: 0.9500 - val_loss: 0.7043 - val_accuracy: 0.8000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1426 - accuracy: 0.9389 - val_loss: 0.7160 - val_accuracy: 0.8000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1169 - accuracy: 0.9444 - val_loss: 0.7163 - val_accuracy: 0.8000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1110 - accuracy: 0.9556 - val_loss: 0.7066 - val_accuracy: 0.8000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1031 - accuracy: 0.9722 - val_loss: 0.7057 - val_accuracy: 0.8000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1446 - accuracy: 0.9222 - val_loss: 0.7055 - val_accuracy: 0.8000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1584 - accuracy: 0.9222 - val_loss: 0.7108 - val_accuracy: 0.8000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1330 - accuracy: 0.9389 - val_loss: 0.7232 - val_accuracy: 0.8000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1243 - accuracy: 0.9444 - val_loss: 0.7187 - val_accuracy: 0.8000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1185 - accuracy: 0.9500 - val_loss: 0.7062 - val_accuracy: 0.8000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1101 - accuracy: 0.9444 - val_loss: 0.7105 - val_accuracy: 0.8000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1203 - accuracy: 0.9333 - val_loss: 0.7321 - val_accuracy: 0.8000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1051 - accuracy: 0.9556 - val_loss: 0.7584 - val_accuracy: 0.8000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1179 - accuracy: 0.9333 - val_loss: 0.7724 - val_accuracy: 0.8000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1032 - accuracy: 0.9722 - val_loss: 0.7912 - val_accuracy: 0.8000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1449 - accuracy: 0.9333 - val_loss: 0.7890 - val_accuracy: 0.8000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1392 - accuracy: 0.9444 - val_loss: 0.7721 - val_accuracy: 0.8000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1180 - accuracy: 0.9556 - val_loss: 0.7496 - val_accuracy: 0.8000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1193 - accuracy: 0.9500 - val_loss: 0.7348 - val_accuracy: 0.8000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1090 - accuracy: 0.9556 - val_loss: 0.7396 - val_accuracy: 0.8000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1240 - accuracy: 0.9389 - val_loss: 0.7603 - val_accuracy: 0.8000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0994 - accuracy: 0.9667 - val_loss: 0.7776 - val_accuracy: 0.8000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0969 - accuracy: 0.9778 - val_loss: 0.7907 - val_accuracy: 0.8000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1092 - accuracy: 0.9611 - val_loss: 0.7968 - val_accuracy: 0.8000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1212 - accuracy: 0.9500 - val_loss: 0.8030 - val_accuracy: 0.7500\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1489 - accuracy: 0.9444 - val_loss: 0.8182 - val_accuracy: 0.7500\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1155 - accuracy: 0.9444 - val_loss: 0.8268 - val_accuracy: 0.7500\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1357 - accuracy: 0.9278 - val_loss: 0.8089 - val_accuracy: 0.8000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1254 - accuracy: 0.9389 - val_loss: 0.7907 - val_accuracy: 0.8000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1017 - accuracy: 0.9556 - val_loss: 0.7790 - val_accuracy: 0.8000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1188 - accuracy: 0.9500 - val_loss: 0.7618 - val_accuracy: 0.8000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1134 - accuracy: 0.9500 - val_loss: 0.7527 - val_accuracy: 0.8000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1045 - accuracy: 0.9556 - val_loss: 0.7468 - val_accuracy: 0.8000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1315 - accuracy: 0.9500 - val_loss: 0.7490 - val_accuracy: 0.8000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1090 - accuracy: 0.9556 - val_loss: 0.7523 - val_accuracy: 0.8000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1165 - accuracy: 0.9389 - val_loss: 0.7600 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "------------------- TRY 10 ----------------------------\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 15:33:45.452775: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_60/dropout_60/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 1.5973 - accuracy: 0.2278 - val_loss: 1.5016 - val_accuracy: 0.2000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5222 - accuracy: 0.2444 - val_loss: 1.4255 - val_accuracy: 0.4000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4589 - accuracy: 0.3667 - val_loss: 1.3590 - val_accuracy: 0.3500\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3908 - accuracy: 0.5000 - val_loss: 1.3045 - val_accuracy: 0.3500\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3500 - accuracy: 0.4389 - val_loss: 1.2619 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2999 - accuracy: 0.5611 - val_loss: 1.2272 - val_accuracy: 0.5500\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2709 - accuracy: 0.5500 - val_loss: 1.1988 - val_accuracy: 0.4500\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2239 - accuracy: 0.5556 - val_loss: 1.1719 - val_accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2030 - accuracy: 0.6000 - val_loss: 1.1448 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1653 - accuracy: 0.6444 - val_loss: 1.1183 - val_accuracy: 0.6000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1323 - accuracy: 0.6833 - val_loss: 1.0903 - val_accuracy: 0.6000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0880 - accuracy: 0.6944 - val_loss: 1.0606 - val_accuracy: 0.6000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0581 - accuracy: 0.7611 - val_loss: 1.0312 - val_accuracy: 0.6500\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0384 - accuracy: 0.7056 - val_loss: 1.0030 - val_accuracy: 0.6000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9817 - accuracy: 0.7389 - val_loss: 0.9740 - val_accuracy: 0.6000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9678 - accuracy: 0.7667 - val_loss: 0.9486 - val_accuracy: 0.6500\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9401 - accuracy: 0.7611 - val_loss: 0.9201 - val_accuracy: 0.6000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9043 - accuracy: 0.7833 - val_loss: 0.8893 - val_accuracy: 0.6500\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8790 - accuracy: 0.7389 - val_loss: 0.8554 - val_accuracy: 0.6000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8433 - accuracy: 0.7333 - val_loss: 0.8286 - val_accuracy: 0.6500\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8042 - accuracy: 0.7611 - val_loss: 0.8022 - val_accuracy: 0.6500\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7998 - accuracy: 0.7333 - val_loss: 0.7752 - val_accuracy: 0.6500\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7625 - accuracy: 0.7278 - val_loss: 0.7588 - val_accuracy: 0.6500\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7534 - accuracy: 0.7667 - val_loss: 0.7490 - val_accuracy: 0.6500\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7445 - accuracy: 0.7556 - val_loss: 0.7269 - val_accuracy: 0.6500\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7203 - accuracy: 0.8000 - val_loss: 0.6953 - val_accuracy: 0.6500\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7017 - accuracy: 0.7833 - val_loss: 0.6755 - val_accuracy: 0.7000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6590 - accuracy: 0.8000 - val_loss: 0.6630 - val_accuracy: 0.7000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6816 - accuracy: 0.7611 - val_loss: 0.6417 - val_accuracy: 0.7000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6814 - accuracy: 0.7556 - val_loss: 0.6431 - val_accuracy: 0.6500\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6530 - accuracy: 0.8056 - val_loss: 0.6482 - val_accuracy: 0.7000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6271 - accuracy: 0.7944 - val_loss: 0.6542 - val_accuracy: 0.7000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6258 - accuracy: 0.8056 - val_loss: 0.6329 - val_accuracy: 0.7500\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6500 - accuracy: 0.7389 - val_loss: 0.6031 - val_accuracy: 0.7500\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5863 - accuracy: 0.8056 - val_loss: 0.5961 - val_accuracy: 0.7000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6116 - accuracy: 0.7667 - val_loss: 0.5968 - val_accuracy: 0.7500\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5725 - accuracy: 0.8056 - val_loss: 0.5952 - val_accuracy: 0.7500\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5598 - accuracy: 0.8000 - val_loss: 0.6008 - val_accuracy: 0.7500\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5825 - accuracy: 0.7778 - val_loss: 0.6026 - val_accuracy: 0.8000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5488 - accuracy: 0.7889 - val_loss: 0.6015 - val_accuracy: 0.7500\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5223 - accuracy: 0.8444 - val_loss: 0.5814 - val_accuracy: 0.7500\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5448 - accuracy: 0.8056 - val_loss: 0.5457 - val_accuracy: 0.8000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5289 - accuracy: 0.8111 - val_loss: 0.5407 - val_accuracy: 0.8000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5061 - accuracy: 0.8278 - val_loss: 0.5515 - val_accuracy: 0.7500\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5084 - accuracy: 0.8222 - val_loss: 0.5769 - val_accuracy: 0.7000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5293 - accuracy: 0.8111 - val_loss: 0.5900 - val_accuracy: 0.7500\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5099 - accuracy: 0.8278 - val_loss: 0.5683 - val_accuracy: 0.7500\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4918 - accuracy: 0.8111 - val_loss: 0.5289 - val_accuracy: 0.7500\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4928 - accuracy: 0.8222 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4542 - accuracy: 0.8389 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4751 - accuracy: 0.8000 - val_loss: 0.5554 - val_accuracy: 0.7500\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4698 - accuracy: 0.8389 - val_loss: 0.5562 - val_accuracy: 0.8000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4315 - accuracy: 0.8611 - val_loss: 0.5307 - val_accuracy: 0.7000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4417 - accuracy: 0.8722 - val_loss: 0.5055 - val_accuracy: 0.7500\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4167 - accuracy: 0.8500 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4425 - accuracy: 0.8389 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4061 - accuracy: 0.8500 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4566 - accuracy: 0.8389 - val_loss: 0.5055 - val_accuracy: 0.7500\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4128 - accuracy: 0.8667 - val_loss: 0.4999 - val_accuracy: 0.8000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4158 - accuracy: 0.8500 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4328 - accuracy: 0.8500 - val_loss: 0.5454 - val_accuracy: 0.7000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4190 - accuracy: 0.8556 - val_loss: 0.5284 - val_accuracy: 0.7500\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3866 - accuracy: 0.8500 - val_loss: 0.5077 - val_accuracy: 0.8000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3528 - accuracy: 0.8944 - val_loss: 0.4760 - val_accuracy: 0.8000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4116 - accuracy: 0.8333 - val_loss: 0.4735 - val_accuracy: 0.7500\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3896 - accuracy: 0.8611 - val_loss: 0.5021 - val_accuracy: 0.8000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3557 - accuracy: 0.8778 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3908 - accuracy: 0.8611 - val_loss: 0.5418 - val_accuracy: 0.7000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3786 - accuracy: 0.8667 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3603 - accuracy: 0.8611 - val_loss: 0.4806 - val_accuracy: 0.7000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3499 - accuracy: 0.8722 - val_loss: 0.4803 - val_accuracy: 0.8000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3615 - accuracy: 0.8722 - val_loss: 0.5203 - val_accuracy: 0.8000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3646 - accuracy: 0.8722 - val_loss: 0.5435 - val_accuracy: 0.8000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3937 - accuracy: 0.8278 - val_loss: 0.5082 - val_accuracy: 0.7000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3478 - accuracy: 0.8722 - val_loss: 0.4931 - val_accuracy: 0.7000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3336 - accuracy: 0.8611 - val_loss: 0.4907 - val_accuracy: 0.7000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3298 - accuracy: 0.8944 - val_loss: 0.4919 - val_accuracy: 0.7000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3152 - accuracy: 0.8833 - val_loss: 0.4998 - val_accuracy: 0.7000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3233 - accuracy: 0.8889 - val_loss: 0.5265 - val_accuracy: 0.8000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3020 - accuracy: 0.9056 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2976 - accuracy: 0.9111 - val_loss: 0.5062 - val_accuracy: 0.8000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3136 - accuracy: 0.8778 - val_loss: 0.4864 - val_accuracy: 0.7000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2928 - accuracy: 0.9167 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2988 - accuracy: 0.9000 - val_loss: 0.5066 - val_accuracy: 0.7000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2936 - accuracy: 0.9056 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3045 - accuracy: 0.8889 - val_loss: 0.5173 - val_accuracy: 0.7500\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2862 - accuracy: 0.9111 - val_loss: 0.5141 - val_accuracy: 0.8000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3052 - accuracy: 0.8944 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2585 - accuracy: 0.9167 - val_loss: 0.4873 - val_accuracy: 0.7500\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2663 - accuracy: 0.9333 - val_loss: 0.4896 - val_accuracy: 0.8000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2721 - accuracy: 0.9000 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2489 - accuracy: 0.9333 - val_loss: 0.4946 - val_accuracy: 0.7000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2674 - accuracy: 0.9056 - val_loss: 0.5076 - val_accuracy: 0.7000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2843 - accuracy: 0.9000 - val_loss: 0.5133 - val_accuracy: 0.7500\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2687 - accuracy: 0.9111 - val_loss: 0.5077 - val_accuracy: 0.8000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2578 - accuracy: 0.8944 - val_loss: 0.4999 - val_accuracy: 0.8000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2723 - accuracy: 0.8833 - val_loss: 0.4817 - val_accuracy: 0.7500\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2445 - accuracy: 0.8944 - val_loss: 0.4714 - val_accuracy: 0.8000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2465 - accuracy: 0.9111 - val_loss: 0.4748 - val_accuracy: 0.7500\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2419 - accuracy: 0.9000 - val_loss: 0.4886 - val_accuracy: 0.7000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2636 - accuracy: 0.9056 - val_loss: 0.5119 - val_accuracy: 0.8000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2398 - accuracy: 0.9278 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2455 - accuracy: 0.9222 - val_loss: 0.5052 - val_accuracy: 0.8000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2136 - accuracy: 0.9444 - val_loss: 0.4858 - val_accuracy: 0.7500\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2317 - accuracy: 0.9056 - val_loss: 0.4735 - val_accuracy: 0.8000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2455 - accuracy: 0.9167 - val_loss: 0.4692 - val_accuracy: 0.8000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2214 - accuracy: 0.9333 - val_loss: 0.4799 - val_accuracy: 0.8500\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2321 - accuracy: 0.9167 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2372 - accuracy: 0.9333 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2147 - accuracy: 0.9278 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2268 - accuracy: 0.9333 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2284 - accuracy: 0.9167 - val_loss: 0.4889 - val_accuracy: 0.7000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2398 - accuracy: 0.8944 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2036 - accuracy: 0.9278 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1798 - accuracy: 0.9333 - val_loss: 0.4943 - val_accuracy: 0.8000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1899 - accuracy: 0.9444 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1810 - accuracy: 0.9667 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1930 - accuracy: 0.9389 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2030 - accuracy: 0.9278 - val_loss: 0.4626 - val_accuracy: 0.8000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2102 - accuracy: 0.9278 - val_loss: 0.4819 - val_accuracy: 0.7500\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2115 - accuracy: 0.9111 - val_loss: 0.5045 - val_accuracy: 0.7000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2191 - accuracy: 0.9000 - val_loss: 0.4999 - val_accuracy: 0.8000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1835 - accuracy: 0.9333 - val_loss: 0.5027 - val_accuracy: 0.7000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1920 - accuracy: 0.9222 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2024 - accuracy: 0.9333 - val_loss: 0.5016 - val_accuracy: 0.7500\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1919 - accuracy: 0.9278 - val_loss: 0.4886 - val_accuracy: 0.7000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1915 - accuracy: 0.9222 - val_loss: 0.4707 - val_accuracy: 0.8000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1846 - accuracy: 0.9333 - val_loss: 0.4538 - val_accuracy: 0.8000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2015 - accuracy: 0.9056 - val_loss: 0.4579 - val_accuracy: 0.7500\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1788 - accuracy: 0.9389 - val_loss: 0.4761 - val_accuracy: 0.7500\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1777 - accuracy: 0.9333 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1840 - accuracy: 0.9389 - val_loss: 0.5190 - val_accuracy: 0.8000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1687 - accuracy: 0.9333 - val_loss: 0.5289 - val_accuracy: 0.7500\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1782 - accuracy: 0.9278 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1691 - accuracy: 0.9500 - val_loss: 0.4804 - val_accuracy: 0.7500\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1686 - accuracy: 0.9389 - val_loss: 0.4605 - val_accuracy: 0.8000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1694 - accuracy: 0.9444 - val_loss: 0.4621 - val_accuracy: 0.8000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1799 - accuracy: 0.9111 - val_loss: 0.4767 - val_accuracy: 0.8500\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1664 - accuracy: 0.9278 - val_loss: 0.5031 - val_accuracy: 0.8000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1661 - accuracy: 0.9444 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1723 - accuracy: 0.9222 - val_loss: 0.5486 - val_accuracy: 0.7500\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1776 - accuracy: 0.9333 - val_loss: 0.5443 - val_accuracy: 0.7500\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1657 - accuracy: 0.9278 - val_loss: 0.5214 - val_accuracy: 0.8000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1626 - accuracy: 0.9444 - val_loss: 0.4907 - val_accuracy: 0.8500\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1668 - accuracy: 0.9333 - val_loss: 0.4658 - val_accuracy: 0.8500\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1488 - accuracy: 0.9444 - val_loss: 0.4622 - val_accuracy: 0.8000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1532 - accuracy: 0.9500 - val_loss: 0.4718 - val_accuracy: 0.8500\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1439 - accuracy: 0.9500 - val_loss: 0.4837 - val_accuracy: 0.8500\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1779 - accuracy: 0.8944 - val_loss: 0.4938 - val_accuracy: 0.8500\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1479 - accuracy: 0.9389 - val_loss: 0.5028 - val_accuracy: 0.8500\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1598 - accuracy: 0.9333 - val_loss: 0.5024 - val_accuracy: 0.8000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1655 - accuracy: 0.9167 - val_loss: 0.4760 - val_accuracy: 0.7500\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1498 - accuracy: 0.9389 - val_loss: 0.4548 - val_accuracy: 0.8000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1609 - accuracy: 0.9111 - val_loss: 0.4465 - val_accuracy: 0.8000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1389 - accuracy: 0.9500 - val_loss: 0.4474 - val_accuracy: 0.8500\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1447 - accuracy: 0.9500 - val_loss: 0.4591 - val_accuracy: 0.8500\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1635 - accuracy: 0.9500 - val_loss: 0.4782 - val_accuracy: 0.8000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1440 - accuracy: 0.9444 - val_loss: 0.5048 - val_accuracy: 0.8000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1526 - accuracy: 0.9111 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1530 - accuracy: 0.9222 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1156 - accuracy: 0.9667 - val_loss: 0.5016 - val_accuracy: 0.7500\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1693 - accuracy: 0.9278 - val_loss: 0.4878 - val_accuracy: 0.8000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1278 - accuracy: 0.9611 - val_loss: 0.4731 - val_accuracy: 0.8000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1412 - accuracy: 0.9611 - val_loss: 0.4602 - val_accuracy: 0.8500\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1449 - accuracy: 0.9389 - val_loss: 0.4566 - val_accuracy: 0.8500\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1164 - accuracy: 0.9667 - val_loss: 0.4655 - val_accuracy: 0.8500\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1485 - accuracy: 0.9333 - val_loss: 0.4778 - val_accuracy: 0.8500\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1190 - accuracy: 0.9611 - val_loss: 0.4931 - val_accuracy: 0.8000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1385 - accuracy: 0.9389 - val_loss: 0.5102 - val_accuracy: 0.8000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1356 - accuracy: 0.9500 - val_loss: 0.5333 - val_accuracy: 0.7500\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1276 - accuracy: 0.9556 - val_loss: 0.5170 - val_accuracy: 0.8000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1256 - accuracy: 0.9611 - val_loss: 0.4953 - val_accuracy: 0.8500\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1314 - accuracy: 0.9667 - val_loss: 0.4711 - val_accuracy: 0.8500\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1149 - accuracy: 0.9611 - val_loss: 0.4637 - val_accuracy: 0.8500\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1272 - accuracy: 0.9556 - val_loss: 0.4597 - val_accuracy: 0.8500\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1505 - accuracy: 0.9500 - val_loss: 0.4557 - val_accuracy: 0.8500\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1419 - accuracy: 0.9333 - val_loss: 0.4574 - val_accuracy: 0.8500\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1332 - accuracy: 0.9611 - val_loss: 0.4590 - val_accuracy: 0.8500\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1318 - accuracy: 0.9611 - val_loss: 0.4769 - val_accuracy: 0.8500\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1293 - accuracy: 0.9333 - val_loss: 0.5008 - val_accuracy: 0.8000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1265 - accuracy: 0.9389 - val_loss: 0.5180 - val_accuracy: 0.8000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1357 - accuracy: 0.9333 - val_loss: 0.5211 - val_accuracy: 0.8000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1192 - accuracy: 0.9500 - val_loss: 0.5201 - val_accuracy: 0.8000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1523 - accuracy: 0.9167 - val_loss: 0.4968 - val_accuracy: 0.8500\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1169 - accuracy: 0.9500 - val_loss: 0.4761 - val_accuracy: 0.8500\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1470 - accuracy: 0.9278 - val_loss: 0.4591 - val_accuracy: 0.8500\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1291 - accuracy: 0.9444 - val_loss: 0.4491 - val_accuracy: 0.8500\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1224 - accuracy: 0.9444 - val_loss: 0.4501 - val_accuracy: 0.8500\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1364 - accuracy: 0.9333 - val_loss: 0.4644 - val_accuracy: 0.8500\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1292 - accuracy: 0.9500 - val_loss: 0.4905 - val_accuracy: 0.8000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1288 - accuracy: 0.9389 - val_loss: 0.5250 - val_accuracy: 0.8000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1198 - accuracy: 0.9389 - val_loss: 0.5598 - val_accuracy: 0.8000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1283 - accuracy: 0.9444 - val_loss: 0.5466 - val_accuracy: 0.8000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1308 - accuracy: 0.9500 - val_loss: 0.5209 - val_accuracy: 0.8000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1387 - accuracy: 0.9333 - val_loss: 0.5001 - val_accuracy: 0.8500\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1323 - accuracy: 0.9500 - val_loss: 0.4632 - val_accuracy: 0.8500\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1370 - accuracy: 0.9389 - val_loss: 0.4461 - val_accuracy: 0.8500\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1159 - accuracy: 0.9556 - val_loss: 0.4743 - val_accuracy: 0.7500\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1364 - accuracy: 0.9389 - val_loss: 0.4667 - val_accuracy: 0.8000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1429 - accuracy: 0.9333 - val_loss: 0.4546 - val_accuracy: 0.8500\n",
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "class TimingCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, logs={}):\n",
    "        self.logs=[]\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.starttime = timer()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(timer()-self.starttime)\n",
    "\n",
    "cb = TimingCallback()\n",
    "\n",
    "batch_size = 50\n",
    "lr = 0.0002\n",
    "epochs = 200\n",
    "\n",
    "all_metrics = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"------------------- TRY {i+1} ----------------------------\")\n",
    "    classifier_model = keras.models.Sequential([    \n",
    "        keras.layers.Conv2D(filters=10, kernel_size=(11,1),kernel_initializer=glorot_normal() ,activation='tanh',padding='same' ,input_shape=(200,5,1)),\n",
    "        keras.layers.MaxPool2D(pool_size=(2, 1)),\n",
    "\n",
    "\n",
    "        keras.layers.Conv2D(filters=20, kernel_size=(5,1),kernel_initializer=glorot_normal() ,activation='tanh' ,padding='same'), \n",
    "        keras.layers.MaxPool2D(pool_size=(2, 1)),\n",
    "        keras.layers.Dropout(rate=0.5),\n",
    "\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(100, activation='tanh',kernel_initializer=glorot_normal()), # glorot_uniform\n",
    "        keras.layers.Dense(5, activation='softmax')\n",
    "    ])\n",
    "\n",
    "\n",
    "    opt = Adam(lr=lr)\n",
    "    classifier_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    cb = TimingCallback()\n",
    "\n",
    " \n",
    "    hist = classifier_model.fit(X_train, y_train, epochs=epochs,batch_size=1000 ,validation_data= (X_val, y_val), callbacks=[cb])\n",
    "    \n",
    "\n",
    "    train_loss = hist.history['loss']\n",
    "    val_loss = hist.history['val_loss']\n",
    "\n",
    "\n",
    "    epch = range(1, len(train_loss) + 1)\n",
    "\n",
    "\n",
    "    plt.plot(epch, train_loss, 'b', label='Training Loss')\n",
    "    plt.plot(epch, val_loss, 'r', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'loss_plot_{batch_size}_{i}.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    train_acc = hist.history['accuracy']\n",
    "    val_acc = hist.history['val_accuracy']\n",
    "\n",
    "\n",
    "    epch = range(1, len(train_loss) + 1)\n",
    "\n",
    "\n",
    "    plt.plot(epch, train_acc, 'b', label='Training Accuracy')\n",
    "    plt.plot(epch, val_acc, 'r', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'accuracy_plot_{batch_size}_{i}.png')\n",
    "    plt.close()\n",
    "\n",
    "    classifier_model.save(f'model_{batch_size}_{i}.h5')\n",
    " \n",
    "    start_test_time = time.time()\n",
    "    y_pred = classifier_model.predict(X_test)\n",
    "    end_test_time = time.time()\n",
    "    testing_time = end_test_time - start_test_time\n",
    "\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "    y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "    cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "\n",
    "\n",
    "    tp = np.diag(cm)\n",
    "    fp = np.sum(cm, axis=0) - tp\n",
    "    fn = np.sum(cm, axis=1) - tp\n",
    "    tn = np.sum(cm) - (tp + fp + fn)\n",
    "\n",
    "    tp = np.sum(tp)\n",
    "    fp = np.sum(fp)\n",
    "    fn = np.sum(fn)\n",
    "    tn = np.sum(tn)\n",
    "\n",
    "    precision = precision_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "    recall = recall_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "    test_accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
    "    f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "\n",
    "\n",
    "    metrics = {\n",
    "            'Train Accuracy' :max(train_acc),\n",
    "            'Validation Accuracy' : max(val_acc),\n",
    "            'Test Accuracy': test_accuracy,\n",
    "            'TP': tp,\n",
    "            'TN': tn,\n",
    "            'FP': fp,\n",
    "            'FN': fn,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1': f1,\n",
    "            'Training Time': sum(cb.logs),\n",
    "            'Testing Time' : testing_time\n",
    "        }\n",
    "\n",
    "    all_metrics.append(metrics)\n",
    "\n",
    "    with open(f'results_{batch_size}_{i}.txt', 'w') as f:\n",
    "            for key, value in metrics.items():\n",
    "                f.write(f'{key}: {value}\\n')\n",
    "\n",
    "                \n",
    "\n",
    "all_train_accuracy = []\n",
    "all_val_accuracy = []\n",
    "all_test_accuracy = []\n",
    "all_tp = []\n",
    "all_tn = []\n",
    "all_fp = []\n",
    "all_fn = []\n",
    "all_precision = []\n",
    "all_recall = []\n",
    "all_f1 = []\n",
    "all_training_time = []\n",
    "all_testing_time = []\n",
    "\n",
    "\n",
    "for metrics in all_metrics:\n",
    "    all_train_accuracy.append(metrics['Train Accuracy'])\n",
    "    all_val_accuracy.append(metrics['Validation Accuracy'])\n",
    "    all_test_accuracy.append(metrics['Test Accuracy'])\n",
    "    all_tp.append(metrics['TP'])\n",
    "    all_tn.append(metrics['TN'])\n",
    "    all_fp.append(metrics['FP'])\n",
    "    all_fn.append(metrics['FN'])\n",
    "    all_precision.append(metrics['Precision'])\n",
    "    all_recall.append(metrics['Recall'])\n",
    "    all_f1.append(metrics['F1'])\n",
    "    all_training_time.append(metrics['Training Time'])\n",
    "    all_testing_time.append(metrics['Testing Time'])\n",
    "\n",
    "\n",
    "average_metrics = {\n",
    "    'Train Accuracy': np.mean(all_train_accuracy),\n",
    "    'Validation Accuracy': np.mean(all_val_accuracy),\n",
    "    'Test Accuracy': np.mean(all_test_accuracy),\n",
    "    'TP': np.mean(all_tp),\n",
    "    'TN': np.mean(all_tn),\n",
    "    'FP': np.mean(all_fp),\n",
    "    'FN': np.mean(all_fn),\n",
    "    'Precision': np.mean(all_precision),\n",
    "    'Recall': np.mean(all_recall),\n",
    "    'F1': np.mean(all_f1),\n",
    "    'Training Time': np.mean(all_training_time),\n",
    "    'Testing Time' : np.mean(all_testing_time)\n",
    "}\n",
    "\n",
    "with open(f'results_{batch_size}_avg.txt', 'w') as f:\n",
    "            for key, value in average_metrics.items():\n",
    "                f.write(f'{key}: {value}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "classifier_model = keras.models.Sequential([    \n",
    "    keras.layers.Conv2D(filters=10, kernel_size=(11,1),kernel_initializer=glorot_normal() ,activation='tanh',padding='same' ,input_shape=(200,10,1)),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 1)),\n",
    "\n",
    "    \n",
    "    keras.layers.Conv2D(filters=20, kernel_size=(5,1),kernel_initializer=glorot_normal() ,activation='tanh' ,padding='same'), \n",
    "    keras.layers.MaxPool2D(pool_size=(2, 1)),\n",
    "    keras.layers.Dropout(rate=0.5),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation='tanh',kernel_initializer=glorot_normal()), # glorot_uniform\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lr = 0.0002\n",
    "epochs = 200\n",
    "\n",
    "opt = Adam(lr=lr)\n",
    "classifier_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "hist = classifier_model.fit(X_train, y_train, epochs=epochs,batch_size=1000 ,validation_data= (X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred = classifier_model.predict(X_test)\n",
    "\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "confusion = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "\n",
    "confusion = confusion/2000\n",
    "\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion, display_labels=[\"Spike\", \"Missing\", \"Normal\", \"Random\", \"Drift\"])\n",
    "\n",
    "disp.plot(cmap='Blues')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "classifier_model = keras.models.Sequential([    \n",
    "    keras.layers.Conv2D(filters=10, kernel_size=(11,1),kernel_initializer=glorot_normal() ,activation='tanh',padding='same' ,input_shape=(200,10,1)),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 1)),\n",
    "\n",
    "    \n",
    "    keras.layers.Conv2D(filters=20, kernel_size=(5,1),kernel_initializer=glorot_normal() ,activation='tanh' ,padding='same'), \n",
    "    keras.layers.MaxPool2D(pool_size=(2, 1)),\n",
    "    keras.layers.Dropout(rate=0.5),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation='tanh',kernel_initializer=glorot_normal()), # glorot_uniform\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "lr = 0.0002\n",
    "epochs = 200\n",
    "\n",
    "opt = Adam(lr=lr)\n",
    "classifier_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "hist = classifier_model.fit(X_train, y_train, epochs=epochs,batch_size=1000 ,validation_data= (X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred = classifier_model.predict(X_test)\n",
    "\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "confusion = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "\n",
    "confusion = confusion/2000\n",
    "\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion, display_labels=[\"Spike\", \"Missing\", \"Normal\", \"Random\", \"Drift\"])\n",
    "\n",
    "disp.plot(cmap='Blues')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "classifier_model = keras.models.Sequential([    \n",
    "    keras.layers.Conv2D(filters=10, kernel_size=(11,1),kernel_initializer=glorot_normal() ,activation='tanh',padding='same' ,input_shape=(200,10,1)),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 1)),\n",
    "\n",
    "    \n",
    "    keras.layers.Conv2D(filters=20, kernel_size=(5,1),kernel_initializer=glorot_normal() ,activation='tanh' ,padding='same'), \n",
    "    keras.layers.MaxPool2D(pool_size=(2, 1)),\n",
    "    keras.layers.Dropout(rate=0.5),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation='tanh',kernel_initializer=glorot_normal()), # glorot_uniform\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "lr = 0.0002\n",
    "epochs = 200\n",
    "\n",
    "opt = Adam(lr=lr)\n",
    "classifier_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "hist = classifier_model.fit(X_train, y_train, epochs=epochs,batch_size=1000 ,validation_data= (X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruciton Stage: Auto Encoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# First For Jump Data\n",
    "\n",
    "X_jump_train, X_jump_test, y_normal_train, y_normal_test = train_test_split(JumpData, NormalData, test_size=0.2, random_state=42)\n",
    "X_jump_train, X_jump_val, y_normal_train, y_normal_val = train_test_split(X_jump_train, y_normal_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_jump_train.shape, X_jump_test.shape, X_jump_val.shape, y_normal_train.shape, y_normal_test.shape, y_normal_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_normal_train[1,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "reconstructor_model = keras.models.Sequential([    \n",
    "    # Encoder\n",
    "    keras.layers.Conv2D(filters=10, kernel_size=(31,5), activation='relu',kernel_initializer=glorot_uniform(3),padding='same' ,input_shape=(200,10,1)),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    \n",
    "    \n",
    "    keras.layers.Conv2D(filters=20, kernel_size=(31,3), activation='relu',kernel_initializer=glorot_uniform(3) ,padding='same'), \n",
    "    keras.layers.MaxPool2D(pool_size=(2, 1)),\n",
    "    \n",
    "    keras.layers.Flatten(), # 5000\n",
    "    keras.layers.Dense(10000, activation='relu',kernel_initializer=glorot_uniform(3)), # 5000\n",
    "    keras.layers.Dense(500, activation='relu',kernel_initializer=glorot_uniform(3)),\n",
    "    \n",
    "    \n",
    "    # Decoder\n",
    "    keras.layers.Dense(500, activation='relu',kernel_initializer=glorot_uniform(3)),\n",
    "#     keras.layers.Dense(10000, activation='relu',kernel_initializer=glorot_uniform(3)),\n",
    "    keras.layers.Dense(5000, activation='relu',kernel_initializer=glorot_uniform(3)), # Doubtful, ask \n",
    "    keras.layers.Reshape((50,5,20)),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=20, kernel_size=(31,3), activation='relu' ,padding='same',kernel_initializer=glorot_uniform(3)),\n",
    "    keras.layers.UpSampling2D(size=(2, 1)),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=10, kernel_size=(31,5), activation='relu' ,padding='same',kernel_initializer=glorot_uniform(3)),\n",
    "    keras.layers.UpSampling2D(size=(2, 2)),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=1, kernel_size=(31,5), activation='relu' ,padding='same',kernel_initializer=glorot_uniform(3)),  \n",
    "])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "epochs = 200\n",
    "\n",
    "opt = Adam(lr=lr)\n",
    "reconstructor_model.compile(loss='mse', optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "reconstructor_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "epochs = 20           \n",
    "jump_rec_hist = reconstructor_model.fit(X_jump_train, y_normal_train, epochs=epochs,batch_size=50 ,validation_data= (X_jump_val, y_normal_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loss = jump_rec_hist.history['loss']\n",
    "val_loss = jump_rec_hist.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss,  label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_pred = reconstructor_model.predict(X_jump_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_pred[1,:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_normal_test[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_normal_test[1,:,1], label='Real Value')\n",
    "plt.plot(y_pred[1,:,1,0], label='Predicted Value')\n",
    "plt.xlabel('Data Points')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.title('Real vs. Predicted Value')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3889302,
     "sourceId": 6756493,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
